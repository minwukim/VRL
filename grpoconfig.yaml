model_name: "Qwen/Qwen2.5-3B"
output_dir: "outputs/qwen2.5-3b-grpo-full"
run_name: "qwen3b-full"
resume_from_checkpoint: True
learning_rate: 1e-6
beta: 0.001
adam_beta1: 0.9
adam_beta2: 0.99
weight_decay: 0.1
warmup_steps: 25
lr_scheduler_type: constant_with_warmup
logging_steps: 1
bf16: True
bf16_full_eval: True
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
gradient_checkpointing: True
num_generations: 8
max_prompt_length: 256
max_completion_length: 4096
num_train_epochs: 1
save_steps: 50
max_grad_norm: 0.1
report_to: wandb
use_vllm: True
vllm_max_model_len: 5000
max_steps: 400
log_completions: True
evaluation_strategy: steps
eval_steps: 50
eval_on_start: False 
