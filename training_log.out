[2025-03-19 14:46:59,408] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0319 14:47:37.759000 8494 site-packages/torch/distributed/run.py:793] 
W0319 14:47:37.759000 8494 site-packages/torch/distributed/run.py:793] *****************************************
W0319 14:47:37.759000 8494 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0319 14:47:37.759000 8494 site-packages/torch/distributed/run.py:793] *****************************************
[2025-03-19 14:49:43,297] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-19 14:49:43,756] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-19 14:49:45,831] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-19 14:49:46,657] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-19 14:49:46,838] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-19 14:49:47,283] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 03-19 14:50:58 __init__.py:190] Automatically detected platform cuda.
INFO 03-19 14:50:58 __init__.py:190] Automatically detected platform cuda.
INFO 03-19 14:50:58 __init__.py:190] Automatically detected platform cuda.
INFO 03-19 14:50:59 __init__.py:190] Automatically detected platform cuda.
INFO 03-19 14:51:00 __init__.py:190] Automatically detected platform cuda.
INFO 03-19 14:51:01 __init__.py:190] Automatically detected platform cuda.
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-large', run_name='qwen3b-large', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=8, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=500, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-large/checkpoint-125', resume_from_checkpoint=True)
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.11s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.40s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.01s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.89s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:58<00:58, 58.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.47s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.12s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.48s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 31.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:10<00:00, 35.38s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.33s/it]
[2025-03-19 14:52:24,520] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:24,529] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:24,537] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:24,538] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-19 14:52:24,550] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:24,559] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:24,585] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-19 14:52:26,771] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:27,592] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:27,647] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:27,655] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:27,750] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:27,794] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:52:32,258] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
INFO 03-19 14:54:51 config.py:542] This model supports multiple tasks: {'classify', 'generate', 'embed', 'score', 'reward'}. Defaulting to 'generate'.
INFO 03-19 14:54:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='outputs/qwen2.5-3b-grpo-large/checkpoint-125', speculative_config=None, tokenizer='outputs/qwen2.5-3b-grpo-large/checkpoint-125', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:6, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=outputs/qwen2.5-3b-grpo-large/checkpoint-125, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 03-19 14:54:58 cuda.py:230] Using Flash Attention backend.
INFO 03-19 14:54:59 model_runner.py:1110] Starting to load model outputs/qwen2.5-3b-grpo-large/checkpoint-125...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.37it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.51it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.67it/s]

INFO 03-19 14:55:01 model_runner.py:1115] Loading model weights took 0.0000 GB
INFO 03-19 14:55:03 worker.py:267] Memory profiling takes 1.67 seconds
INFO 03-19 14:55:03 worker.py:267] the current vLLM instance can use total_gpu_memory (79.21GiB) x gpu_memory_utilization (0.90) = 71.29GiB
INFO 03-19 14:55:03 worker.py:267] model weights take 0.00GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.00GiB; the rest of the memory reserved for KV Cache is 71.29GiB.
INFO 03-19 14:55:03 executor_base.py:110] # CUDA blocks: 129775, # CPU blocks: 7281
INFO 03-19 14:55:03 executor_base.py:115] Maximum concurrency for 5000 tokens per request: 415.28x
INFO 03-19 14:55:06 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:18,  1.82it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:00<00:13,  2.36it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:11,  2.70it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:01<00:10,  2.88it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:01<00:10,  2.93it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:02<00:10,  2.74it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:02<00:09,  2.88it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:02<00:09,  2.98it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:03<00:08,  3.04it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:03<00:08,  3.09it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:03<00:07,  3.12it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:04<00:07,  3.10it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:04<00:07,  3.11it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:04<00:06,  3.14it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:05<00:06,  3.18it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:05<00:05,  3.20it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:05<00:05,  3.09it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:06<00:05,  3.16it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:06<00:04,  3.22it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:06<00:04,  3.25it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:06<00:04,  3.28it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:07<00:03,  3.30it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:07<00:03,  3.31it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:07<00:03,  3.31it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:08<00:03,  3.15it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:08<00:02,  3.21it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:08<00:02,  3.25it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:09<00:02,  3.29it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:09<00:01,  3.29it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:09<00:01,  3.31it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:09<00:01,  3.50it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:10<00:00,  3.85it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:10<00:00,  3.42it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:10<00:00,  3.78it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:11<00:00,  3.23it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:11<00:00,  3.15it/s]
INFO 03-19 14:55:17 model_runner.py:1562] Graph capturing finished in 11 secs, took 0.00 GiB
INFO 03-19 14:55:17 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 15.92 seconds
[2025-03-19 14:55:19,381] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown
[2025-03-19 14:55:19,382] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,382] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,382] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,383] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,383] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,383] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 6
[2025-03-19 14:55:19,402] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-03-19 14:55:19,404] [INFO] [logging.py:129:log_dist] [Rank 0] Creating ZeRO Offload
[2025-03-19 14:55:19,873] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-03-19 14:55:19,874] [INFO] [utils.py:782:see_memory_usage] MA 0.96 GB         Max_MA 0.96 GB         CA 1.76 GB         Max_CA 2 GB 
[2025-03-19 14:55:19,875] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 121.59 GB, percent = 6.0%
Parameter Offload: Total persistent parameters: 241664 in 181 params
[2025-03-19 14:55:20,384] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-03-19 14:55:20,385] [INFO] [utils.py:782:see_memory_usage] MA 0.96 GB         Max_MA 0.96 GB         CA 1.76 GB         Max_CA 2 GB 
[2025-03-19 14:55:20,386] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 114.28 GB, percent = 5.7%
[2025-03-19 14:55:20,388] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-03-19 14:55:20,389] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-19 14:55:20,389] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-19 14:55:20,389] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-03-19 14:55:20,390] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-03-19 14:55:20,391] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-19 14:55:20,391] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-03-19 14:55:20,392] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-03-19 14:55:20,393] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-03-19 14:55:20,393] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-03-19 14:55:20,394] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-03-19 14:55:20,395] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x793cd03e20b0>
[2025-03-19 14:55:20,395] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-03-19 14:55:20,396] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-19 14:55:20,396] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-03-19 14:55:20,397] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-03-19 14:55:20,397] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-19 14:55:20,399] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-03-19 14:55:20,399] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-03-19 14:55:20,399] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-03-19 14:55:20,400] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-03-19 14:55:20,400] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-03-19 14:55:20,400] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-03-19 14:55:20,400] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-19 14:55:20,400] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-19 14:55:20,401] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-03-19 14:55:20,401] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-03-19 14:55:20,402] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-03-19 14:55:20,402] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-03-19 14:55:20,403] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-03-19 14:55:20,403] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-03-19 14:55:20,404] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-19 14:55:20,404] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-03-19 14:55:20,404] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-03-19 14:55:20,405] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-03-19 14:55:20,405] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-03-19 14:55:20,405] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-03-19 14:55:20,406] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 4
[2025-03-19 14:55:20,406] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.1
[2025-03-19 14:55:20,406] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-03-19 14:55:20,406] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-03-19 14:55:20,407] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-19 14:55:20,407] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-03-19 14:55:20,408] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-03-19 14:55:20,408] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-03-19 14:55:20,408] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-03-19 14:55:20,408] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-03-19 14:55:20,409] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-03-19 14:55:20,409] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-19 14:55:20,409] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-19 14:55:20,409] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-03-19 14:55:20,410] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-03-19 14:55:20,410] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-03-19 14:55:20,410] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-19 14:55:20,410] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-03-19 14:55:20,410] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-03-19 14:55:20,411] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-03-19 14:55:20,411] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-03-19 14:55:20,411] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-03-19 14:55:20,411] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-19 14:55:20,412] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-03-19 14:55:20,412] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-03-19 14:55:20,412] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-03-19 14:55:20,413] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-03-19 14:55:20,413] [INFO] [config.py:1003:print]   train_batch_size ............. 192
[2025-03-19 14:55:20,413] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  8
[2025-03-19 14:55:20,414] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-03-19 14:55:20,414] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-03-19 14:55:20,414] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-03-19 14:55:20,414] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-03-19 14:55:20,415] [INFO] [config.py:1003:print]   world_size ................... 6
[2025-03-19 14:55:20,415] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-03-19 14:55:20,415] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-03-19 14:55:20,415] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-03-19 14:55:20,416] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-19 14:55:20,416] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-03-19 14:55:20,416] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 192, 
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 4, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 0.1, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 4.194304e+06, 
    "zero_optimization.stage3_param_persistence_threshold": 2.048000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 3.774874e+06
}
Parameter Offload: Total persistent parameters: 241664 in 181 params
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 50 (from args) != 100 (from trainer_state.json)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ss13750 (ss13750-new-york-university-abu-dhabi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/VRL/wandb/run-20250319_145602-e8rm9eku
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qwen3b-large
wandb: ⭐️ View project at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface
wandb: 🚀 View run at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface/runs/e8rm9eku
  0%|          | 0/500 [00:00<?, ?it/s]/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
 25%|██▌       | 126/500 [01:24<04:12,  1.48it/s]                                                 {'loss': -0.0, 'grad_norm': 0.31986754951594826, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1015625447034836, 'reward': 1.1015625447034836, 'reward_std': 0.5459938421845436, 'completion_length': 504.9219055175781, 'kl': 0.0, 'epoch': 0.4}
 25%|██▌       | 126/500 [01:24<04:12,  1.48it/s]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
 25%|██▌       | 127/500 [02:42<09:34,  1.54s/it]                                                 {'loss': 0.0, 'grad_norm': 0.3613500291812856, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0885417014360428, 'reward': 1.0885417014360428, 'reward_std': 0.5882712155580521, 'completion_length': 599.3541946411133, 'kl': 0.0001347064971923828, 'epoch': 0.41}
 25%|██▌       | 127/500 [02:42<09:34,  1.54s/it] 26%|██▌       | 128/500 [03:49<15:54,  2.57s/it]                                                 {'loss': 0.0, 'grad_norm': 0.3255042206626782, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1640625223517418, 'reward': 1.1640625223517418, 'reward_std': 0.5212151408195496, 'completion_length': 407.3645935058594, 'kl': 0.0002932548522949219, 'epoch': 0.41}
 26%|██▌       | 128/500 [03:49<15:54,  2.57s/it] 26%|██▌       | 129/500 [04:35<21:44,  3.51s/it]                                                 {'loss': 0.0, 'grad_norm': 0.3759478286334143, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.236979216337204, 'reward': 1.236979216337204, 'reward_std': 0.715852901339531, 'completion_length': 356.1510467529297, 'kl': 0.0007352828979492188, 'epoch': 0.41}
 26%|██▌       | 129/500 [04:35<21:44,  3.51s/it] 26%|██▌       | 130/500 [05:43<33:56,  5.50s/it]                                                 {'loss': 0.0, 'grad_norm': 0.31654039401383854, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7786458544433117, 'reward': 0.7786458544433117, 'reward_std': 0.5801614038646221, 'completion_length': 485.3854293823242, 'kl': 0.0010128021240234375, 'epoch': 0.42}
 26%|██▌       | 130/500 [05:43<33:56,  5.50s/it] 26%|██▌       | 131/500 [07:17<56:36,  9.20s/it]                                                 {'loss': 0.0, 'grad_norm': 0.32835863193500026, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4114583469927311, 'reward': 0.4114583469927311, 'reward_std': 0.5622148290276527, 'completion_length': 669.8750228881836, 'kl': 0.0011310577392578125, 'epoch': 0.42}
 26%|██▌       | 131/500 [07:17<56:36,  9.20s/it] 26%|██▋       | 132/500 [08:23<1:15:53, 12.37s/it]                                                   {'loss': 0.0, 'grad_norm': 0.34042104779462173, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.015625037252903, 'reward': 1.015625037252903, 'reward_std': 0.6666065007448196, 'completion_length': 472.90625762939453, 'kl': 0.0017795562744140625, 'epoch': 0.42}
 26%|██▋       | 132/500 [08:23<1:15:53, 12.37s/it] 27%|██▋       | 133/500 [09:31<1:40:47, 16.48s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3424459069093406, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.036458358168602, 'reward': 1.036458358168602, 'reward_std': 0.6220323890447617, 'completion_length': 506.8958435058594, 'kl': 0.0021419525146484375, 'epoch': 0.43}
 27%|██▋       | 133/500 [09:31<1:40:47, 16.48s/it] 27%|██▋       | 134/500 [10:42<2:12:40, 21.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.30630013807405465, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.838541679084301, 'reward': 0.838541679084301, 'reward_std': 0.4950829818844795, 'completion_length': 530.96875, 'kl': 0.00213623046875, 'epoch': 0.43}
 27%|██▋       | 134/500 [10:42<2:12:40, 21.75s/it] 27%|██▋       | 135/500 [11:59<2:53:22, 28.50s/it]                                                   {'loss': 0.0, 'grad_norm': 0.32366147417927454, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.718750037252903, 'reward': 0.718750037252903, 'reward_std': 0.6393315494060516, 'completion_length': 583.1093902587891, 'kl': 0.002330780029296875, 'epoch': 0.43}
 27%|██▋       | 135/500 [11:59<2:53:22, 28.50s/it] 27%|██▋       | 136/500 [13:34<3:51:37, 38.18s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3104616780336086, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7682291939854622, 'reward': 0.7682291939854622, 'reward_std': 0.7048910111188889, 'completion_length': 570.7812576293945, 'kl': 0.003040313720703125, 'epoch': 0.44}
 27%|██▋       | 136/500 [13:34<3:51:37, 38.18s/it] 27%|██▋       | 137/500 [14:42<4:22:17, 43.35s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3578109203974763, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2447916865348816, 'reward': 1.2447916865348816, 'reward_std': 0.6363849192857742, 'completion_length': 465.5052261352539, 'kl': 0.003459930419921875, 'epoch': 0.44}
 27%|██▋       | 137/500 [14:42<4:22:17, 43.35s/it] 28%|██▊       | 138/500 [15:52<4:54:06, 48.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2661125052524839, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8098958507180214, 'reward': 0.8098958507180214, 'reward_std': 0.5700575709342957, 'completion_length': 633.4896087646484, 'kl': 0.003154754638671875, 'epoch': 0.44}
 28%|██▊       | 138/500 [15:52<4:54:06, 48.75s/it] 28%|██▊       | 139/500 [17:05<5:24:34, 53.95s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3349556586851638, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2005208730697632, 'reward': 1.2005208730697632, 'reward_std': 0.7935972809791565, 'completion_length': 511.9635467529297, 'kl': 0.00311279296875, 'epoch': 0.44}
 28%|██▊       | 139/500 [17:05<5:24:34, 53.95s/it] 28%|██▊       | 140/500 [18:21<5:55:28, 59.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.31954855162570345, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7734375111758709, 'reward': 0.7734375111758709, 'reward_std': 0.677626222372055, 'completion_length': 627.6406478881836, 'kl': 0.003574371337890625, 'epoch': 0.45}
 28%|██▊       | 140/500 [18:21<5:55:28, 59.25s/it] 28%|██▊       | 141/500 [19:36<6:18:46, 63.30s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3142407137942449, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9843750149011612, 'reward': 0.9843750149011612, 'reward_std': 0.6501127779483795, 'completion_length': 554.6823043823242, 'kl': 0.007930755615234375, 'epoch': 0.45}
 28%|██▊       | 141/500 [19:36<6:18:46, 63.30s/it] 28%|██▊       | 142/500 [21:19<7:21:38, 74.02s/it]                                                   {'loss': 0.0, 'grad_norm': 0.22334886373272553, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2109375223517418, 'reward': 1.2109375223517418, 'reward_std': 0.46508045494556427, 'completion_length': 527.8489685058594, 'kl': 0.00626373291015625, 'epoch': 0.45}
 28%|██▊       | 142/500 [21:19<7:21:38, 74.02s/it] 29%|██▊       | 143/500 [21:55<6:17:24, 63.43s/it]                                                   {'loss': 0.0, 'grad_norm': 0.36929796440227786, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.041666716337204, 'reward': 1.041666716337204, 'reward_std': 0.427584707736969, 'completion_length': 365.0729217529297, 'kl': 0.00861358642578125, 'epoch': 0.46}
 29%|██▊       | 143/500 [21:55<6:17:24, 63.43s/it] 29%|██▉       | 144/500 [22:59<6:18:14, 63.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.27438683537633524, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0078125298023224, 'reward': 1.0078125298023224, 'reward_std': 0.5104064643383026, 'completion_length': 532.0364685058594, 'kl': 0.00644683837890625, 'epoch': 0.46}
 29%|██▉       | 144/500 [22:59<6:18:14, 63.75s/it] 29%|██▉       | 145/500 [24:13<6:34:41, 66.71s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2520351313098728, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8750000298023224, 'reward': 0.8750000298023224, 'reward_std': 0.5579178407788277, 'completion_length': 545.9531402587891, 'kl': 0.00705718994140625, 'epoch': 0.46}
 29%|██▉       | 145/500 [24:13<6:34:41, 66.71s/it] 29%|██▉       | 146/500 [25:11<6:18:21, 64.13s/it]                                                   {'loss': 0.0, 'grad_norm': 0.23918814108601563, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2786458730697632, 'reward': 1.2786458730697632, 'reward_std': 0.4834364727139473, 'completion_length': 438.5052185058594, 'kl': 0.00939178466796875, 'epoch': 0.47}
 29%|██▉       | 146/500 [25:11<6:18:21, 64.13s/it] 29%|██▉       | 147/500 [26:20<6:25:08, 65.46s/it]                                                   {'loss': 0.0, 'grad_norm': 0.252995531963066, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8906250298023224, 'reward': 0.8906250298023224, 'reward_std': 0.5415510460734367, 'completion_length': 520.9270935058594, 'kl': 0.01332855224609375, 'epoch': 0.47}
 29%|██▉       | 147/500 [26:20<6:25:08, 65.46s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Zero' object has no attribute 'items'. Did you mean: 'atoms'?
 30%|██▉       | 148/500 [27:05<5:49:33, 59.58s/it]                                                   {'loss': 0.0, 'grad_norm': 0.18118974164475432, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.4322917312383652, 'reward': 1.4322917312383652, 'reward_std': 0.34690743312239647, 'completion_length': 411.82293701171875, 'kl': 0.012786865234375, 'epoch': 0.47}
 30%|██▉       | 148/500 [27:05<5:49:33, 59.58s/it] 30%|██▉       | 149/500 [27:41<5:07:07, 52.50s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4659533349292339, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9062500223517418, 'reward': 0.9062500223517418, 'reward_std': 0.7137638479471207, 'completion_length': 493.56251525878906, 'kl': 0.0112152099609375, 'epoch': 0.48}
 30%|██▉       | 149/500 [27:41<5:07:07, 52.50s/it] 30%|███       | 150/500 [29:00<5:52:05, 60.36s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3461174818739138, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8489583507180214, 'reward': 0.8489583507180214, 'reward_std': 0.7454965859651566, 'completion_length': 564.3489761352539, 'kl': 0.0122222900390625, 'epoch': 0.48}
 30%|███       | 150/500 [29:00<5:52:05, 60.36s/it] 30%|███       | 151/500 [30:20<6:25:15, 66.23s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2682992967356317, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9453125223517418, 'reward': 0.9453125223517418, 'reward_std': 0.2494450844824314, 'completion_length': 531.9635543823242, 'kl': 0.01282501220703125, 'epoch': 0.48}
 30%|███       | 151/500 [30:20<6:25:15, 66.23s/it] 30%|███       | 152/500 [30:57<5:33:42, 57.53s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3732945224178272, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2786458730697632, 'reward': 1.2786458730697632, 'reward_std': 0.7179122269153595, 'completion_length': 512.5885620117188, 'kl': 0.01248931884765625, 'epoch': 0.49}
 30%|███       | 152/500 [30:57<5:33:42, 57.53s/it] 31%|███       | 153/500 [32:31<6:35:12, 68.34s/it]                                                   {'loss': 0.0, 'grad_norm': 0.26970137953748746, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0286458432674408, 'reward': 1.0286458432674408, 'reward_std': 0.5523144602775574, 'completion_length': 593.2969055175781, 'kl': 0.0122528076171875, 'epoch': 0.49}
 31%|███       | 153/500 [32:31<6:35:12, 68.34s/it] 31%|███       | 154/500 [34:09<7:24:53, 77.15s/it]                                                   {'loss': 0.0, 'grad_norm': 0.28614883941402364, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9088542014360428, 'reward': 0.9088542014360428, 'reward_std': 0.6441231444478035, 'completion_length': 691.6562805175781, 'kl': 0.0105133056640625, 'epoch': 0.49}
 31%|███       | 154/500 [34:09<7:24:53, 77.15s/it] 31%|███       | 155/500 [35:03<6:43:45, 70.22s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2681811002840773, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1953125149011612, 'reward': 1.1953125149011612, 'reward_std': 0.4351717680692673, 'completion_length': 494.7135696411133, 'kl': 0.01971435546875, 'epoch': 0.5}
 31%|███       | 155/500 [35:03<6:43:45, 70.22s/it] 31%|███       | 156/500 [36:05<6:29:24, 67.92s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2929184097650999, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8359375298023224, 'reward': 0.8359375298023224, 'reward_std': 0.5886798202991486, 'completion_length': 593.7760620117188, 'kl': 0.014251708984375, 'epoch': 0.5}
 31%|███       | 156/500 [36:05<6:29:24, 67.92s/it] 31%|███▏      | 157/500 [37:02<6:09:49, 64.69s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2746044117679323, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1614583730697632, 'reward': 1.1614583730697632, 'reward_std': 0.620369516313076, 'completion_length': 519.6354370117188, 'kl': 0.01904296875, 'epoch': 0.5}
 31%|███▏      | 157/500 [37:02<6:09:49, 64.69s/it] 32%|███▏      | 158/500 [38:30<6:47:21, 71.47s/it]                                                   {'loss': 0.0, 'grad_norm': 0.30682963589183504, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8567708730697632, 'reward': 0.8567708730697632, 'reward_std': 0.6517392322421074, 'completion_length': 611.2031555175781, 'kl': 0.0141448974609375, 'epoch': 0.51}
 32%|███▏      | 158/500 [38:30<6:47:21, 71.47s/it] 32%|███▏      | 159/500 [39:56<7:12:03, 76.02s/it]                                                   {'loss': 0.0, 'grad_norm': 0.31209367298987895, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.005208358168602, 'reward': 1.005208358168602, 'reward_std': 0.6643009036779404, 'completion_length': 627.6666870117188, 'kl': 0.01302337646484375, 'epoch': 0.51}
 32%|███▏      | 159/500 [39:56<7:12:03, 76.02s/it] 32%|███▏      | 160/500 [40:59<6:47:45, 71.96s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2564313898087047, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1406250149011612, 'reward': 1.1406250149011612, 'reward_std': 0.4763942211866379, 'completion_length': 544.3385543823242, 'kl': 0.021636962890625, 'epoch': 0.51}
 32%|███▏      | 160/500 [40:59<6:47:45, 71.96s/it] 32%|███▏      | 161/500 [41:57<6:23:59, 67.96s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3926205486621931, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1848959028720856, 'reward': 1.1848959028720856, 'reward_std': 0.6204557418823242, 'completion_length': 497.95314025878906, 'kl': 0.02728271484375, 'epoch': 0.52}
 32%|███▏      | 161/500 [41:57<6:23:59, 67.96s/it] 32%|███▏      | 162/500 [42:58<6:10:22, 65.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3401360624519028, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9479166939854622, 'reward': 0.9479166939854622, 'reward_std': 0.5277987569570541, 'completion_length': 514.2604293823242, 'kl': 0.0183258056640625, 'epoch': 0.52}
 32%|███▏      | 162/500 [42:58<6:10:22, 65.75s/it] 33%|███▎      | 163/500 [44:10<6:20:19, 67.71s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3302198657723131, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.955729216337204, 'reward': 0.955729216337204, 'reward_std': 0.5620356127619743, 'completion_length': 551.1510543823242, 'kl': 0.024505615234375, 'epoch': 0.52}
 33%|███▎      | 163/500 [44:10<6:20:19, 67.71s/it] 33%|███▎      | 164/500 [45:35<6:46:59, 72.68s/it]                                                   {'loss': 0.0, 'grad_norm': 0.31062283359754106, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1692708730697632, 'reward': 1.1692708730697632, 'reward_std': 0.6318903565406799, 'completion_length': 586.1406478881836, 'kl': 0.0337066650390625, 'epoch': 0.52}
 33%|███▎      | 164/500 [45:35<6:46:59, 72.68s/it] 33%|███▎      | 165/500 [46:10<5:43:29, 61.52s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3705417621466415, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2421875298023224, 'reward': 1.2421875298023224, 'reward_std': 0.3900788612663746, 'completion_length': 440.43751525878906, 'kl': 0.031402587890625, 'epoch': 0.53}
 33%|███▎      | 165/500 [46:10<5:43:29, 61.52s/it] 33%|███▎      | 166/500 [47:08<5:35:51, 60.33s/it]                                                   {'loss': 0.0, 'grad_norm': 0.41497002134698535, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9583333730697632, 'reward': 0.9583333730697632, 'reward_std': 0.7614351063966751, 'completion_length': 556.723991394043, 'kl': 0.0461273193359375, 'epoch': 0.53}
 33%|███▎      | 166/500 [47:08<5:35:51, 60.33s/it] 33%|███▎      | 167/500 [48:17<5:49:41, 63.01s/it]                                                   {'loss': 0.0, 'grad_norm': 0.37159803371249933, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9609375149011612, 'reward': 0.9609375149011612, 'reward_std': 0.646566316485405, 'completion_length': 605.7604522705078, 'kl': 0.034942626953125, 'epoch': 0.53}
 33%|███▎      | 167/500 [48:17<5:49:41, 63.01s/it] 34%|███▎      | 168/500 [49:31<6:06:27, 66.23s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3321924710492189, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0000000149011612, 'reward': 1.0000000149011612, 'reward_std': 0.697262167930603, 'completion_length': 630.5677261352539, 'kl': 0.0197296142578125, 'epoch': 0.54}
 34%|███▎      | 168/500 [49:31<6:06:27, 66.23s/it] 34%|███▍      | 169/500 [50:31<5:55:43, 64.48s/it]                                                   {'loss': 0.0, 'grad_norm': 0.20574767975680752, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.346354216337204, 'reward': 1.346354216337204, 'reward_std': 0.2168855033814907, 'completion_length': 507.3750228881836, 'kl': 0.0447998046875, 'epoch': 0.54}
 34%|███▍      | 169/500 [50:31<5:55:43, 64.48s/it] 34%|███▍      | 170/500 [51:32<5:48:06, 63.29s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.25910684580823573, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1770833730697632, 'reward': 1.1770833730697632, 'reward_std': 0.47326062619686127, 'completion_length': 527.6562652587891, 'kl': 0.0726318359375, 'epoch': 0.54}
 34%|███▍      | 170/500 [51:32<5:48:06, 63.29s/it] 34%|███▍      | 171/500 [52:05<4:58:47, 54.49s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.28433792688082815, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.106770858168602, 'reward': 1.106770858168602, 'reward_std': 0.47187281027436256, 'completion_length': 449.53125762939453, 'kl': 0.05877685546875, 'epoch': 0.55}
 34%|███▍      | 171/500 [52:05<4:58:47, 54.49s/it] 34%|███▍      | 172/500 [53:12<5:18:15, 58.22s/it]                                                   {'loss': 0.0, 'grad_norm': 0.30940865063589595, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1510417014360428, 'reward': 1.1510417014360428, 'reward_std': 0.5247913971543312, 'completion_length': 596.4322967529297, 'kl': 0.032989501953125, 'epoch': 0.55}
 34%|███▍      | 172/500 [53:12<5:18:15, 58.22s/it] 35%|███▍      | 173/500 [54:29<5:46:51, 63.64s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.3099821959262384, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9843750149011612, 'reward': 0.9843750149011612, 'reward_std': 0.6001852303743362, 'completion_length': 613.4479522705078, 'kl': 0.05267333984375, 'epoch': 0.55}
 35%|███▍      | 173/500 [54:29<5:46:51, 63.64s/it] 35%|███▍      | 174/500 [55:54<6:21:27, 70.21s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3754734672246722, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7812500149011612, 'reward': 0.7812500149011612, 'reward_std': 0.7091185078024864, 'completion_length': 651.3541870117188, 'kl': 0.0218963623046875, 'epoch': 0.56}
 35%|███▍      | 174/500 [55:54<6:21:27, 70.21s/it] 35%|███▌      | 175/500 [56:32<5:28:05, 60.57s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.31314240044024616, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.4192709028720856, 'reward': 1.4192709028720856, 'reward_std': 0.2706556972116232, 'completion_length': 463.4739761352539, 'kl': 0.058746337890625, 'epoch': 0.56}
 35%|███▌      | 175/500 [56:32<5:28:05, 60.57s/it] 35%|███▌      | 176/500 [57:30<5:21:38, 59.56s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5140501688153325, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.5468750596046448, 'reward': 1.5468750596046448, 'reward_std': 0.4649743065237999, 'completion_length': 509.3593978881836, 'kl': 0.055511474609375, 'epoch': 0.56}
 35%|███▌      | 176/500 [57:30<5:21:38, 59.56s/it] 35%|███▌      | 177/500 [58:30<5:22:56, 59.99s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.3068655671819233, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7656250149011612, 'reward': 0.7656250149011612, 'reward_std': 0.7014783769845963, 'completion_length': 623.3645935058594, 'kl': 0.0672607421875, 'epoch': 0.57}
 35%|███▌      | 177/500 [58:31<5:22:56, 59.99s/it] 36%|███▌      | 178/500 [59:08<4:45:31, 53.20s/it]                                                   {'loss': 0.0, 'grad_norm': 0.21397657039228785, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.53125, 'reward': 1.53125, 'reward_std': 0.34019311517477036, 'completion_length': 450.2760467529297, 'kl': 0.044586181640625, 'epoch': 0.57}
 36%|███▌      | 178/500 [59:08<4:45:31, 53.20s/it] 36%|███▌      | 179/500 [1:00:20<5:14:51, 58.85s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.6507218434800368, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1666666865348816, 'reward': 1.1666666865348816, 'reward_std': 0.4706454835832119, 'completion_length': 541.9218902587891, 'kl': 0.09344482421875, 'epoch': 0.57}
 36%|███▌      | 179/500 [1:00:20<5:14:51, 58.85s/it] 36%|███▌      | 180/500 [1:01:16<5:09:30, 58.03s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.3045772428942721, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.106770858168602, 'reward': 1.106770858168602, 'reward_std': 0.4769180342555046, 'completion_length': 493.26564025878906, 'kl': 0.06402587890625, 'epoch': 0.58}
 36%|███▌      | 180/500 [1:01:16<5:09:30, 58.03s/it] 36%|███▌      | 181/500 [1:02:03<4:51:25, 54.81s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.3283203188321895, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.755208358168602, 'reward': 0.755208358168602, 'reward_std': 0.5201007835566998, 'completion_length': 629.3802337646484, 'kl': 0.119110107421875, 'epoch': 0.58}
 36%|███▌      | 181/500 [1:02:03<4:51:25, 54.81s/it] 36%|███▋      | 182/500 [1:03:07<5:05:08, 57.57s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.0401334777421163, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2291666865348816, 'reward': 1.2291666865348816, 'reward_std': 0.5908488035202026, 'completion_length': 536.7343978881836, 'kl': 0.05029296875, 'epoch': 0.58}
 36%|███▋      | 182/500 [1:03:07<5:05:08, 57.57s/it]Timeout during comparison
Timeout during comparison
Timeout during comparison
 37%|███▋      | 183/500 [1:04:21<5:30:27, 62.55s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.2812745083188084, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2968750298023224, 'reward': 1.2968750298023224, 'reward_std': 0.4755798038095236, 'completion_length': 556.7291870117188, 'kl': 0.209869384765625, 'epoch': 0.59}
 37%|███▋      | 183/500 [1:04:21<5:30:27, 62.55s/it] 37%|███▋      | 184/500 [1:05:36<5:47:41, 66.02s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.22841138280968856, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.645833358168602, 'reward': 0.645833358168602, 'reward_std': 0.5358761362731457, 'completion_length': 776.1302337646484, 'kl': 0.05413818359375, 'epoch': 0.59}
 37%|███▋      | 184/500 [1:05:36<5:47:41, 66.02s/it] 37%|███▋      | 185/500 [1:06:16<5:06:49, 58.44s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.26269851168582614, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.4296875447034836, 'reward': 1.4296875447034836, 'reward_std': 0.3392393961548805, 'completion_length': 413.47918701171875, 'kl': 0.0601806640625, 'epoch': 0.59}
 37%|███▋      | 185/500 [1:06:16<5:06:49, 58.44s/it] 37%|███▋      | 186/500 [1:07:14<5:03:57, 58.08s/it]                                                     {'loss': 0.0, 'grad_norm': 1.4406319958740939, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2369792014360428, 'reward': 1.2369792014360428, 'reward_std': 0.4595950357615948, 'completion_length': 616.6093826293945, 'kl': 0.04559326171875, 'epoch': 0.6}
 37%|███▋      | 186/500 [1:07:14<5:03:57, 58.08s/it] 37%|███▋      | 187/500 [1:08:21<5:17:55, 60.95s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.8103213798189848, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7473958507180214, 'reward': 0.7473958507180214, 'reward_std': 0.5410855412483215, 'completion_length': 656.2031326293945, 'kl': 0.06622314453125, 'epoch': 0.6}
 37%|███▋      | 187/500 [1:08:21<5:17:55, 60.95s/it] 38%|███▊      | 188/500 [1:09:38<5:41:50, 65.74s/it]                                                     {'loss': 0.0, 'grad_norm': 0.2958191276449862, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0104167014360428, 'reward': 1.0104167014360428, 'reward_std': 0.606646753847599, 'completion_length': 629.9167022705078, 'kl': 0.04388427734375, 'epoch': 0.6}
 38%|███▊      | 188/500 [1:09:38<5:41:50, 65.74s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 662, in sympy_expr_eq
    if sympy_str_eq(gold, pred):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 362, in sympy_str_eq
    raise ValueError("Can't evaluate nan or zoo")
ValueError: Can't evaluate nan or zoo
 38%|███▊      | 189/500 [1:10:35<5:27:00, 63.09s/it]                                                     {'loss': 0.0, 'grad_norm': 0.43553797536707767, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9843750298023224, 'reward': 0.9843750298023224, 'reward_std': 0.472278468310833, 'completion_length': 535.7500076293945, 'kl': 0.04998779296875, 'epoch': 0.6}
 38%|███▊      | 189/500 [1:10:35<5:27:00, 63.09s/it] 38%|███▊      | 190/500 [1:11:42<5:31:43, 64.20s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.6011034386099858, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2526041865348816, 'reward': 1.2526041865348816, 'reward_std': 0.5114558897912502, 'completion_length': 437.8958396911621, 'kl': 0.09869384765625, 'epoch': 0.61}
 38%|███▊      | 190/500 [1:11:42<5:31:43, 64.20s/it] 38%|███▊      | 191/500 [1:12:43<5:26:12, 63.34s/it]                                                     {'loss': 0.0, 'grad_norm': 0.30516411811440014, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8619792014360428, 'reward': 0.8619792014360428, 'reward_std': 0.5721681714057922, 'completion_length': 618.6406555175781, 'kl': 0.042083740234375, 'epoch': 0.61}
 38%|███▊      | 191/500 [1:12:43<5:26:12, 63.34s/it] 38%|███▊      | 192/500 [1:13:47<5:25:59, 63.51s/it]                                                     {'loss': 0.0, 'grad_norm': 1.6057464789627673, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2994791865348816, 'reward': 1.2994791865348816, 'reward_std': 0.5997451320290565, 'completion_length': 558.9531402587891, 'kl': 0.04376220703125, 'epoch': 0.61}
 38%|███▊      | 192/500 [1:13:47<5:25:59, 63.51s/it] 39%|███▊      | 193/500 [1:14:37<5:03:59, 59.41s/it]                                                     {'loss': 0.0, 'grad_norm': 0.31070482849964126, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.958333358168602, 'reward': 0.958333358168602, 'reward_std': 0.6242764666676521, 'completion_length': 617.5468902587891, 'kl': 0.04388427734375, 'epoch': 0.62}
 39%|███▊      | 193/500 [1:14:37<5:03:59, 59.41s/it] 39%|███▉      | 194/500 [1:15:38<5:06:05, 60.02s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.7221668791033125, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3567708730697632, 'reward': 1.3567708730697632, 'reward_std': 0.5850943326950073, 'completion_length': 417.8073043823242, 'kl': 0.17498779296875, 'epoch': 0.62}
 39%|███▉      | 194/500 [1:15:38<5:06:05, 60.02s/it] 39%|███▉      | 195/500 [1:16:12<4:24:44, 52.08s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.49345591940863703, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.992187537252903, 'reward': 0.992187537252903, 'reward_std': 0.6212565898895264, 'completion_length': 392.46875762939453, 'kl': 0.07867431640625, 'epoch': 0.62}
 39%|███▉      | 195/500 [1:16:12<4:24:44, 52.08s/it] 39%|███▉      | 196/500 [1:17:04<4:24:09, 52.14s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.4516674970050488, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.4296875298023224, 'reward': 1.4296875298023224, 'reward_std': 0.4726061597466469, 'completion_length': 518.0208587646484, 'kl': 0.29827880859375, 'epoch': 0.63}
 39%|███▉      | 196/500 [1:17:04<4:24:09, 52.14s/it] 39%|███▉      | 197/500 [1:18:04<4:34:36, 54.38s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.844141629301441, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7656250074505806, 'reward': 0.7656250074505806, 'reward_std': 0.6798174530267715, 'completion_length': 590.1979293823242, 'kl': 0.316986083984375, 'epoch': 0.63}
 39%|███▉      | 197/500 [1:18:04<4:34:36, 54.38s/it] 40%|███▉      | 198/500 [1:19:05<4:44:38, 56.55s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.5646325553328811, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1901041865348816, 'reward': 1.1901041865348816, 'reward_std': 0.5572642013430595, 'completion_length': 518.3645935058594, 'kl': 0.052642822265625, 'epoch': 0.63}
 40%|███▉      | 198/500 [1:19:05<4:44:38, 56.55s/it] 40%|███▉      | 199/500 [1:19:54<4:32:07, 54.24s/it]                                                     {'loss': 0.0, 'grad_norm': 0.25772441853023914, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0572917014360428, 'reward': 1.0572917014360428, 'reward_std': 0.46823057904839516, 'completion_length': 470.4271011352539, 'kl': 0.0482177734375, 'epoch': 0.64}
 40%|███▉      | 199/500 [1:19:54<4:32:07, 54.24s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Integer' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'NegativeOne' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Zero' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Integer' object has no attribute 'items'. Did you mean: 'atoms'?
 40%|████      | 200/500 [1:20:43<4:23:27, 52.69s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.1567984497438695, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0911458432674408, 'reward': 1.0911458432674408, 'reward_std': 0.3902667239308357, 'completion_length': 509.2760543823242, 'kl': 0.199188232421875, 'epoch': 0.64}
 40%|████      | 200/500 [1:20:43<4:23:27, 52.69s/it] 40%|████      | 201/500 [1:22:18<5:25:20, 65.29s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.5707513018777649, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.205729216337204, 'reward': 1.205729216337204, 'reward_std': 0.515981238335371, 'completion_length': 434.8333435058594, 'kl': 0.3150634765625, 'epoch': 0.64}
 40%|████      | 201/500 [1:22:18<5:25:20, 65.29s/it] 40%|████      | 202/500 [1:23:16<5:13:19, 63.08s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.2067887193481671, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1692708432674408, 'reward': 1.1692708432674408, 'reward_std': 0.264095738530159, 'completion_length': 506.6458511352539, 'kl': 0.071441650390625, 'epoch': 0.65}
 40%|████      | 202/500 [1:23:16<5:13:19, 63.08s/it] 41%|████      | 203/500 [1:23:51<4:30:45, 54.70s/it]                                                     {'loss': 0.0026, 'grad_norm': 2.2808734464326417, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0130208432674408, 'reward': 1.0130208432674408, 'reward_std': 0.31121085584163666, 'completion_length': 441.2239761352539, 'kl': 2.55377197265625, 'epoch': 0.65}
 41%|████      | 203/500 [1:23:51<4:30:45, 54.70s/it] 41%|████      | 204/500 [1:24:43<4:25:15, 53.77s/it]                                                     {'loss': 0.0126, 'grad_norm': 12.99962678478502, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.416666716337204, 'reward': 1.416666716337204, 'reward_std': 0.547457866370678, 'completion_length': 509.4271011352539, 'kl': 12.53643798828125, 'epoch': 0.65}
 41%|████      | 204/500 [1:24:43<4:25:15, 53.77s/it] 41%|████      | 205/500 [1:25:39<4:27:37, 54.43s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.4944013901669075, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.997395858168602, 'reward': 0.997395858168602, 'reward_std': 0.5657113939523697, 'completion_length': 482.13543701171875, 'kl': 0.07733154296875, 'epoch': 0.66}
 41%|████      | 205/500 [1:25:39<4:27:37, 54.43s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
 41%|████      | 206/500 [1:26:21<4:08:26, 50.70s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.340544638595445, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.315104216337204, 'reward': 1.315104216337204, 'reward_std': 0.32545354776084423, 'completion_length': 414.3958396911621, 'kl': 0.758880615234375, 'epoch': 0.66}
 41%|████      | 206/500 [1:26:21<4:08:26, 50.70s/it] 41%|████▏     | 207/500 [1:26:53<3:40:37, 45.18s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.6529420324825111, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.158854216337204, 'reward': 1.158854216337204, 'reward_std': 0.48513253778219223, 'completion_length': 468.8802185058594, 'kl': 0.4825439453125, 'epoch': 0.66}
 41%|████▏     | 207/500 [1:26:53<3:40:37, 45.18s/it] 42%|████▏     | 208/500 [1:27:46<3:50:58, 47.46s/it]                                                     {'loss': 2.3797, 'grad_norm': 9913.834746949495, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2682291865348816, 'reward': 1.2682291865348816, 'reward_std': 0.39391206949949265, 'completion_length': 445.3073043823242, 'kl': 2384.6515197753906, 'epoch': 0.67}
 42%|████▏     | 208/500 [1:27:46<3:50:58, 47.46s/it] 42%|████▏     | 209/500 [1:28:27<3:41:36, 45.69s/it]                                                     {'loss': 0.002, 'grad_norm': 2.7209657307857764, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3333333432674408, 'reward': 1.3333333432674408, 'reward_std': 0.5653872713446617, 'completion_length': 467.5573043823242, 'kl': 1.977508544921875, 'epoch': 0.67}
 42%|████▏     | 209/500 [1:28:27<3:41:36, 45.69s/it] 42%|████▏     | 210/500 [1:29:32<4:08:06, 51.33s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.3605212357695933, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.007812537252903, 'reward': 1.007812537252903, 'reward_std': 0.6591467708349228, 'completion_length': 610.1093826293945, 'kl': 0.3625946044921875, 'epoch': 0.67}
 42%|████▏     | 210/500 [1:29:32<4:08:06, 51.33s/it] 42%|████▏     | 211/500 [1:30:25<4:09:45, 51.85s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.9627148503259021, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8541666865348816, 'reward': 0.8541666865348816, 'reward_std': 0.6659152060747147, 'completion_length': 593.3177108764648, 'kl': 0.757354736328125, 'epoch': 0.68}
 42%|████▏     | 211/500 [1:30:25<4:09:45, 51.85s/it] 42%|████▏     | 212/500 [1:31:33<4:32:26, 56.76s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.36374292755155757, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.721354179084301, 'reward': 0.721354179084301, 'reward_std': 0.6034626588225365, 'completion_length': 669.8750152587891, 'kl': 0.2881011962890625, 'epoch': 0.68}
 42%|████▏     | 212/500 [1:31:33<4:32:26, 56.76s/it] 43%|████▎     | 213/500 [1:32:50<4:59:46, 62.67s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.7349998361843821, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8072916716337204, 'reward': 0.8072916716337204, 'reward_std': 0.6000937670469284, 'completion_length': 551.2083511352539, 'kl': 1.08026123046875, 'epoch': 0.68}
 43%|████▎     | 213/500 [1:32:50<4:59:46, 62.67s/it] 43%|████▎     | 214/500 [1:33:24<4:18:06, 54.15s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4854359236224887, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3072916865348816, 'reward': 1.3072916865348816, 'reward_std': 0.5062849596142769, 'completion_length': 429.6458511352539, 'kl': 0.03472900390625, 'epoch': 0.68}
 43%|████▎     | 214/500 [1:33:24<4:18:06, 54.15s/it] 43%|████▎     | 215/500 [1:34:39<4:47:20, 60.49s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.5923275768655896, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8750000298023224, 'reward': 0.8750000298023224, 'reward_std': 0.47512535378336906, 'completion_length': 587.1041870117188, 'kl': 0.41790771484375, 'epoch': 0.69}
 43%|████▎     | 215/500 [1:34:39<4:47:20, 60.49s/it] 43%|████▎     | 216/500 [1:35:42<4:49:34, 61.18s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.2787341609752108, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8307291865348816, 'reward': 0.8307291865348816, 'reward_std': 0.5556831583380699, 'completion_length': 596.4166793823242, 'kl': 0.76397705078125, 'epoch': 0.69}
 43%|████▎     | 216/500 [1:35:42<4:49:34, 61.18s/it] 43%|████▎     | 217/500 [1:36:25<4:22:30, 55.66s/it]                                                     {'loss': 0.0, 'grad_norm': 0.31432792692144224, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2552083730697632, 'reward': 1.2552083730697632, 'reward_std': 0.6491673737764359, 'completion_length': 505.9375305175781, 'kl': 0.0179901123046875, 'epoch': 0.69}
 43%|████▎     | 217/500 [1:36:25<4:22:30, 55.66s/it] 44%|████▎     | 218/500 [1:37:27<4:30:16, 57.51s/it]                                                     {'loss': 0.0, 'grad_norm': 0.47096335362094854, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1171875447034836, 'reward': 1.1171875447034836, 'reward_std': 0.650359146296978, 'completion_length': 480.15626525878906, 'kl': 0.028533935546875, 'epoch': 0.7}
 44%|████▎     | 218/500 [1:37:27<4:30:16, 57.51s/it] 44%|████▍     | 219/500 [1:38:16<4:17:55, 55.07s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.43835358613942266, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9140625298023224, 'reward': 0.9140625298023224, 'reward_std': 0.4603848233819008, 'completion_length': 556.4635467529297, 'kl': 0.232452392578125, 'epoch': 0.7}
 44%|████▍     | 219/500 [1:38:16<4:17:55, 55.07s/it] 44%|████▍     | 220/500 [1:39:08<4:13:21, 54.29s/it]                                                     {'loss': 0.0054, 'grad_norm': 2.55608986382273, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3776041865348816, 'reward': 1.3776041865348816, 'reward_std': 0.6695261597633362, 'completion_length': 477.7708511352539, 'kl': 5.4270477294921875, 'epoch': 0.7}
 44%|████▍     | 220/500 [1:39:08<4:13:21, 54.29s/it] 44%|████▍     | 221/500 [1:39:51<3:55:55, 50.74s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.7881897495444451, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2057292014360428, 'reward': 1.2057292014360428, 'reward_std': 0.7374365441501141, 'completion_length': 513.9948043823242, 'kl': 0.080291748046875, 'epoch': 0.71}
 44%|████▍     | 221/500 [1:39:51<3:55:55, 50.74s/it] 44%|████▍     | 222/500 [1:40:33<3:43:38, 48.27s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.7460218235699596, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2812500447034836, 'reward': 1.2812500447034836, 'reward_std': 0.5446020439267159, 'completion_length': 463.59896087646484, 'kl': 0.389251708984375, 'epoch': 0.71}
 44%|████▍     | 222/500 [1:40:33<3:43:38, 48.27s/it] 45%|████▍     | 223/500 [1:41:24<3:46:23, 49.04s/it]                                                     {'loss': 0.001, 'grad_norm': 0.9962533131266333, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2552083730697632, 'reward': 1.2552083730697632, 'reward_std': 0.4909577965736389, 'completion_length': 476.8385543823242, 'kl': 1.045654296875, 'epoch': 0.71}
 45%|████▍     | 223/500 [1:41:24<3:46:23, 49.04s/it] 45%|████▍     | 224/500 [1:42:07<3:36:42, 47.11s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.2599544464100875, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6093750149011612, 'reward': 0.6093750149011612, 'reward_std': 0.4404759109020233, 'completion_length': 546.8698120117188, 'kl': 0.115203857421875, 'epoch': 0.72}
 45%|████▍     | 224/500 [1:42:07<3:36:42, 47.11s/it] 45%|████▌     | 225/500 [1:42:44<3:22:57, 44.28s/it]                                                     {'loss': 0.0024, 'grad_norm': 1.636926269841513, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1041667014360428, 'reward': 1.1041667014360428, 'reward_std': 0.618942528963089, 'completion_length': 497.60938262939453, 'kl': 2.375244140625, 'epoch': 0.72}
 45%|████▌     | 225/500 [1:42:44<3:22:57, 44.28s/it] 45%|████▌     | 226/500 [1:43:23<3:14:37, 42.62s/it]                                                     {'loss': 0.0028, 'grad_norm': 1.0718132851052342, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9947917088866234, 'reward': 0.9947917088866234, 'reward_std': 0.7085513100028038, 'completion_length': 513.8750228881836, 'kl': 2.765777587890625, 'epoch': 0.72}
 45%|████▌     | 226/500 [1:43:23<3:14:37, 42.62s/it] 45%|████▌     | 227/500 [1:44:18<3:31:12, 46.42s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.096554673225052, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8723958432674408, 'reward': 0.8723958432674408, 'reward_std': 0.6278971135616302, 'completion_length': 618.2448196411133, 'kl': 0.23193359375, 'epoch': 0.73}
 45%|████▌     | 227/500 [1:44:18<3:31:12, 46.42s/it] 46%|████▌     | 228/500 [1:45:06<3:31:47, 46.72s/it]                                                     {'loss': 0.0018, 'grad_norm': 1.1587627220381058, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375000447034836, 'reward': 0.9375000447034836, 'reward_std': 0.36601492762565613, 'completion_length': 477.2812805175781, 'kl': 1.806610107421875, 'epoch': 0.73}
 46%|████▌     | 228/500 [1:45:06<3:31:47, 46.72s/it] 46%|████▌     | 229/500 [1:45:54<3:32:23, 47.03s/it]                                                     {'loss': 0.0022, 'grad_norm': 2.0808048782295634, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9479166865348816, 'reward': 0.9479166865348816, 'reward_std': 0.6474648416042328, 'completion_length': 505.0104446411133, 'kl': 2.155914306640625, 'epoch': 0.73}
 46%|████▌     | 229/500 [1:45:54<3:32:23, 47.03s/it] 46%|████▌     | 230/500 [1:46:43<3:34:38, 47.70s/it]                                                     {'loss': 0.0035, 'grad_norm': 1.7122699023276655, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7343750149011612, 'reward': 0.7343750149011612, 'reward_std': 0.6873424202203751, 'completion_length': 535.7500152587891, 'kl': 3.5301513671875, 'epoch': 0.74}
 46%|████▌     | 230/500 [1:46:43<3:34:38, 47.70s/it] 46%|████▌     | 231/500 [1:47:34<3:37:56, 48.61s/it]                                                     {'loss': 0.0101, 'grad_norm': 2.342381194433937, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.106770858168602, 'reward': 1.106770858168602, 'reward_std': 0.6831688582897186, 'completion_length': 426.6354331970215, 'kl': 10.109130859375, 'epoch': 0.74}
 46%|████▌     | 231/500 [1:47:34<3:37:56, 48.61s/it] 46%|████▋     | 232/500 [1:48:27<3:44:09, 50.18s/it]                                                     {'loss': 0.0071, 'grad_norm': 1.6101100427959585, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1223958432674408, 'reward': 1.1223958432674408, 'reward_std': 0.5806923136115074, 'completion_length': 456.80731201171875, 'kl': 7.122802734375, 'epoch': 0.74}
 46%|████▋     | 232/500 [1:48:28<3:44:09, 50.18s/it] 47%|████▋     | 233/500 [1:49:09<3:31:33, 47.54s/it]                                                     {'loss': 0.0059, 'grad_norm': 8.499830486425822, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.895833358168602, 'reward': 0.895833358168602, 'reward_std': 0.5157321244478226, 'completion_length': 485.38021087646484, 'kl': 5.893035888671875, 'epoch': 0.75}
 47%|████▋     | 233/500 [1:49:09<3:31:33, 47.54s/it] 47%|████▋     | 234/500 [1:49:57<3:31:41, 47.75s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.34076380371972553, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9765625149011612, 'reward': 0.9765625149011612, 'reward_std': 0.7040037661790848, 'completion_length': 465.5052261352539, 'kl': 0.157012939453125, 'epoch': 0.75}
 47%|████▋     | 234/500 [1:49:57<3:31:41, 47.75s/it] 47%|████▋     | 235/500 [1:50:44<3:29:30, 47.44s/it]                                                     {'loss': 0.0037, 'grad_norm': 0.8629779081981147, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9791666716337204, 'reward': 0.9791666716337204, 'reward_std': 0.5819069854915142, 'completion_length': 476.3958511352539, 'kl': 3.697357177734375, 'epoch': 0.75}
 47%|████▋     | 235/500 [1:50:44<3:29:30, 47.44s/it] 47%|████▋     | 236/500 [1:51:25<3:20:14, 45.51s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.6317106423951379, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2317708730697632, 'reward': 1.2317708730697632, 'reward_std': 0.53866096585989, 'completion_length': 477.2083511352539, 'kl': 0.24444580078125, 'epoch': 0.76}
 47%|████▋     | 236/500 [1:51:25<3:20:14, 45.51s/it] 47%|████▋     | 237/500 [1:52:18<3:29:43, 47.85s/it]                                                     {'loss': 0.003, 'grad_norm': 2.007622641387858, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.130208358168602, 'reward': 1.130208358168602, 'reward_std': 0.5101849548518658, 'completion_length': 483.14064025878906, 'kl': 3.05438232421875, 'epoch': 0.76}
 47%|████▋     | 237/500 [1:52:18<3:29:43, 47.85s/it]Timeout during comparison
 48%|████▊     | 238/500 [1:53:05<3:28:18, 47.70s/it]                                                     {'loss': 0.0005, 'grad_norm': 0.9651222986953617, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8072916939854622, 'reward': 0.8072916939854622, 'reward_std': 0.6396412551403046, 'completion_length': 463.7291717529297, 'kl': 0.531494140625, 'epoch': 0.76}
 48%|████▊     | 238/500 [1:53:06<3:28:18, 47.70s/it] 48%|████▊     | 239/500 [1:53:53<3:27:24, 47.68s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.2565901162595787, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0312500298023224, 'reward': 1.0312500298023224, 'reward_std': 0.33090417832136154, 'completion_length': 462.87500762939453, 'kl': 0.361175537109375, 'epoch': 0.76}
 48%|████▊     | 239/500 [1:53:53<3:27:24, 47.68s/it] 48%|████▊     | 240/500 [1:54:35<3:18:51, 45.89s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.5642419014865072, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1302083432674408, 'reward': 1.1302083432674408, 'reward_std': 0.5726198554039001, 'completion_length': 466.3958511352539, 'kl': 0.21844482421875, 'epoch': 0.77}
 48%|████▊     | 240/500 [1:54:35<3:18:51, 45.89s/it] 48%|████▊     | 241/500 [1:55:18<3:14:29, 45.06s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.5395480173317738, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9895833730697632, 'reward': 0.9895833730697632, 'reward_std': 0.29958227649331093, 'completion_length': 507.32814025878906, 'kl': 0.433868408203125, 'epoch': 0.77}
 48%|████▊     | 241/500 [1:55:18<3:14:29, 45.06s/it] 48%|████▊     | 242/500 [1:55:49<2:56:08, 40.96s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.45916701802855914, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2447917014360428, 'reward': 1.2447917014360428, 'reward_std': 0.2682960368692875, 'completion_length': 430.24481201171875, 'kl': 0.165252685546875, 'epoch': 0.77}
 48%|████▊     | 242/500 [1:55:49<2:56:08, 40.96s/it] 49%|████▊     | 243/500 [1:56:45<3:13:43, 45.23s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.9695975865626976, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0859375298023224, 'reward': 1.0859375298023224, 'reward_std': 0.6006777137517929, 'completion_length': 555.1771011352539, 'kl': 0.228546142578125, 'epoch': 0.78}
 49%|████▊     | 243/500 [1:56:45<3:13:43, 45.23s/it] 49%|████▉     | 244/500 [1:57:30<3:12:52, 45.20s/it]                                                     {'loss': 0.0011, 'grad_norm': 2.2715209400863534, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.197916716337204, 'reward': 1.197916716337204, 'reward_std': 0.45238321274518967, 'completion_length': 484.2708435058594, 'kl': 1.076416015625, 'epoch': 0.78}
 49%|████▉     | 244/500 [1:57:30<3:12:52, 45.20s/it] 49%|████▉     | 245/500 [1:58:09<3:04:03, 43.31s/it]                                                     {'loss': 0.0065, 'grad_norm': 1.6331549806174384, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.684895858168602, 'reward': 0.684895858168602, 'reward_std': 0.6935418844223022, 'completion_length': 531.2708435058594, 'kl': 6.42529296875, 'epoch': 0.78}
 49%|████▉     | 245/500 [1:58:09<3:04:03, 43.31s/it] 49%|████▉     | 246/500 [1:58:50<3:00:42, 42.69s/it]                                                     {'loss': 0.0031, 'grad_norm': 1.0495154054412155, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.846354179084301, 'reward': 0.846354179084301, 'reward_std': 0.5138493105769157, 'completion_length': 528.0677185058594, 'kl': 3.09991455078125, 'epoch': 0.79}
 49%|████▉     | 246/500 [1:58:50<3:00:42, 42.69s/it] 49%|████▉     | 247/500 [1:59:48<3:19:23, 47.29s/it]                                                     {'loss': 0.005, 'grad_norm': 1.073228617583104, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7760416865348816, 'reward': 0.7760416865348816, 'reward_std': 0.5778137147426605, 'completion_length': 577.2448120117188, 'kl': 4.999969482421875, 'epoch': 0.79}
 49%|████▉     | 247/500 [1:59:48<3:19:23, 47.29s/it] 50%|████▉     | 248/500 [2:00:36<3:19:14, 47.44s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.2989464812398115, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9010416865348816, 'reward': 0.9010416865348816, 'reward_std': 0.5513234548270702, 'completion_length': 476.14063262939453, 'kl': 0.625244140625, 'epoch': 0.79}
 50%|████▉     | 248/500 [2:00:36<3:19:14, 47.44s/it] 50%|████▉     | 249/500 [2:01:14<3:06:48, 44.66s/it]                                                     {'loss': 0.005, 'grad_norm': 1.78394516968284, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1562500298023224, 'reward': 1.1562500298023224, 'reward_std': 0.39029776118695736, 'completion_length': 435.2395935058594, 'kl': 4.9691162109375, 'epoch': 0.8}
 50%|████▉     | 249/500 [2:01:14<3:06:48, 44.66s/it] 50%|█████     | 250/500 [2:02:04<3:12:58, 46.31s/it]                                                     {'loss': 0.0022, 'grad_norm': 1.2609213528624779, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1692708730697632, 'reward': 1.1692708730697632, 'reward_std': 0.4251983165740967, 'completion_length': 497.35938262939453, 'kl': 2.23004150390625, 'epoch': 0.8}
 50%|█████     | 250/500 [2:02:04<3:12:58, 46.31s/it] 50%|█████     | 251/500 [2:02:58<3:22:08, 48.71s/it]                                                     {'loss': 0.0013, 'grad_norm': 2.0268269153499365, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1979167014360428, 'reward': 1.1979167014360428, 'reward_std': 0.8168628811836243, 'completion_length': 463.9010543823242, 'kl': 1.3126220703125, 'epoch': 0.8}
 50%|█████     | 251/500 [2:02:58<3:22:08, 48.71s/it] 50%|█████     | 252/500 [2:03:48<3:22:04, 48.89s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.6877120266510599, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9973958432674408, 'reward': 0.9973958432674408, 'reward_std': 0.632855199277401, 'completion_length': 471.8177185058594, 'kl': 0.80462646484375, 'epoch': 0.81}
 50%|█████     | 252/500 [2:03:48<3:22:04, 48.89s/it] 51%|█████     | 253/500 [2:04:28<3:10:16, 46.22s/it]                                                     {'loss': 0.0039, 'grad_norm': 1.2683348962204686, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0520833730697632, 'reward': 1.0520833730697632, 'reward_std': 0.47915275394916534, 'completion_length': 481.9583435058594, 'kl': 3.88446044921875, 'epoch': 0.81}
 51%|█████     | 253/500 [2:04:28<3:10:16, 46.22s/it] 51%|█████     | 254/500 [2:05:10<3:05:22, 45.21s/it]                                                     {'loss': 0.002, 'grad_norm': 1.3779016720852826, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0937500298023224, 'reward': 1.0937500298023224, 'reward_std': 0.5148123279213905, 'completion_length': 484.3645935058594, 'kl': 2.00567626953125, 'epoch': 0.81}
 51%|█████     | 254/500 [2:05:10<3:05:22, 45.21s/it] 51%|█████     | 255/500 [2:05:44<2:49:47, 41.58s/it]                                                     {'loss': 0.0035, 'grad_norm': 1.682463433413145, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0755208432674408, 'reward': 1.0755208432674408, 'reward_std': 0.4921211153268814, 'completion_length': 457.1198043823242, 'kl': 3.4903564453125, 'epoch': 0.82}
 51%|█████     | 255/500 [2:05:44<2:49:47, 41.58s/it] 51%|█████     | 256/500 [2:06:30<2:55:40, 43.20s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.5349185786661066, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0833333730697632, 'reward': 1.0833333730697632, 'reward_std': 0.46567830443382263, 'completion_length': 461.84375762939453, 'kl': 0.2979736328125, 'epoch': 0.82}
 51%|█████     | 256/500 [2:06:31<2:55:40, 43.20s/it] 51%|█████▏    | 257/500 [2:07:19<3:00:50, 44.65s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.674811000356128, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0781250298023224, 'reward': 1.0781250298023224, 'reward_std': 0.5534658879041672, 'completion_length': 495.0677261352539, 'kl': 1.651123046875, 'epoch': 0.82}
 51%|█████▏    | 257/500 [2:07:19<3:00:50, 44.65s/it] 52%|█████▏    | 258/500 [2:08:05<3:02:23, 45.22s/it]                                                     {'loss': 0.0048, 'grad_norm': 1.0391239408193549, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1458333879709244, 'reward': 1.1458333879709244, 'reward_std': 0.5398834720253944, 'completion_length': 424.11458587646484, 'kl': 4.83544921875, 'epoch': 0.83}
 52%|█████▏    | 258/500 [2:08:05<3:02:23, 45.22s/it] 52%|█████▏    | 259/500 [2:08:52<3:03:43, 45.74s/it]                                                     {'loss': 0.0189, 'grad_norm': 2.3503796052021246, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8541666716337204, 'reward': 0.8541666716337204, 'reward_std': 0.5321980826556683, 'completion_length': 525.0416870117188, 'kl': 18.967926025390625, 'epoch': 0.83}
 52%|█████▏    | 259/500 [2:08:52<3:03:43, 45.74s/it] 52%|█████▏    | 260/500 [2:09:26<2:48:51, 42.21s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.8954751451795011, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8776041939854622, 'reward': 0.8776041939854622, 'reward_std': 0.6946014165878296, 'completion_length': 497.79689025878906, 'kl': 0.3499908447265625, 'epoch': 0.83}
 52%|█████▏    | 260/500 [2:09:26<2:48:51, 42.21s/it] 52%|█████▏    | 261/500 [2:10:26<3:09:04, 47.47s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.085929245903811, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7500000149011612, 'reward': 0.7500000149011612, 'reward_std': 0.9151885360479355, 'completion_length': 592.6458435058594, 'kl': 0.179229736328125, 'epoch': 0.84}
 52%|█████▏    | 261/500 [2:10:26<3:09:04, 47.47s/it] 52%|█████▏    | 262/500 [2:11:05<2:58:44, 45.06s/it]                                                     {'loss': 0.0009, 'grad_norm': 0.6150758081978068, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1536458879709244, 'reward': 1.1536458879709244, 'reward_std': 0.5642010569572449, 'completion_length': 472.12501525878906, 'kl': 0.87115478515625, 'epoch': 0.84}
 52%|█████▏    | 262/500 [2:11:05<2:58:44, 45.06s/it] 53%|█████▎    | 263/500 [2:11:45<2:51:14, 43.35s/it]                                                     {'loss': 0.0188, 'grad_norm': 3.4742965254225067, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1744792014360428, 'reward': 1.1744792014360428, 'reward_std': 0.574172779917717, 'completion_length': 415.09376525878906, 'kl': 18.76171875, 'epoch': 0.84}
 53%|█████▎    | 263/500 [2:11:45<2:51:14, 43.35s/it] 53%|█████▎    | 264/500 [2:12:27<2:49:38, 43.13s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.3016707427486501, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2031250298023224, 'reward': 1.2031250298023224, 'reward_std': 0.7151513397693634, 'completion_length': 591.6354293823242, 'kl': 0.094635009765625, 'epoch': 0.84}
 53%|█████▎    | 264/500 [2:12:27<2:49:38, 43.13s/it] 53%|█████▎    | 265/500 [2:13:00<2:36:58, 40.08s/it]                                                     {'loss': 0.0011, 'grad_norm': 1.301790825598137, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2734375447034836, 'reward': 1.2734375447034836, 'reward_std': 0.5743320286273956, 'completion_length': 408.9479217529297, 'kl': 1.05926513671875, 'epoch': 0.85}
 53%|█████▎    | 265/500 [2:13:00<2:36:58, 40.08s/it] 53%|█████▎    | 266/500 [2:13:41<2:37:17, 40.33s/it]                                                     {'loss': 0.0, 'grad_norm': 0.3010089520094843, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.255208358168602, 'reward': 1.255208358168602, 'reward_std': 0.5902919992804527, 'completion_length': 466.1198043823242, 'kl': 0.02264404296875, 'epoch': 0.85}
 53%|█████▎    | 266/500 [2:13:41<2:37:17, 40.33s/it] 53%|█████▎    | 267/500 [2:14:22<2:36:59, 40.43s/it]                                                     {'loss': 0.0016, 'grad_norm': 0.5204384039824236, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8619791939854622, 'reward': 0.8619791939854622, 'reward_std': 0.5444472879171371, 'completion_length': 510.26564025878906, 'kl': 1.5941162109375, 'epoch': 0.85}
 53%|█████▎    | 267/500 [2:14:22<2:36:59, 40.43s/it] 54%|█████▎    | 268/500 [2:15:05<2:40:06, 41.41s/it]                                                     {'loss': 0.0008, 'grad_norm': 0.9539962066879235, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0286458656191826, 'reward': 1.0286458656191826, 'reward_std': 0.3187940940260887, 'completion_length': 407.56250762939453, 'kl': 0.821075439453125, 'epoch': 0.86}
 54%|█████▎    | 268/500 [2:15:05<2:40:06, 41.41s/it] 54%|█████▍    | 269/500 [2:15:54<2:48:01, 43.64s/it]                                                     {'loss': 0.001, 'grad_norm': 1.275657155698294, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.028645858168602, 'reward': 1.028645858168602, 'reward_std': 0.6489603370428085, 'completion_length': 580.5260620117188, 'kl': 0.9467010498046875, 'epoch': 0.86}
 54%|█████▍    | 269/500 [2:15:54<2:48:01, 43.64s/it] 54%|█████▍    | 270/500 [2:16:28<2:35:20, 40.53s/it]                                                     {'loss': 0.0059, 'grad_norm': 1.3663910026418322, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2890625149011612, 'reward': 1.2890625149011612, 'reward_std': 0.5135375186800957, 'completion_length': 458.8489685058594, 'kl': 5.8549957275390625, 'epoch': 0.86}
 54%|█████▍    | 270/500 [2:16:28<2:35:20, 40.53s/it] 54%|█████▍    | 271/500 [2:17:24<2:53:18, 45.41s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.5037031247552021, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9921875447034836, 'reward': 0.9921875447034836, 'reward_std': 0.7518028020858765, 'completion_length': 484.8333511352539, 'kl': 0.1624755859375, 'epoch': 0.87}
 54%|█████▍    | 271/500 [2:17:24<2:53:18, 45.41s/it] 54%|█████▍    | 272/500 [2:18:04<2:46:19, 43.77s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.2043871032066655, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.416666716337204, 'reward': 1.416666716337204, 'reward_std': 0.5760185495018959, 'completion_length': 376.6198043823242, 'kl': 0.29498291015625, 'epoch': 0.87}
 54%|█████▍    | 272/500 [2:18:04<2:46:19, 43.77s/it] 55%|█████▍    | 273/500 [2:18:40<2:36:59, 41.50s/it]                                                     {'loss': 0.0, 'grad_norm': 0.26662525972463674, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2031250298023224, 'reward': 1.2031250298023224, 'reward_std': 0.5348522886633873, 'completion_length': 528.8125152587891, 'kl': 0.0218963623046875, 'epoch': 0.87}
 55%|█████▍    | 273/500 [2:18:40<2:36:59, 41.50s/it] 55%|█████▍    | 274/500 [2:19:29<2:44:06, 43.57s/it]                                                     {'loss': 0.0033, 'grad_norm': 1.3769532818525663, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9062500149011612, 'reward': 0.9062500149011612, 'reward_std': 0.622943826019764, 'completion_length': 607.6510467529297, 'kl': 3.289581298828125, 'epoch': 0.88}
 55%|█████▍    | 274/500 [2:19:29<2:44:06, 43.57s/it] 55%|█████▌    | 275/500 [2:20:11<2:42:01, 43.21s/it]                                                     {'loss': 0.0014, 'grad_norm': 1.3252150305702863, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1276041865348816, 'reward': 1.1276041865348816, 'reward_std': 0.5937575921416283, 'completion_length': 477.8177185058594, 'kl': 1.386962890625, 'epoch': 0.88}
 55%|█████▌    | 275/500 [2:20:11<2:42:01, 43.21s/it] 55%|█████▌    | 276/500 [2:20:57<2:44:13, 43.99s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.1468832109421416, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8958333507180214, 'reward': 0.8958333507180214, 'reward_std': 0.7322247922420502, 'completion_length': 482.4479217529297, 'kl': 0.678253173828125, 'epoch': 0.88}
 55%|█████▌    | 276/500 [2:20:57<2:44:13, 43.99s/it] 55%|█████▌    | 277/500 [2:21:28<2:28:57, 40.08s/it]                                                     {'loss': 0.0015, 'grad_norm': 1.9859566376574165, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.973958358168602, 'reward': 0.973958358168602, 'reward_std': 0.6550348252058029, 'completion_length': 513.3698120117188, 'kl': 1.501953125, 'epoch': 0.89}
 55%|█████▌    | 277/500 [2:21:28<2:28:57, 40.08s/it] 56%|█████▌    | 278/500 [2:22:05<2:24:26, 39.04s/it]                                                     {'loss': 0.0, 'grad_norm': 0.18545660383687207, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.244791716337204, 'reward': 1.244791716337204, 'reward_std': 0.4456770922988653, 'completion_length': 495.3489685058594, 'kl': 0.02154541015625, 'epoch': 0.89}
 56%|█████▌    | 278/500 [2:22:05<2:24:26, 39.04s/it] 56%|█████▌    | 279/500 [2:22:44<2:23:57, 39.08s/it]                                                     {'loss': 0.0023, 'grad_norm': 0.6664929769971993, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3307291865348816, 'reward': 1.3307291865348816, 'reward_std': 0.5029655769467354, 'completion_length': 394.1458511352539, 'kl': 2.2724151611328125, 'epoch': 0.89}
 56%|█████▌    | 279/500 [2:22:44<2:23:57, 39.08s/it] 56%|█████▌    | 280/500 [2:23:18<2:17:52, 37.60s/it]                                                     {'loss': 0.0007, 'grad_norm': 0.7281659467300987, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9531250298023224, 'reward': 0.9531250298023224, 'reward_std': 0.4218849763274193, 'completion_length': 435.2864761352539, 'kl': 0.7191162109375, 'epoch': 0.9}
 56%|█████▌    | 280/500 [2:23:18<2:17:52, 37.60s/it] 56%|█████▌    | 281/500 [2:23:55<2:16:51, 37.49s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.117722969109166, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.966145858168602, 'reward': 0.966145858168602, 'reward_std': 0.5985846072435379, 'completion_length': 476.17189025878906, 'kl': 0.43682861328125, 'epoch': 0.9}
 56%|█████▌    | 281/500 [2:23:55<2:16:51, 37.49s/it] 56%|█████▋    | 282/500 [2:24:44<2:28:37, 40.91s/it]                                                     {'loss': 0.0007, 'grad_norm': 1.294130316127476, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8020833507180214, 'reward': 0.8020833507180214, 'reward_std': 0.6256546005606651, 'completion_length': 600.7968902587891, 'kl': 0.722747802734375, 'epoch': 0.9}
 56%|█████▋    | 282/500 [2:24:44<2:28:37, 40.91s/it] 57%|█████▋    | 283/500 [2:25:19<2:21:33, 39.14s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.1870746934368996, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.3046875298023224, 'reward': 1.3046875298023224, 'reward_std': 0.4158623293042183, 'completion_length': 441.9010543823242, 'kl': 0.330352783203125, 'epoch': 0.91}
 57%|█████▋    | 283/500 [2:25:19<2:21:33, 39.14s/it] 57%|█████▋    | 284/500 [2:26:04<2:27:25, 40.95s/it]                                                     {'loss': 0.0006, 'grad_norm': 0.977107014674417, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9244792014360428, 'reward': 0.9244792014360428, 'reward_std': 0.6242693290114403, 'completion_length': 490.7291946411133, 'kl': 0.56536865234375, 'epoch': 0.91}
 57%|█████▋    | 284/500 [2:26:04<2:27:25, 40.95s/it] 57%|█████▋    | 285/500 [2:26:41<2:22:25, 39.75s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.2696175427330614, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1223958730697632, 'reward': 1.1223958730697632, 'reward_std': 0.3936419263482094, 'completion_length': 455.5104293823242, 'kl': 0.053466796875, 'epoch': 0.91}
 57%|█████▋    | 285/500 [2:26:41<2:22:25, 39.75s/it] 57%|█████▋    | 286/500 [2:27:16<2:16:56, 38.40s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.4392710416773395, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.2057292014360428, 'reward': 1.2057292014360428, 'reward_std': 0.5119556188583374, 'completion_length': 408.92188262939453, 'kl': 0.065643310546875, 'epoch': 0.92}
 57%|█████▋    | 286/500 [2:27:16<2:16:56, 38.40s/it] 57%|█████▋    | 287/500 [2:27:49<2:10:15, 36.69s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8026140292967768, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.502604216337204, 'reward': 1.502604216337204, 'reward_std': 0.598365068435669, 'completion_length': 431.2135543823242, 'kl': 0.08001708984375, 'epoch': 0.92}
 57%|█████▋    | 287/500 [2:27:49<2:10:15, 36.69s/it] 58%|█████▊    | 288/500 [2:28:30<2:14:32, 38.08s/it]                                                     {'loss': 0.0013, 'grad_norm': 1.8403245089096152, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125000298023224, 'reward': 0.8125000298023224, 'reward_std': 0.5807622820138931, 'completion_length': 489.00000762939453, 'kl': 1.29376220703125, 'epoch': 0.92}
 58%|█████▊    | 288/500 [2:28:30<2:14:32, 38.08s/it] 58%|█████▊    | 289/500 [2:29:19<2:24:47, 41.18s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.6874532707186398, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.174479216337204, 'reward': 1.174479216337204, 'reward_std': 0.6662801206111908, 'completion_length': 570.3489837646484, 'kl': 0.388885498046875, 'epoch': 0.92}
 58%|█████▊    | 289/500 [2:29:19<2:24:47, 41.18s/it] 58%|█████▊    | 290/500 [2:29:58<2:21:45, 40.50s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.0743680372333015, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9843750447034836, 'reward': 0.9843750447034836, 'reward_std': 0.7252949923276901, 'completion_length': 477.4010467529297, 'kl': 0.448822021484375, 'epoch': 0.93}
 58%|█████▊    | 290/500 [2:29:58<2:21:45, 40.50s/it] 58%|█████▊    | 291/500 [2:30:48<2:31:21, 43.45s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.3954176669322002, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.088541716337204, 'reward': 1.088541716337204, 'reward_std': 0.5784703940153122, 'completion_length': 581.8229293823242, 'kl': 0.082305908203125, 'epoch': 0.93}
 58%|█████▊    | 291/500 [2:30:48<2:31:21, 43.45s/it] 58%|█████▊    | 292/500 [2:31:28<2:27:10, 42.45s/it]                                                     {'loss': 0.0021, 'grad_norm': 1.112880799371538, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1171875447034836, 'reward': 1.1171875447034836, 'reward_std': 0.7351412922143936, 'completion_length': 468.82293701171875, 'kl': 2.14215087890625, 'epoch': 0.93}
 58%|█████▊    | 292/500 [2:31:28<2:27:10, 42.45s/it] 59%|█████▊    | 293/500 [2:32:11<2:26:43, 42.53s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9132244914956541, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8151042014360428, 'reward': 0.8151042014360428, 'reward_std': 0.8038139343261719, 'completion_length': 541.9843978881836, 'kl': 0.4255523681640625, 'epoch': 0.94}
 59%|█████▊    | 293/500 [2:32:11<2:26:43, 42.53s/it] 59%|█████▉    | 294/500 [2:32:55<2:27:41, 43.02s/it]                                                     {'loss': 0.0006, 'grad_norm': 1.6608760376048937, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.7942708681803197, 'reward': 0.7942708681803197, 'reward_std': 0.6520186811685562, 'completion_length': 506.2708435058594, 'kl': 0.64825439453125, 'epoch': 0.94}
 59%|█████▉    | 294/500 [2:32:55<2:27:41, 43.02s/it] 59%|█████▉    | 295/500 [2:33:32<2:20:17, 41.06s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.7644171732121734, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.841145858168602, 'reward': 0.841145858168602, 'reward_std': 0.7343204021453857, 'completion_length': 436.5364685058594, 'kl': 0.1871337890625, 'epoch': 0.94}
 59%|█████▉    | 295/500 [2:33:32<2:20:17, 41.06s/it] 59%|█████▉    | 296/500 [2:34:03<2:09:58, 38.23s/it]                                                     {'loss': 0.0015, 'grad_norm': 1.246669106162316, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0052083730697632, 'reward': 1.0052083730697632, 'reward_std': 0.5014147907495499, 'completion_length': 412.03125762939453, 'kl': 1.5362548828125, 'epoch': 0.95}
 59%|█████▉    | 296/500 [2:34:03<2:09:58, 38.23s/it] 59%|█████▉    | 297/500 [2:34:32<2:00:00, 35.47s/it]                                                     {'loss': 0.0009, 'grad_norm': 1.115694753987963, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1770833730697632, 'reward': 1.1770833730697632, 'reward_std': 0.6794633567333221, 'completion_length': 429.4322967529297, 'kl': 0.8817138671875, 'epoch': 0.95}
 59%|█████▉    | 297/500 [2:34:32<2:00:00, 35.47s/it] 60%|█████▉    | 298/500 [2:35:13<2:04:50, 37.08s/it]                                                     {'loss': 0.0007, 'grad_norm': 2.0736358987519576, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.731770858168602, 'reward': 0.731770858168602, 'reward_std': 0.6301349103450775, 'completion_length': 479.76563262939453, 'kl': 0.66033935546875, 'epoch': 0.95}
 60%|█████▉    | 298/500 [2:35:13<2:04:50, 37.08s/it] 60%|█████▉    | 299/500 [2:35:40<1:54:26, 34.16s/it]                                                     {'loss': 0.0, 'grad_norm': 0.3164752380392253, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.294270858168602, 'reward': 1.294270858168602, 'reward_std': 0.5251378417015076, 'completion_length': 418.4739761352539, 'kl': 0.028472900390625, 'epoch': 0.96}
 60%|█████▉    | 299/500 [2:35:40<1:54:26, 34.16s/it] 60%|██████    | 300/500 [2:36:07<1:45:52, 31.76s/it]                                                     {'loss': 0.0003, 'grad_norm': 0.611724651779771, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8880208681803197, 'reward': 0.8880208681803197, 'reward_std': 0.48842421919107437, 'completion_length': 440.21875762939453, 'kl': 0.29779052734375, 'epoch': 0.96}
 60%|██████    | 300/500 [2:36:07<1:45:52, 31.76s/it] 60%|██████    | 301/500 [2:37:19<2:25:44, 43.94s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.182914010849187, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.1093750447034836, 'reward': 1.1093750447034836, 'reward_std': 0.6144953966140747, 'completion_length': 397.81250762939453, 'kl': 0.108642578125, 'epoch': 0.96}
 60%|██████    | 301/500 [2:37:19<2:25:44, 43.94s/it] 60%|██████    | 302/500 [2:37:44<2:05:59, 38.18s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.1505365725966603, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4739583383779973, 'reward': 0.4739583383779973, 'reward_std': 0.5005969777703285, 'completion_length': 350.1458435058594, 'kl': 0.369293212890625, 'epoch': 0.97}
 60%|██████    | 302/500 [2:37:44<2:05:59, 38.18s/it] 61%|██████    | 303/500 [2:38:10<1:53:44, 34.64s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.8901299277348458, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46354169212281704, 'reward': 0.46354169212281704, 'reward_std': 0.6769523024559021, 'completion_length': 353.8802185058594, 'kl': 0.7720947265625, 'epoch': 0.97}
 61%|██████    | 303/500 [2:38:10<1:53:44, 34.64s/it] 61%|██████    | 304/500 [2:38:32<1:40:35, 30.79s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.3101899305319253, 'learning_rate': 1e-06, 'rewards/reward_correct': -0.4583333395421505, 'reward': -0.4583333395421505, 'reward_std': 0.6243487298488617, 'completion_length': 286.859375, 'kl': 0.3212890625, 'epoch': 0.97}
 61%|██████    | 304/500 [2:38:32<1:40:35, 30.79s/it] 61%|██████    | 305/500 [2:38:50<1:27:26, 26.91s/it]                                                     {'loss': 0.0003, 'grad_norm': 1.5787163970599158, 'learning_rate': 1e-06, 'rewards/reward_correct': -0.6458333432674408, 'reward': -0.6458333432674408, 'reward_std': 0.8654637187719345, 'completion_length': 247.18750762939453, 'kl': 0.25048828125, 'epoch': 0.98}
 61%|██████    | 305/500 [2:38:50<1:27:26, 26.91s/it] 61%|██████    | 306/500 [2:39:09<1:19:12, 24.50s/it]                                                     {'loss': 0.0002, 'grad_norm': 0.607779666894523, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.0338541716337204, 'reward': 0.0338541716337204, 'reward_std': 0.8846249878406525, 'completion_length': 253.55730056762695, 'kl': 0.1551513671875, 'epoch': 0.98}
 61%|██████    | 306/500 [2:39:09<1:19:12, 24.50s/it] 61%|██████▏   | 307/500 [2:39:26<1:11:41, 22.29s/it]                                                     {'loss': 0.0004, 'grad_norm': 0.9679769827731312, 'learning_rate': 1e-06, 'rewards/reward_correct': -0.963541692122817, 'reward': -0.963541692122817, 'reward_std': 0.6131048500537872, 'completion_length': 224.8020896911621, 'kl': 0.3646240234375, 'epoch': 0.98}
 61%|██████▏   | 307/500 [2:39:26<1:11:41, 22.29s/it] 62%|██████▏   | 308/500 [2:39:44<1:07:50, 21.20s/it]                                                     {'loss': 0.0009, 'grad_norm': 2.2702452748494077, 'learning_rate': 1e-06, 'rewards/reward_correct': -0.5703125223517418, 'reward': -0.5703125223517418, 'reward_std': 0.7508414387702942, 'completion_length': 260.7552185058594, 'kl': 0.87347412109375, 'epoch': 0.99}
 62%|██████▏   | 308/500 [2:39:44<1:07:50, 21.20s/it] 62%|██████▏   | 309/500 [2:40:02<1:04:03, 20.12s/it]                                                     {'loss': 0.0008, 'grad_norm': 1.818946464611867, 'learning_rate': 1e-06, 'rewards/reward_correct': -0.007812505587935448, 'reward': -0.007812505587935448, 'reward_std': 0.9375176131725311, 'completion_length': 286.7291793823242, 'kl': 0.78009033203125, 'epoch': 0.99}
 62%|██████▏   | 309/500 [2:40:02<1:04:03, 20.12s/it] 62%|██████▏   | 310/500 [2:40:22<1:03:15, 19.98s/it]                                                     {'loss': 0.0013, 'grad_norm': 1.4918065297210303, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.02604167046956718, 'reward': 0.02604167046956718, 'reward_std': 0.7713372111320496, 'completion_length': 310.9739685058594, 'kl': 1.289703369140625, 'epoch': 0.99}
 62%|██████▏   | 310/500 [2:40:22<1:03:15, 19.98s/it] 62%|██████▏   | 311/500 [2:40:45<1:05:47, 20.89s/it]                                                     {'loss': 0.0017, 'grad_norm': 2.4149955042336804, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5312500149011612, 'reward': 0.5312500149011612, 'reward_std': 0.5731586217880249, 'completion_length': 323.85938262939453, 'kl': 1.726806640625, 'epoch': 1.0}
 62%|██████▏   | 311/500 [2:40:45<1:05:47, 20.89s/it] 62%|██████▏   | 312/500 [2:41:11<1:10:10, 22.40s/it]                                                     {'loss': 0.0004, 'grad_norm': 1.007796233941905, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.276041679084301, 'reward': 0.276041679084301, 'reward_std': 0.6739414408802986, 'completion_length': 410.0885543823242, 'kl': 0.413909912109375, 'epoch': 1.0}
 62%|██████▏   | 312/500 [2:41:11<1:10:10, 22.40s/it] 63%|██████▎   | 313/500 [2:41:49<1:25:13, 27.35s/it]                                                     {'loss': 0.0002, 'grad_norm': 1.0084202604983368, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.47395834637184936, 'reward': 0.47395834637184936, 'reward_std': 0.5633077522118887, 'completion_length': 424.9652913411458, 'kl': 0.15592447916666666, 'epoch': 1.0}
 63%|██████▎   | 313/500 [2:41:49<1:25:13, 27.35s/it][rank3]: Traceback (most recent call last):
[rank3]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank3]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank3]:     return inner_training_loop(
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank3]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank3]:     inputs = self._prepare_inputs(inputs)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank3]:     self._move_model_to_vllm()
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank3]:     with unwrap_model_for_generation(
[rank3]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank3]:     next(self.gen)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank3]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank3]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank3]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank3]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank3]:     free_param(param)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank3]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank3]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank2]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank2]:     return inner_training_loop(
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank2]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank2]:     inputs = self._prepare_inputs(inputs)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank2]:     self._move_model_to_vllm()
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank2]:     with unwrap_model_for_generation(
[rank2]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank2]:     next(self.gen)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank2]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank2]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank2]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank2]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank2]:     free_param(param)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank2]:     ret_val = func(*args, **kwargs)
[rank2]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank2]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank2]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank5]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank5]:     return inner_training_loop(
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank5]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank5]:     inputs = self._prepare_inputs(inputs)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank5]:     self._move_model_to_vllm()
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank5]:     with unwrap_model_for_generation(
[rank5]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank5]:     next(self.gen)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank5]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank5]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank5]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank5]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank5]:     ret_val = func(*args, **kwargs)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank5]:     free_param(param)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank5]:     ret_val = func(*args, **kwargs)
[rank5]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank5]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank5]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank1]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank1]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank1]:     inputs = self._prepare_inputs(inputs)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank1]:     self._move_model_to_vllm()
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank1]:     with unwrap_model_for_generation(
[rank1]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank1]:     next(self.gen)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank1]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank1]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank1]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank1]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank1]:     free_param(param)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank1]:     ret_val = func(*args, **kwargs)
[rank1]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank1]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank1]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank4]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank4]:     return inner_training_loop(
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank4]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank4]:     inputs = self._prepare_inputs(inputs)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank4]:     self._move_model_to_vllm()
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank4]:     with unwrap_model_for_generation(
[rank4]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank4]:     next(self.gen)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank4]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank4]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank4]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank4]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank4]:     ret_val = func(*args, **kwargs)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank4]:     free_param(param)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank4]:     ret_val = func(*args, **kwargs)
[rank4]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank4]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank4]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
Traceback (most recent call last):
  File "/home/VRL/trainer_qwen.py", line 193, in <module>
    trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
  File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
  File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
    self._move_model_to_vllm()
  File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
    with unwrap_model_for_generation(
  File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
    next(self.gen)
  File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
    with deepspeed.zero.GatheredParameters(model.parameters()):
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
    self.params[0].partition(param_list=self.params, has_been_updated=False)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
    self._partition(param_list, has_been_updated=has_been_updated)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
    self._partition_param(param, has_been_updated=has_been_updated)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
    free_param(param)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
    assert not param.ds_active_sub_modules, param.ds_summary()
AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/VRL/trainer_qwen.py", line 193, in <module>
[rank0]:     trainer.train(resume_from_checkpoint=training_args.checkpoint_path if training_args.resume_from_checkpoint else False)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py", line 3692, in training_step
[rank0]:     inputs = self._prepare_inputs(inputs)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 538, in _prepare_inputs
[rank0]:     self._move_model_to_vllm()
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 490, in _move_model_to_vllm
[rank0]:     with unwrap_model_for_generation(
[rank0]:   File "/home/VRL/env/lib/python3.10/contextlib.py", line 142, in __exit__
[rank0]:     next(self.gen)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/trl/models/utils.py", line 210, in unwrap_model_for_generation
[rank0]:     with deepspeed.zero.GatheredParameters(model.parameters()):
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 2241, in __exit__
[rank0]:     self.params[0].partition(param_list=self.params, has_been_updated=False)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1386, in partition
[rank0]:     self._partition(param_list, has_been_updated=has_been_updated)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1535, in _partition
[rank0]:     self._partition_param(param, has_been_updated=has_been_updated)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 1568, in _partition_param
[rank0]:     free_param(param)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 284, in free_param
[rank0]:     assert not param.ds_active_sub_modules, param.ds_summary()
[rank0]: AssertionError: {'id': 435, 'status': 'AVAILABLE', 'numel': 311164928, 'ds_numel': 311164928, 'shape': (151936, 2048), 'ds_shape': (151936, 2048), 'requires_grad': True, 'grad_shape': None, 'persist': False, 'active_sub_modules': {476}, 'ds_tensor.shape': torch.Size([51860822])}
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mqwen3b-large[0m at: [34mhttps://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface/runs/e8rm9eku[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250319_145602-e8rm9eku/logs[0m
W0319 17:38:00.702000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 8623 closing signal SIGTERM
W0319 17:38:00.720000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 8624 closing signal SIGTERM
W0319 17:38:00.724000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 8625 closing signal SIGTERM
W0319 17:38:00.728000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 8627 closing signal SIGTERM
W0319 17:38:00.731000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 8628 closing signal SIGTERM
E0319 17:38:02.506000 8494 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 8626) of binary: /home/VRL/env/bin/python
Traceback (most recent call last):
  File "/home/VRL/env/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/VRL/env/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/home/VRL/env/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/home/VRL/env/lib/python3.10/site-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/home/VRL/env/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/VRL/env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/VRL/env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
trainer_qwen.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-19_17:38:00
  host      : ef5e7d5b7da5
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 8626)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
