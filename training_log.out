[2025-03-17 11:43:48,014] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
W0317 11:44:20.040000 5793 site-packages/torch/distributed/run.py:793] 
W0317 11:44:20.040000 5793 site-packages/torch/distributed/run.py:793] *****************************************
W0317 11:44:20.040000 5793 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0317 11:44:20.040000 5793 site-packages/torch/distributed/run.py:793] *****************************************
[2025-03-17 11:46:02,523] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-17 11:46:02,702] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 03-17 11:46:57 __init__.py:190] Automatically detected platform cuda.
INFO 03-17 11:46:57 __init__.py:190] Automatically detected platform cuda.
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-full', run_name='qwen3b-full', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=4, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=800, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-full/checkpoint-400', resume_from_checkpoint=True)MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-full', run_name='qwen3b-full', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=4, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=800, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False, checkpoint_path='outputs/qwen2.5-3b-grpo-full/checkpoint-400', resume_from_checkpoint=True)

Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:50<00:50, 50.37s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:50<00:50, 50.39s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:04<00:00, 29.17s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:04<00:00, 32.35s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:04<00:00, 29.18s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:04<00:00, 32.36s/it]
[2025-03-17 11:48:13,018] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 11:48:13,036] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-17 11:48:13,036] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-17 11:48:13,324] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-17 11:48:13,652] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-17 11:48:15,082] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.22s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.21s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s]
INFO 03-17 11:50:10 config.py:542] This model supports multiple tasks: {'score', 'classify', 'reward', 'embed', 'generate'}. Defaulting to 'generate'.
INFO 03-17 11:50:10 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='outputs/qwen2.5-3b-grpo-full/checkpoint-400', speculative_config=None, tokenizer='outputs/qwen2.5-3b-grpo-full/checkpoint-400', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:2, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=outputs/qwen2.5-3b-grpo-full/checkpoint-400, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 03-17 11:50:16 cuda.py:230] Using Flash Attention backend.
INFO 03-17 11:50:16 model_runner.py:1110] Starting to load model outputs/qwen2.5-3b-grpo-full/checkpoint-400...
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  5.81it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.13it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.36it/s]

INFO 03-17 11:50:18 model_runner.py:1115] Loading model weights took 0.0000 GB
INFO 03-17 11:50:19 worker.py:267] Memory profiling takes 1.49 seconds
INFO 03-17 11:50:19 worker.py:267] the current vLLM instance can use total_gpu_memory (79.21GiB) x gpu_memory_utilization (0.90) = 71.29GiB
INFO 03-17 11:50:19 worker.py:267] model weights take 0.00GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.00GiB; the rest of the memory reserved for KV Cache is 71.29GiB.
INFO 03-17 11:50:19 executor_base.py:110] # CUDA blocks: 129775, # CPU blocks: 7281
INFO 03-17 11:50:19 executor_base.py:115] Maximum concurrency for 5000 tokens per request: 415.28x
INFO 03-17 11:50:21 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|‚ñé         | 1/35 [00:00<00:15,  2.20it/s]Capturing CUDA graph shapes:   6%|‚ñå         | 2/35 [00:00<00:12,  2.56it/s]Capturing CUDA graph shapes:   9%|‚ñä         | 3/35 [00:01<00:11,  2.71it/s]Capturing CUDA graph shapes:  11%|‚ñà‚ñè        | 4/35 [00:01<00:11,  2.80it/s]Capturing CUDA graph shapes:  14%|‚ñà‚ñç        | 5/35 [00:01<00:11,  2.71it/s]Capturing CUDA graph shapes:  17%|‚ñà‚ñã        | 6/35 [00:02<00:10,  2.81it/s]Capturing CUDA graph shapes:  20%|‚ñà‚ñà        | 7/35 [00:02<00:09,  2.89it/s]Capturing CUDA graph shapes:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:02<00:09,  2.83it/s]Capturing CUDA graph shapes:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:03<00:09,  2.80it/s]Capturing CUDA graph shapes:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:03<00:09,  2.76it/s]Capturing CUDA graph shapes:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:03<00:08,  2.85it/s]Capturing CUDA graph shapes:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:04<00:07,  2.90it/s]Capturing CUDA graph shapes:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:04<00:07,  2.93it/s]Capturing CUDA graph shapes:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:04<00:07,  2.89it/s]Capturing CUDA graph shapes:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:05<00:06,  2.88it/s]Capturing CUDA graph shapes:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:05<00:07,  2.65it/s]Capturing CUDA graph shapes:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:06<00:07,  2.42it/s]Capturing CUDA graph shapes:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:06<00:06,  2.45it/s]Capturing CUDA graph shapes:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:07<00:06,  2.35it/s]Capturing CUDA graph shapes:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:07<00:06,  2.46it/s]Capturing CUDA graph shapes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:07<00:05,  2.52it/s]Capturing CUDA graph shapes:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:08<00:05,  2.55it/s]Capturing CUDA graph shapes:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:08<00:04,  2.58it/s]Capturing CUDA graph shapes:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:09<00:04,  2.52it/s]Capturing CUDA graph shapes:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:09<00:04,  2.50it/s]Capturing CUDA graph shapes:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:09<00:03,  2.65it/s]Capturing CUDA graph shapes:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:10<00:02,  2.77it/s]Capturing CUDA graph shapes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:10<00:02,  2.76it/s]Capturing CUDA graph shapes:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:10<00:02,  2.70it/s]Capturing CUDA graph shapes:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:11<00:01,  2.58it/s]Capturing CUDA graph shapes:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:11<00:01,  2.44it/s]Capturing CUDA graph shapes:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:12<00:01,  2.45it/s]Capturing CUDA graph shapes:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:12<00:00,  2.28it/s]Capturing CUDA graph shapes:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:13<00:00,  2.38it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:13<00:00,  2.31it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:13<00:00,  2.59it/s]
INFO 03-17 11:50:35 model_runner.py:1562] Graph capturing finished in 14 secs, took 0.00 GiB
INFO 03-17 11:50:35 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 17.24 seconds
[2025-03-17 11:50:39,099] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown
[2025-03-17 11:50:39,100] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-17 11:50:39,101] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-17 11:50:39,124] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-03-17 11:50:39,126] [INFO] [logging.py:129:log_dist] [Rank 0] Creating ZeRO Offload
[2025-03-17 11:50:39,866] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-03-17 11:50:39,868] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.96 GB         Max_CA 3 GB 
[2025-03-17 11:50:39,872] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 70.11 GB, percent = 3.5%
Parameter Offload: Total persistent parameters: 241664 in 181 params
[2025-03-17 11:50:40,654] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-03-17 11:50:40,656] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.96 GB         Max_CA 3 GB 
[2025-03-17 11:50:40,657] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 67.72 GB, percent = 3.4%
[2025-03-17 11:50:40,659] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-03-17 11:50:40,659] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-17 11:50:40,660] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-17 11:50:40,660] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-03-17 11:50:40,661] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-03-17 11:50:40,661] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-17 11:50:40,662] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-03-17 11:50:40,662] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-03-17 11:50:40,663] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-03-17 11:50:40,664] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-03-17 11:50:40,664] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-03-17 11:50:40,665] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x715c843b9840>
[2025-03-17 11:50:40,665] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-03-17 11:50:40,666] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-17 11:50:40,666] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-03-17 11:50:40,667] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-03-17 11:50:40,667] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-17 11:50:40,668] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-03-17 11:50:40,668] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-03-17 11:50:40,669] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-03-17 11:50:40,670] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-03-17 11:50:40,670] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-03-17 11:50:40,671] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-03-17 11:50:40,671] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-17 11:50:40,672] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-17 11:50:40,673] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-03-17 11:50:40,673] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-03-17 11:50:40,674] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-03-17 11:50:40,674] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-03-17 11:50:40,674] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-03-17 11:50:40,675] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-03-17 11:50:40,676] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-17 11:50:40,676] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-03-17 11:50:40,677] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-03-17 11:50:40,677] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-03-17 11:50:40,678] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-03-17 11:50:40,679] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-03-17 11:50:40,679] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 4
[2025-03-17 11:50:40,680] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.1
[2025-03-17 11:50:40,680] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-03-17 11:50:40,681] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-03-17 11:50:40,682] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-17 11:50:40,682] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-03-17 11:50:40,683] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-03-17 11:50:40,683] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-03-17 11:50:40,684] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-03-17 11:50:40,685] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-03-17 11:50:40,685] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-03-17 11:50:40,686] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-17 11:50:40,687] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-17 11:50:40,687] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-03-17 11:50:40,688] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-03-17 11:50:40,689] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-03-17 11:50:40,689] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-17 11:50:40,690] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-03-17 11:50:40,691] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-03-17 11:50:40,691] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-03-17 11:50:40,692] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-03-17 11:50:40,693] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-03-17 11:50:40,693] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-17 11:50:40,694] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-03-17 11:50:40,694] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-03-17 11:50:40,695] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-03-17 11:50:40,695] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-03-17 11:50:40,696] [INFO] [config.py:1003:print]   train_batch_size ............. 32
[2025-03-17 11:50:40,696] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  4
[2025-03-17 11:50:40,696] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-03-17 11:50:40,697] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-03-17 11:50:40,698] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-03-17 11:50:40,698] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-03-17 11:50:40,699] [INFO] [config.py:1003:print]   world_size ................... 2
[2025-03-17 11:50:40,699] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-03-17 11:50:40,700] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-03-17 11:50:40,701] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-03-17 11:50:40,702] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-17 11:50:40,702] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-03-17 11:50:40,703] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 4, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 0.1, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 4.194304e+06, 
    "zero_optimization.stage3_param_persistence_threshold": 2.048000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 3.774874e+06
}
Parameter Offload: Total persistent parameters: 241664 in 181 params
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  partition = torch.load(path, map_location=map_location)
/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ss13750 (ss13750-new-york-university-abu-dhabi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/VRL/wandb/run-20250317_115156-zh21d7sb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qwen3b-full
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface
wandb: üöÄ View run at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface/runs/zh21d7sb
  0%|          | 0/800 [00:00<?, ?it/s]/home/VRL/env/lib/python3.10/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 401/800 [00:26<00:26, 15.25it/s]                                                 {'loss': 0.0, 'grad_norm': 1.1022739786145026, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.2925042062997818, 'completion_length': 428.59375, 'kl': 0.0, 'epoch': 0.21}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 401/800 [00:26<00:26, 15.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 401/800 [00:38<00:26, 15.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 402/800 [00:53<01:04,  6.21it/s]                                                 {'loss': 0.0, 'grad_norm': 7.400889179875328e-05, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'completion_length': 530.3125, 'kl': 8.499622344970703e-05, 'epoch': 0.21}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 402/800 [00:53<01:04,  6.21it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 403/800 [01:17<01:52,  3.53it/s]                                                 {'loss': 0.0, 'grad_norm': 0.2962669474051672, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.0883883461356163, 'completion_length': 383.875, 'kl': 7.048249244689941e-05, 'epoch': 0.21}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 403/800 [01:17<01:52,  3.53it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 404/800 [01:45<03:10,  2.08it/s]                                                 {'loss': 0.0, 'grad_norm': 0.2168897850504435, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 760.5625, 'kl': 5.257129669189453e-05, 'epoch': 0.22}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 404/800 [01:45<03:10,  2.08it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 405/800 [02:05<04:27,  1.47it/s]                                                 {'loss': 0.0, 'grad_norm': 0.00015839883316031683, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 449.84375, 'kl': 8.615851402282715e-05, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 405/800 [02:05<04:27,  1.47it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 406/800 [02:30<06:43,  1.02s/it]                                                 {'loss': 0.0, 'grad_norm': 0.7847938316204355, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.4261348247528076, 'completion_length': 591.78125, 'kl': 9.781122207641602e-05, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 406/800 [02:30<06:43,  1.02s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 407/800 [02:47<08:46,  1.34s/it]                                                 {'loss': 0.0, 'grad_norm': 0.00020054197337181096, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 403.875, 'kl': 0.00014770030975341797, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 407/800 [02:47<08:46,  1.34s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 408/800 [03:07<12:12,  1.87s/it]                                                 {'loss': 0.0, 'grad_norm': 0.37704304503649155, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.2041158601641655, 'completion_length': 607.46875, 'kl': 0.00023472309112548828, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 408/800 [03:07<12:12,  1.87s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 409/800 [03:43<20:35,  3.16s/it]                                                 {'loss': 0.0, 'grad_norm': 0.21091784150464543, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.13363061845302582, 'completion_length': 845.84375, 'kl': 0.00012612342834472656, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 409/800 [03:43<20:35,  3.16s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 410/800 [03:58<24:21,  3.75s/it]                                                 {'loss': 0.0, 'grad_norm': 0.6993903100908299, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2177756354212761, 'completion_length': 370.8125, 'kl': 0.0002334117889404297, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 410/800 [03:58<24:21,  3.75s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 411/800 [04:12<28:54,  4.46s/it]                                                 {'loss': 0.0, 'grad_norm': 0.5119291113308153, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.1293872892856598, 'completion_length': 405.28125, 'kl': 0.0003733634948730469, 'epoch': 0.22}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 411/800 [04:12<28:54,  4.46s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 412/800 [04:53<49:52,  7.71s/it]                                                 {'loss': 0.0, 'grad_norm': 0.49784801579185944, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3471629247069359, 'completion_length': 884.5, 'kl': 0.0002288818359375, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 412/800 [04:53<49:52,  7.71s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 413/800 [05:35<1:15:16, 11.67s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4543320879853442, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.1293872892856598, 'completion_length': 1027.34375, 'kl': 0.00027060508728027344, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 413/800 [05:35<1:15:16, 11.67s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 414/800 [06:06<1:32:06, 14.32s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4588368650911786, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.13363061845302582, 'completion_length': 804.15625, 'kl': 0.0003638267517089844, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 414/800 [06:06<1:32:06, 14.32s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 415/800 [06:29<1:40:52, 15.72s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5958392610368017, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2314550280570984, 'completion_length': 551.0, 'kl': 0.0005731582641601562, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 415/800 [06:29<1:40:52, 15.72s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 416/800 [07:10<2:12:31, 20.71s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5258312338759806, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.249358132481575, 'completion_length': 836.59375, 'kl': 0.0005917549133300781, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 416/800 [07:10<2:12:31, 20.71s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 417/800 [07:51<2:39:10, 24.94s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0003461773062355478, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'completion_length': 796.0625, 'kl': 0.0005807876586914062, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 417/800 [07:51<2:39:10, 24.94s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 418/800 [08:11<2:30:56, 23.71s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5496648568262246, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2177756354212761, 'completion_length': 462.46875, 'kl': 0.0006799697875976562, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 418/800 [08:11<2:30:56, 23.71s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 419/800 [08:28<2:21:01, 22.21s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9466181254015836, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3335031494498253, 'completion_length': 391.21875, 'kl': 0.0008955001831054688, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 419/800 [08:28<2:21:01, 22.21s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [09:07<2:48:10, 26.55s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6532780089217952, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.24511480331420898, 'completion_length': 548.15625, 'kl': 0.0007429122924804688, 'epoch': 0.22}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 420/800 [09:07<2:48:10, 26.55s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 421/800 [09:53<3:21:46, 31.94s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6420584048000857, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.1293872892856598, 'completion_length': 716.90625, 'kl': 0.000743865966796875, 'epoch': 0.22}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 421/800 [09:53<3:21:46, 31.94s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 422/800 [10:13<3:00:02, 28.58s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6615299654289475, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.2587745785713196, 'completion_length': 489.5, 'kl': 0.0010471343994140625, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 422/800 [10:13<3:00:02, 28.58s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 423/800 [10:32<2:42:34, 25.87s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7362155146354246, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.2041158601641655, 'completion_length': 405.21875, 'kl': 0.0014019012451171875, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 423/800 [10:32<2:42:34, 25.87s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 424/800 [10:53<2:33:36, 24.51s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7270355307348939, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.24511480331420898, 'completion_length': 525.8125, 'kl': 0.0013332366943359375, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 424/800 [10:53<2:33:36, 24.51s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 425/800 [11:17<2:32:14, 24.36s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7450034559576637, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.2925042062997818, 'completion_length': 632.8125, 'kl': 0.0009765625, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 425/800 [11:17<2:32:14, 24.36s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 426/800 [11:48<2:43:03, 26.16s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7842443433070043, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3377464786171913, 'completion_length': 654.40625, 'kl': 0.0009555816650390625, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 426/800 [11:48<2:43:03, 26.16s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 427/800 [12:07<2:30:05, 24.14s/it]                                                   {'loss': 0.0, 'grad_norm': 0.41429144215827723, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.0883883461356163, 'completion_length': 494.0, 'kl': 0.0012493133544921875, 'epoch': 0.23}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 427/800 [12:07<2:30:05, 24.14s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 428/800 [12:48<3:00:15, 29.08s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3503980514026198, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1157275140285492, 'completion_length': 1049.78125, 'kl': 0.0015106201171875, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 428/800 [12:48<3:00:15, 29.08s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 429/800 [13:36<3:35:33, 34.86s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6556388822207395, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.1157275140285492, 'completion_length': 1036.125, 'kl': 0.0014438629150390625, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 429/800 [13:36<3:35:33, 34.86s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 278, in sympy_solve_and_compare
    return all(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 282, in <genexpr>
    for (g_k, g_v), (p_k, p_v) in zip(sorted(g.items()), sorted(p.items()))
AttributeError: 'Rational' object has no attribute 'items'. Did you mean: 'atoms'?
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 430/800 [14:12<3:36:00, 35.03s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8177660528471674, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3608423173427582, 'completion_length': 633.6875, 'kl': 0.0016021728515625, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 430/800 [14:12<3:36:00, 35.03s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 431/800 [14:34<3:11:27, 31.13s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6261054547734156, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 506.40625, 'kl': 0.0010080337524414062, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 431/800 [14:34<3:11:27, 31.13s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 432/800 [15:10<3:20:08, 32.63s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6508012074378913, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2587745785713196, 'completion_length': 568.0, 'kl': 0.00138092041015625, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 432/800 [15:10<3:20:08, 32.63s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 433/800 [15:27<2:50:42, 27.91s/it]                                                   {'loss': 0.0, 'grad_norm': 0.00083648753871795, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0, 'rewards/reward_correct_and_format': 0.0, 'reward': 1.0, 'reward_std': 0.0, 'completion_length': 363.21875, 'kl': 0.001922607421875, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 433/800 [15:27<2:50:42, 27.91s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 434/800 [15:51<2:42:49, 26.69s/it]                                                   {'loss': 0.0, 'grad_norm': 0.20118482010296893, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.1293872892856598, 'completion_length': 643.96875, 'kl': 0.0021486282348632812, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 434/800 [15:51<2:42:49, 26.69s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 435/800 [16:50<3:40:56, 36.32s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5483796163579073, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.2630179077386856, 'completion_length': 962.21875, 'kl': 0.000988006591796875, 'epoch': 0.23}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 435/800 [16:50<3:40:56, 36.32s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 436/800 [17:50<4:23:44, 43.47s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5649949667862016, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.3335031494498253, 'completion_length': 1129.3125, 'kl': 0.0017766952514648438, 'epoch': 0.23}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 436/800 [17:50<4:23:44, 43.47s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 437/800 [18:10<3:40:17, 36.41s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7144467930206128, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.2587745785713196, 'completion_length': 522.59375, 'kl': 0.0020599365234375, 'epoch': 0.23}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 437/800 [18:10<3:40:17, 36.41s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 438/800 [18:36<3:21:26, 33.39s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7927935553165609, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.4765502139925957, 'completion_length': 675.8125, 'kl': 0.002071380615234375, 'epoch': 0.23}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 438/800 [18:36<3:21:26, 33.39s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 439/800 [18:53<2:50:59, 28.42s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8145675302922869, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3335031494498253, 'completion_length': 465.28125, 'kl': 0.00319671630859375, 'epoch': 0.23}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 439/800 [18:53<2:50:59, 28.42s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [20:03<4:05:13, 40.87s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5173034712432625, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.24511480331420898, 'completion_length': 1050.59375, 'kl': 0.002071380615234375, 'epoch': 0.23}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 440/800 [20:03<4:05:13, 40.87s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 441/800 [20:39<3:56:43, 39.56s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5045249595434919, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2177756354212761, 'completion_length': 707.96875, 'kl': 0.002475738525390625, 'epoch': 0.24}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 441/800 [20:39<3:56:43, 39.56s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 442/800 [21:00<3:22:18, 33.91s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9368238415376917, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.3535533845424652, 'completion_length': 557.59375, 'kl': 0.0030364990234375, 'epoch': 0.24}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 442/800 [21:00<3:22:18, 33.91s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 443/800 [21:22<3:01:04, 30.43s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6907750653759948, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 680.09375, 'kl': 0.002246856689453125, 'epoch': 0.24}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 443/800 [21:22<3:01:04, 30.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 444/800 [21:37<2:32:42, 25.74s/it]                                                   {'loss': 0.0, 'grad_norm': 0.506013359696412, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1157275140285492, 'completion_length': 426.46875, 'kl': 0.003017425537109375, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 444/800 [21:37<2:32:42, 25.74s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 445/800 [22:09<2:43:28, 27.63s/it]                                                   {'loss': 0.0, 'grad_norm': 0.40361004444246307, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 742.09375, 'kl': 0.003173828125, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 445/800 [22:09<2:43:28, 27.63s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 446/800 [22:45<2:56:44, 29.96s/it]                                                   {'loss': 0.0, 'grad_norm': 0.415026112612147, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.0883883461356163, 'completion_length': 791.4375, 'kl': 0.002452850341796875, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 446/800 [22:45<2:56:44, 29.96s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 447/800 [23:04<2:37:47, 26.82s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8401493056473591, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.4628904387354851, 'completion_length': 517.375, 'kl': 0.002735137939453125, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 447/800 [23:04<2:37:47, 26.82s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 448/800 [23:58<3:24:20, 34.83s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6651780744609682, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.3061639815568924, 'completion_length': 964.90625, 'kl': 0.0028476715087890625, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 448/800 [23:58<3:24:20, 34.83s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 449/800 [24:14<2:50:41, 29.18s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5609374458135771, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 414.4375, 'kl': 0.00463104248046875, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 449/800 [24:14<2:50:41, 29.18s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 450/800 [24:41<2:47:10, 28.66s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7259385420093528, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2041158601641655, 'completion_length': 617.03125, 'kl': 0.0030364990234375, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 450/800 [24:41<2:47:10, 28.66s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 451/800 [26:22<4:52:46, 50.33s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5915775076867463, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1767766922712326, 'completion_length': 505.90625, 'kl': 0.00331878662109375, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 451/800 [26:22<4:52:46, 50.33s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 452/800 [26:51<4:14:42, 43.91s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4777830265299211, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 649.59375, 'kl': 0.00278472900390625, 'epoch': 0.24}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 452/800 [26:51<4:14:42, 43.91s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 453/800 [27:14<3:37:58, 37.69s/it]                                                   {'loss': 0.0, 'grad_norm': 0.37215792356325184, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.1293872892856598, 'completion_length': 601.84375, 'kl': 0.0032176971435546875, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 453/800 [27:14<3:37:58, 37.69s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 454/800 [27:29<2:58:25, 30.94s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2777770128826086, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.1293872892856598, 'completion_length': 368.625, 'kl': 0.004611968994140625, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 454/800 [27:29<2:58:25, 30.94s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 455/800 [27:47<2:34:45, 26.92s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5574227570792456, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 427.875, 'kl': 0.004169464111328125, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 455/800 [27:47<2:34:45, 26.92s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 456/800 [28:25<2:53:40, 30.29s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8958308464111829, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.2041158601641655, 'completion_length': 787.90625, 'kl': 0.0032329559326171875, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 456/800 [28:25<2:53:40, 30.29s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 457/800 [28:39<2:25:42, 25.49s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9182696431809694, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.24511480331420898, 'completion_length': 340.9375, 'kl': 0.0024509429931640625, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 457/800 [28:39<2:25:42, 25.49s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 458/800 [29:14<2:41:53, 28.40s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9105335615756743, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3471629247069359, 'completion_length': 603.875, 'kl': 0.0035066604614257812, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 458/800 [29:14<2:41:53, 28.40s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 459/800 [29:43<2:42:06, 28.52s/it]                                                   {'loss': 0.0, 'grad_norm': 0.46263860884080743, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.2041158601641655, 'completion_length': 711.3125, 'kl': 0.002735137939453125, 'epoch': 0.24}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 459/800 [29:43<2:42:06, 28.52s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [30:12<2:41:51, 28.56s/it]                                                   {'loss': 0.0, 'grad_norm': 0.48788318949359943, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.1767766922712326, 'completion_length': 602.46875, 'kl': 0.004276275634765625, 'epoch': 0.25}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 460/800 [30:12<2:41:51, 28.56s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 461/800 [30:34<2:30:02, 26.56s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5561204611965462, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.24511480331420898, 'completion_length': 687.65625, 'kl': 0.003662109375, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 461/800 [30:34<2:30:02, 26.56s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 462/800 [30:48<2:09:07, 22.92s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0010227745226455882, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 416.71875, 'kl': 0.003620147705078125, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 462/800 [30:48<2:09:07, 22.92s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 463/800 [31:24<2:30:03, 26.72s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6934357611901396, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3808925524353981, 'completion_length': 766.4375, 'kl': 0.0041294097900390625, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 463/800 [31:24<2:30:03, 26.72s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 464/800 [31:54<2:36:22, 27.92s/it]                                                   {'loss': 0.0, 'grad_norm': 0.555200278320868, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.0883883461356163, 'completion_length': 748.09375, 'kl': 0.00487518310546875, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 464/800 [31:54<2:36:22, 27.92s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 465/800 [32:20<2:31:46, 27.18s/it]                                                   {'loss': 0.0, 'grad_norm': 0.38702564286530255, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.1157275140285492, 'completion_length': 551.78125, 'kl': 0.003505706787109375, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 465/800 [32:20<2:31:46, 27.18s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 466/800 [32:48<2:33:00, 27.49s/it]                                                   {'loss': 0.0, 'grad_norm': 0.518525720185555, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.2041158601641655, 'completion_length': 690.625, 'kl': 0.004596710205078125, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 466/800 [32:48<2:33:00, 27.49s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 467/800 [33:42<3:17:02, 35.50s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7945114907002708, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.4218914955854416, 'completion_length': 731.25, 'kl': 0.00397491455078125, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 467/800 [33:42<3:17:02, 35.50s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 468/800 [33:55<2:38:24, 28.63s/it]                                                   {'loss': 0.0, 'grad_norm': 0.48684385731909036, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 365.0625, 'kl': 0.005889892578125, 'epoch': 0.25}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 468/800 [33:55<2:38:24, 28.63s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 469/800 [34:14<2:21:37, 25.67s/it]                                                   {'loss': 0.0, 'grad_norm': 0.00177826765117218, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'completion_length': 566.03125, 'kl': 0.00566864013671875, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 469/800 [34:14<2:21:37, 25.67s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 470/800 [34:30<2:05:50, 22.88s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9737877704055302, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3335031494498253, 'completion_length': 392.1875, 'kl': 0.00472259521484375, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 470/800 [34:30<2:05:50, 22.88s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 471/800 [34:57<2:12:58, 24.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5861788293538264, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.3377464786171913, 'completion_length': 727.125, 'kl': 0.00521087646484375, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 471/800 [34:57<2:12:58, 24.25s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 472/800 [35:10<1:53:58, 20.85s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4353863327267452, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.0883883461356163, 'completion_length': 347.15625, 'kl': 0.00469207763671875, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 472/800 [35:10<1:53:58, 20.85s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 473/800 [35:33<1:55:50, 21.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0012137118813470313, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.0, 'completion_length': 720.34375, 'kl': 0.004970550537109375, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 473/800 [35:33<1:55:50, 21.25s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 474/800 [35:50<1:50:00, 20.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6005622147605335, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 527.625, 'kl': 0.00739288330078125, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 474/800 [35:50<1:50:00, 20.25s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 475/800 [36:24<2:11:50, 24.34s/it]                                                   {'loss': 0.0, 'grad_norm': 0.20320858417306079, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.0883883461356163, 'completion_length': 842.96875, 'kl': 0.00553131103515625, 'epoch': 0.25}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 475/800 [36:24<2:11:50, 24.34s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 476/800 [36:39<1:55:31, 21.39s/it]                                                   {'loss': 0.0, 'grad_norm': 0.002286807734215489, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 394.8125, 'kl': 0.00817108154296875, 'epoch': 0.25}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 476/800 [36:39<1:55:31, 21.39s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 477/800 [37:17<2:21:31, 26.29s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5657392243383538, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.2651650384068489, 'completion_length': 897.9375, 'kl': 0.003490447998046875, 'epoch': 0.25}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 477/800 [37:17<2:21:31, 26.29s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 478/800 [37:32<2:03:34, 23.03s/it]                                                   {'loss': 0.0, 'grad_norm': 0.46358924991226225, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.249358132481575, 'completion_length': 510.53125, 'kl': 0.00702667236328125, 'epoch': 0.25}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 478/800 [37:32<2:03:34, 23.03s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 479/800 [38:09<2:25:17, 27.16s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3842727355627808, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.1767766922712326, 'completion_length': 984.4375, 'kl': 0.00386810302734375, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 479/800 [38:09<2:25:17, 27.16s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [38:29<2:14:10, 25.16s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0011988038048996385, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'completion_length': 581.96875, 'kl': 0.004730224609375, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 480/800 [38:29<2:14:10, 25.16s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 481/800 [38:40<1:50:35, 20.80s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6648615749551305, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 302.3125, 'kl': 0.00852203369140625, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 481/800 [38:40<1:50:35, 20.80s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 482/800 [38:58<1:45:19, 19.87s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4157232674199122, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.24511480331420898, 'completion_length': 520.1875, 'kl': 0.006618499755859375, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 482/800 [38:58<1:45:19, 19.87s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 483/800 [39:12<1:36:56, 18.35s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5677085537353747, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1157275140285492, 'completion_length': 413.375, 'kl': 0.009552001953125, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 483/800 [39:12<1:36:56, 18.35s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 484/800 [39:30<1:34:52, 18.01s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2924003459403364, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 520.21875, 'kl': 0.008167266845703125, 'epoch': 0.26}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 484/800 [39:30<1:34:52, 18.01s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 485/800 [40:02<1:57:20, 22.35s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4068097990351904, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.2041158601641655, 'completion_length': 534.5, 'kl': 0.01111602783203125, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 485/800 [40:02<1:57:20, 22.35s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 486/800 [40:22<1:53:17, 21.65s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8863086284255358, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3471629247069359, 'completion_length': 499.75, 'kl': 0.01058197021484375, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 486/800 [40:22<1:53:17, 21.65s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 487/800 [40:48<1:59:15, 22.86s/it]                                                   {'loss': 0.0, 'grad_norm': 0.1957898076991233, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 801.0625, 'kl': 0.006107330322265625, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 487/800 [40:48<1:59:15, 22.86s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 488/800 [40:59<1:39:51, 19.20s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0019237148348136785, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0, 'rewards/reward_correct_and_format': 0.0, 'reward': 1.0, 'reward_std': 0.0, 'completion_length': 272.34375, 'kl': 0.00728607177734375, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 488/800 [40:59<1:39:51, 19.20s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 489/800 [41:18<1:40:26, 19.38s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4549247551944381, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1767766922712326, 'completion_length': 539.90625, 'kl': 0.004566192626953125, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 489/800 [41:18<1:40:26, 19.38s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 490/800 [41:33<1:32:53, 17.98s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5838603630967566, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1157275140285492, 'completion_length': 395.125, 'kl': 0.007537841796875, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 490/800 [41:33<1:32:53, 17.98s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 491/800 [41:46<1:24:44, 16.46s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5632462638707756, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 312.96875, 'kl': 0.01016998291015625, 'epoch': 0.26}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 491/800 [41:46<1:24:44, 16.46s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 492/800 [42:19<1:50:08, 21.46s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4251749870935877, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.249358132481575, 'completion_length': 585.6875, 'kl': 0.005157470703125, 'epoch': 0.26}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 492/800 [42:19<1:50:08, 21.46s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 493/800 [42:35<1:41:43, 19.88s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8817271431433488, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.3335031494498253, 'completion_length': 505.75, 'kl': 0.00701141357421875, 'epoch': 0.26}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 493/800 [42:35<1:41:43, 19.88s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 494/800 [42:56<1:42:45, 20.15s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7354995764649155, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.4629100561141968, 'completion_length': 596.40625, 'kl': 0.00565338134765625, 'epoch': 0.26}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 494/800 [42:56<1:42:45, 20.15s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 495/800 [43:17<1:43:10, 20.30s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7354743634605181, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.2177756354212761, 'completion_length': 580.71875, 'kl': 0.00502777099609375, 'epoch': 0.26}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 495/800 [43:17<1:43:10, 20.30s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 496/800 [43:47<1:57:27, 23.18s/it]                                                   {'loss': 0.0, 'grad_norm': 0.608517591703918, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 580.53125, 'kl': 0.005218505859375, 'epoch': 0.26}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 496/800 [43:47<1:57:27, 23.18s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 497/800 [44:26<2:20:58, 27.91s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8565644367963698, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.4765502139925957, 'completion_length': 746.34375, 'kl': 0.003566741943359375, 'epoch': 0.27}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 497/800 [44:26<2:20:58, 27.91s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 498/800 [44:41<2:01:31, 24.14s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8626027812270433, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.3198433741927147, 'completion_length': 400.9375, 'kl': 0.005584716796875, 'epoch': 0.27}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 498/800 [44:41<2:01:31, 24.14s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 499/800 [45:18<2:20:24, 27.99s/it]                                                   {'loss': 0.0, 'grad_norm': 0.536131664885286, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2177756354212761, 'completion_length': 795.40625, 'kl': 0.006938934326171875, 'epoch': 0.27}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 499/800 [45:18<2:20:24, 27.99s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [45:55<2:34:03, 30.81s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8230135862529927, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.4765502139925957, 'completion_length': 773.96875, 'kl': 0.00481414794921875, 'epoch': 0.27}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 500/800 [45:55<2:34:03, 30.81s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 501/800 [47:41<4:25:19, 53.24s/it]                                                   {'loss': 0.0, 'grad_norm': 0.41403704923288603, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 617.84375, 'kl': 0.0048980712890625, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 501/800 [47:41<4:25:19, 53.24s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 502/800 [48:01<3:34:57, 43.28s/it]                                                   {'loss': 0.0, 'grad_norm': 1.037425219578949, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.3061639815568924, 'completion_length': 518.625, 'kl': 0.007354736328125, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 502/800 [48:01<3:34:57, 43.28s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 503/800 [48:19<2:57:01, 35.76s/it]                                                   {'loss': 0.0, 'grad_norm': 1.085469924800288, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2177756354212761, 'completion_length': 477.40625, 'kl': 0.0069732666015625, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 503/800 [48:19<2:57:01, 35.76s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 504/800 [49:05<3:11:51, 38.89s/it]                                                   {'loss': 0.0, 'grad_norm': 0.43156464735603145, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.1157275140285492, 'completion_length': 1075.65625, 'kl': 0.00655364990234375, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 504/800 [49:05<3:11:51, 38.89s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 505/800 [49:27<2:46:38, 33.89s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8972121028696155, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3335031494498253, 'completion_length': 493.46875, 'kl': 0.0074920654296875, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 505/800 [49:27<2:46:38, 33.89s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 506/800 [49:49<2:27:27, 30.09s/it]                                                   {'loss': 0.0, 'grad_norm': 0.62570811356844, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1157275140285492, 'completion_length': 522.15625, 'kl': 0.00794219970703125, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 506/800 [49:49<2:27:27, 30.09s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 507/800 [50:08<2:10:26, 26.71s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6432034594015301, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3471629247069359, 'completion_length': 516.875, 'kl': 0.00804901123046875, 'epoch': 0.27}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 507/800 [50:08<2:10:26, 26.71s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 508/800 [50:24<1:55:35, 23.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4784479028005167, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 387.09375, 'kl': 0.0122222900390625, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 508/800 [50:24<1:55:35, 23.75s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 509/800 [50:45<1:50:34, 22.80s/it]                                                   {'loss': 0.0, 'grad_norm': 0.36842438211395123, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 460.0, 'kl': 0.011016845703125, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 509/800 [50:45<1:50:34, 22.80s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 510/800 [51:07<1:48:56, 22.54s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8530090308686233, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.4765698313713074, 'completion_length': 602.03125, 'kl': 0.00787353515625, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 510/800 [51:07<1:48:56, 22.54s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 511/800 [51:53<2:22:41, 29.63s/it]                                                   {'loss': 0.0, 'grad_norm': 0.657432592974058, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.3104073107242584, 'completion_length': 843.78125, 'kl': 0.00897216796875, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 511/800 [51:53<2:22:41, 29.63s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 512/800 [52:29<2:31:57, 31.66s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6175976867131431, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3061639815568924, 'completion_length': 636.875, 'kl': 0.0104217529296875, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 512/800 [52:29<2:31:57, 31.66s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 513/800 [53:04<2:35:30, 32.51s/it]                                                   {'loss': 0.0, 'grad_norm': 1.0800825910421077, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.4492306634783745, 'completion_length': 605.125, 'kl': 0.01020050048828125, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 513/800 [53:04<2:35:30, 32.51s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 514/800 [53:20<2:11:36, 27.61s/it]                                                   {'loss': 0.0, 'grad_norm': 0.554349869747958, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 377.5625, 'kl': 0.032928466796875, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 514/800 [53:20<2:11:36, 27.61s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 515/800 [53:34<1:52:14, 23.63s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5701005620023244, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 326.5, 'kl': 0.00921630859375, 'epoch': 0.27}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 515/800 [53:34<1:52:14, 23.63s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 516/800 [54:06<2:03:28, 26.09s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4393883030876861, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.2587745785713196, 'completion_length': 793.4375, 'kl': 0.005664825439453125, 'epoch': 0.28}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 516/800 [54:06<2:03:28, 26.09s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 517/800 [54:40<2:14:27, 28.51s/it]                                                   {'loss': 0.0, 'grad_norm': 0.20250799878188175, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.13363061845302582, 'completion_length': 679.625, 'kl': 0.006866455078125, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 517/800 [54:40<2:14:27, 28.51s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 518/800 [55:31<2:45:14, 35.16s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5083303585128542, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3061639815568924, 'completion_length': 1095.375, 'kl': 0.0030975341796875, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 518/800 [55:31<2:45:14, 35.16s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 519/800 [55:51<2:22:46, 30.49s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6473447424128069, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2587745785713196, 'completion_length': 539.84375, 'kl': 0.00543975830078125, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 519/800 [55:51<2:22:46, 30.49s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [56:11<2:08:13, 27.48s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4942757202333605, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.1293872892856598, 'completion_length': 454.15625, 'kl': 0.0084228515625, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 520/800 [56:11<2:08:13, 27.48s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 521/800 [56:26<1:50:43, 23.81s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4927706510055908, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 353.1875, 'kl': 0.00572967529296875, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 521/800 [56:26<1:50:43, 23.81s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 522/800 [56:47<1:45:29, 22.77s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5924914721674793, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1767766922712326, 'completion_length': 514.25, 'kl': 0.005550384521484375, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 522/800 [56:47<1:45:29, 22.77s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 523/800 [57:41<2:28:54, 32.25s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7604819648447385, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.2041158601641655, 'completion_length': 834.90625, 'kl': 0.0060272216796875, 'epoch': 0.28}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 523/800 [57:41<2:28:54, 32.25s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 524/800 [58:09<2:22:22, 30.95s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8808033515138604, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.1767766922712326, 'completion_length': 730.1875, 'kl': 0.0055084228515625, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 524/800 [58:09<2:22:22, 30.95s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 525/800 [58:51<2:36:30, 34.15s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6671908310638315, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.2177756354212761, 'completion_length': 910.84375, 'kl': 0.003940582275390625, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 525/800 [58:51<2:36:30, 34.15s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 526/800 [59:07<2:11:30, 28.80s/it]                                                   {'loss': 0.0, 'grad_norm': 0.667047033241526, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 416.4375, 'kl': 0.00518798828125, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 526/800 [59:07<2:11:30, 28.80s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 527/800 [59:44<2:22:23, 31.29s/it]                                                   {'loss': 0.0, 'grad_norm': 0.0008849056860459799, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.0, 'completion_length': 983.28125, 'kl': 0.00450897216796875, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 527/800 [59:44<2:22:23, 31.29s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 528/800 [1:00:09<2:13:35, 29.47s/it]                                                     {'loss': 0.0, 'grad_norm': 0.934044566311706, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3471629247069359, 'completion_length': 599.78125, 'kl': 0.00628662109375, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 528/800 [1:00:09<2:13:35, 29.47s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 529/800 [1:00:36<2:09:49, 28.74s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7253194476473716, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.15625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.15625, 'reward_std': 0.22201896458864212, 'completion_length': 681.59375, 'kl': 0.0046234130859375, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 529/800 [1:00:36<2:09:49, 28.74s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 530/800 [1:01:18<2:27:22, 32.75s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6451963463766365, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.2925042062997818, 'completion_length': 741.375, 'kl': 0.00533294677734375, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 530/800 [1:01:18<2:27:22, 32.75s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 531/800 [1:01:35<2:05:27, 27.98s/it]                                                     {'loss': 0.0, 'grad_norm': 1.186269147225924, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2925042062997818, 'completion_length': 402.375, 'kl': 0.007598876953125, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 531/800 [1:01:35<2:05:27, 27.98s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 532/800 [1:02:01<2:01:46, 27.26s/it]                                                     {'loss': 0.0, 'grad_norm': 0.29528378354478074, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 723.0, 'kl': 0.005397796630859375, 'epoch': 0.28}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 532/800 [1:02:01<2:01:46, 27.26s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 533/800 [1:02:24<1:55:09, 25.88s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4892159440388548, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.2587745785713196, 'completion_length': 582.53125, 'kl': 0.0043697357177734375, 'epoch': 0.28}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 533/800 [1:02:24<1:55:09, 25.88s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 534/800 [1:02:59<2:07:45, 28.82s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5439551015197417, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.24511480331420898, 'completion_length': 1000.84375, 'kl': 0.003643035888671875, 'epoch': 0.28}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 534/800 [1:02:59<2:07:45, 28.82s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 535/800 [1:03:32<2:12:04, 29.90s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6504853833284127, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.1767766922712326, 'completion_length': 643.3125, 'kl': 0.0060882568359375, 'epoch': 0.29}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 535/800 [1:03:32<2:12:04, 29.90s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 536/800 [1:03:46<1:50:28, 25.11s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5447989764672603, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1157275140285492, 'completion_length': 341.53125, 'kl': 0.00560760498046875, 'epoch': 0.29}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 536/800 [1:03:46<1:50:28, 25.11s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 537/800 [1:04:24<2:07:36, 29.11s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6195876520687849, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.249358132481575, 'completion_length': 657.1875, 'kl': 0.0070037841796875, 'epoch': 0.29}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 537/800 [1:04:24<2:07:36, 29.11s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 538/800 [1:04:42<1:51:58, 25.64s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8320559959569548, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3104073107242584, 'completion_length': 415.71875, 'kl': 0.00762176513671875, 'epoch': 0.29}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 538/800 [1:04:42<1:51:58, 25.64s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 539/800 [1:05:26<2:15:45, 31.21s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6380589153572004, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.3514062538743019, 'completion_length': 946.125, 'kl': 0.004669189453125, 'epoch': 0.29}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 539/800 [1:05:26<2:15:45, 31.21s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [1:05:47<2:02:43, 28.32s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6135201909607103, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 458.15625, 'kl': 0.00531005859375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 540/800 [1:05:47<2:02:43, 28.32s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 541/800 [1:06:04<1:47:34, 24.92s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6794622168228198, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2314550280570984, 'completion_length': 431.3125, 'kl': 0.005779266357421875, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 541/800 [1:06:04<1:47:34, 24.92s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 542/800 [1:06:27<1:43:59, 24.19s/it]                                                     {'loss': 0.0, 'grad_norm': 1.0616633430375282, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2651650384068489, 'completion_length': 462.65625, 'kl': 0.006134033203125, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 542/800 [1:06:27<1:43:59, 24.19s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 543/800 [1:06:42<1:32:31, 21.60s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8430395408312821, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 356.3125, 'kl': 0.00777435302734375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 543/800 [1:06:42<1:32:31, 21.60s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 544/800 [1:06:59<1:25:14, 19.98s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5250865553051068, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.1293872892856598, 'completion_length': 410.9375, 'kl': 0.01290130615234375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 544/800 [1:06:59<1:25:14, 19.98s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 545/800 [1:07:20<1:26:59, 20.47s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5402332692477398, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.3198433741927147, 'completion_length': 560.34375, 'kl': 0.00502777099609375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 545/800 [1:07:20<1:26:59, 20.47s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 546/800 [1:07:59<1:50:01, 25.99s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7840616458090763, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3335031494498253, 'completion_length': 754.34375, 'kl': 0.00846099853515625, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 546/800 [1:07:59<1:50:01, 25.99s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 547/800 [1:08:19<1:41:48, 24.14s/it]                                                     {'loss': 0.0, 'grad_norm': 0.3772519701973774, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 529.21875, 'kl': 0.00875091552734375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 547/800 [1:08:19<1:41:48, 24.14s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 548/800 [1:08:47<1:46:09, 25.28s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5303680919920023, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.249358132481575, 'completion_length': 711.59375, 'kl': 0.006160736083984375, 'epoch': 0.29}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 548/800 [1:08:47<1:46:09, 25.28s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 549/800 [1:09:24<2:01:03, 28.94s/it]                                                     {'loss': 0.0, 'grad_norm': 0.40796617062714713, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2587745785713196, 'completion_length': 907.5625, 'kl': 0.007080078125, 'epoch': 0.29}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 549/800 [1:09:24<2:01:03, 28.94s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 550/800 [1:09:49<1:55:41, 27.77s/it]                                                     {'loss': 0.0, 'grad_norm': 0.663221490023946, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.24511480331420898, 'completion_length': 433.21875, 'kl': 0.0112457275390625, 'epoch': 0.29}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 550/800 [1:09:49<1:55:41, 27.77s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 551/800 [1:11:34<3:31:11, 50.89s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7830112800946384, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.2314550280570984, 'completion_length': 574.15625, 'kl': 0.0080108642578125, 'epoch': 0.29}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 551/800 [1:11:34<3:31:11, 50.89s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 552/800 [1:11:49<2:45:10, 39.96s/it]                                                     {'loss': 0.0, 'grad_norm': 0.0033973456884638584, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0, 'rewards/reward_correct_and_format': 0.0, 'reward': 1.0, 'reward_std': 0.0, 'completion_length': 350.625, 'kl': 0.011566162109375, 'epoch': 0.29}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 552/800 [1:11:49<2:45:10, 39.96s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 553/800 [1:12:15<2:27:07, 35.74s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5298828223408202, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.2041158601641655, 'completion_length': 646.34375, 'kl': 0.00728607177734375, 'epoch': 0.29}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 553/800 [1:12:15<2:27:07, 35.74s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 554/800 [1:12:37<2:09:37, 31.62s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6826828608734593, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.24511480331420898, 'completion_length': 517.4375, 'kl': 0.009246826171875, 'epoch': 0.3}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 554/800 [1:12:37<2:09:37, 31.62s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 555/800 [1:13:02<2:02:08, 29.91s/it]                                                     {'loss': 0.0, 'grad_norm': 0.26914136860898574, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 580.96875, 'kl': 0.0080718994140625, 'epoch': 0.3}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 555/800 [1:13:02<2:02:08, 29.91s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 556/800 [1:13:24<1:51:05, 27.32s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5101794478017831, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.2177756354212761, 'completion_length': 564.8125, 'kl': 0.0084075927734375, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 556/800 [1:13:24<1:51:05, 27.32s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 557/800 [1:13:46<1:44:24, 25.78s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6152472015401957, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.24511480331420898, 'completion_length': 482.125, 'kl': 0.009552001953125, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 557/800 [1:13:46<1:44:24, 25.78s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 558/800 [1:14:21<1:55:20, 28.60s/it]                                                     {'loss': 0.0, 'grad_norm': 0.791126068856186, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.3198433741927147, 'completion_length': 772.5, 'kl': 0.0086212158203125, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 558/800 [1:14:21<1:55:20, 28.60s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 559/800 [1:14:46<1:50:49, 27.59s/it]                                                     {'loss': 0.0, 'grad_norm': 0.3395961739680191, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.1767766922712326, 'completion_length': 593.1875, 'kl': 0.0104827880859375, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 559/800 [1:14:46<1:50:49, 27.59s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [1:15:36<2:16:23, 34.10s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5694551133163442, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.22201896458864212, 'completion_length': 782.96875, 'kl': 0.00766754150390625, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 560/800 [1:15:36<2:16:23, 34.10s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 561/800 [1:15:53<1:56:09, 29.16s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6121482481052837, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 444.8125, 'kl': 0.00746917724609375, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 561/800 [1:15:53<1:56:09, 29.16s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 562/800 [1:16:18<1:50:57, 27.97s/it]                                                     {'loss': 0.0, 'grad_norm': 0.559401500330544, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.249358132481575, 'completion_length': 697.53125, 'kl': 0.0066070556640625, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 562/800 [1:16:18<1:50:57, 27.97s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 563/800 [1:16:45<1:48:51, 27.56s/it]                                                     {'loss': 0.0, 'grad_norm': 0.3747068621131136, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.13363061845302582, 'completion_length': 759.0625, 'kl': 0.006381988525390625, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 563/800 [1:16:45<1:48:51, 27.56s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 564/800 [1:17:08<1:42:28, 26.05s/it]                                                     {'loss': 0.0, 'grad_norm': 0.9158136314639643, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3198433741927147, 'completion_length': 550.125, 'kl': 0.008514404296875, 'epoch': 0.3}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 564/800 [1:17:08<1:42:28, 26.05s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 565/800 [1:17:28<1:35:49, 24.47s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6126620251809477, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.1767766922712326, 'completion_length': 456.875, 'kl': 0.0134429931640625, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 565/800 [1:17:28<1:35:49, 24.47s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 566/800 [1:17:59<1:42:31, 26.29s/it]                                                     {'loss': 0.0, 'grad_norm': 0.37405911622032967, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2177756354212761, 'completion_length': 831.8125, 'kl': 0.00848388671875, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 566/800 [1:17:59<1:42:31, 26.29s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 567/800 [1:18:14<1:29:05, 22.94s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6152541711683164, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 392.40625, 'kl': 0.0084991455078125, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 567/800 [1:18:14<1:29:05, 22.94s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 568/800 [1:18:40<1:32:18, 23.87s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8980525369374073, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.0883883461356163, 'completion_length': 566.0, 'kl': 0.01104736328125, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 568/800 [1:18:40<1:32:18, 23.87s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 569/800 [1:19:02<1:29:23, 23.22s/it]                                                     {'loss': 0.0, 'grad_norm': 0.635815756415418, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.24511480331420898, 'completion_length': 556.96875, 'kl': 0.0092315673828125, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 569/800 [1:19:02<1:29:23, 23.22s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 570/800 [1:19:39<1:44:49, 27.35s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8904495894625016, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3808925524353981, 'completion_length': 655.9375, 'kl': 0.0092926025390625, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 570/800 [1:19:39<1:44:49, 27.35s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 571/800 [1:20:06<1:44:12, 27.30s/it]                                                     {'loss': 0.0, 'grad_norm': 0.48226457518393606, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1767766922712326, 'completion_length': 775.9375, 'kl': 0.0088043212890625, 'epoch': 0.3}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 571/800 [1:20:06<1:44:12, 27.30s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 572/800 [1:20:22<1:31:19, 24.03s/it]                                                     {'loss': 0.0, 'grad_norm': 0.564848500957468, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.13363061845302582, 'completion_length': 398.6875, 'kl': 0.01373291015625, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 572/800 [1:20:22<1:31:19, 24.03s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 573/800 [1:21:12<2:00:10, 31.77s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6340671320464785, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3471629247069359, 'completion_length': 1074.5, 'kl': 0.00872802734375, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 573/800 [1:21:12<2:00:10, 31.77s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 574/800 [1:21:48<2:04:24, 33.03s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4090690925171068, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 611.9375, 'kl': 0.0101470947265625, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 574/800 [1:21:48<2:04:24, 33.03s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 575/800 [1:22:23<2:06:04, 33.62s/it]                                                     {'loss': 0.0, 'grad_norm': 0.20799417178183888, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.13363061845302582, 'completion_length': 717.4375, 'kl': 0.00782012939453125, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 575/800 [1:22:23<2:06:04, 33.62s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 576/800 [1:22:49<1:56:47, 31.28s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5531996164350975, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2041158601641655, 'completion_length': 751.96875, 'kl': 0.00821685791015625, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 576/800 [1:22:49<1:56:47, 31.28s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 577/800 [1:23:09<1:43:23, 27.82s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6566566908838675, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.24511480331420898, 'completion_length': 485.59375, 'kl': 0.01064300537109375, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 577/800 [1:23:09<1:43:23, 27.82s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 578/800 [1:23:28<1:33:29, 25.27s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6445702602541387, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.13363061845302582, 'completion_length': 477.15625, 'kl': 0.0127716064453125, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 578/800 [1:23:28<1:33:29, 25.27s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 579/800 [1:24:10<1:51:21, 30.23s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6258684929578641, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2925042062997818, 'completion_length': 693.46875, 'kl': 0.006267547607421875, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 579/800 [1:24:10<1:51:21, 30.23s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [1:24:44<1:54:58, 31.36s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5924264792307783, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.2177756354212761, 'completion_length': 854.46875, 'kl': 0.01052093505859375, 'epoch': 0.31}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 580/800 [1:24:44<1:54:58, 31.36s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 581/800 [1:25:03<1:41:26, 27.79s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7295826053064621, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3471825420856476, 'completion_length': 501.28125, 'kl': 0.0111236572265625, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 581/800 [1:25:03<1:41:26, 27.79s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 582/800 [1:25:25<1:34:47, 26.09s/it]                                                     {'loss': 0.0, 'grad_norm': 0.672181716568941, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2314550280570984, 'completion_length': 495.84375, 'kl': 0.01621246337890625, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 582/800 [1:25:25<1:34:47, 26.09s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 583/800 [1:25:50<1:32:13, 25.50s/it]                                                     {'loss': 0.0, 'grad_norm': 0.30367978260806056, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.1293872892856598, 'completion_length': 649.53125, 'kl': 0.01324462890625, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 583/800 [1:25:50<1:32:13, 25.50s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 584/800 [1:26:15<1:32:05, 25.58s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5444449203251067, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.22201896458864212, 'completion_length': 749.1875, 'kl': 0.0140533447265625, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 584/800 [1:26:15<1:32:05, 25.58s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 585/800 [1:26:46<1:36:43, 26.99s/it]                                                     {'loss': 0.0, 'grad_norm': 0.0017694373480425791, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.0, 'completion_length': 935.0, 'kl': 0.009918212890625, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 585/800 [1:26:46<1:36:43, 26.99s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 586/800 [1:27:02<1:25:03, 23.85s/it]                                                     {'loss': 0.0, 'grad_norm': 0.506685785730737, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.1293872892856598, 'completion_length': 505.59375, 'kl': 0.0126495361328125, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 586/800 [1:27:02<1:25:03, 23.85s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 587/800 [1:27:19<1:17:34, 21.85s/it]                                                     {'loss': 0.0, 'grad_norm': 0.40568856696463057, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 522.25, 'kl': 0.014617919921875, 'epoch': 0.31}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 587/800 [1:27:19<1:17:34, 21.85s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 588/800 [1:27:55<1:31:34, 25.92s/it]                                                     {'loss': 0.0, 'grad_norm': 0.619922610347076, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3608423173427582, 'completion_length': 713.375, 'kl': 0.01605224609375, 'epoch': 0.31}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 588/800 [1:27:55<1:31:34, 25.92s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 589/800 [1:28:26<1:37:06, 27.61s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5428084856710884, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2314550280570984, 'completion_length': 775.78125, 'kl': 0.0128936767578125, 'epoch': 0.31}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 589/800 [1:28:26<1:37:06, 27.61s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 590/800 [1:28:44<1:25:51, 24.53s/it]                                                     {'loss': 0.0, 'grad_norm': 0.30123056435703144, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.1293872892856598, 'completion_length': 506.46875, 'kl': 0.015594482421875, 'epoch': 0.31}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 590/800 [1:28:44<1:25:51, 24.53s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 591/800 [1:29:14<1:31:06, 26.15s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6446353914713591, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.249358132481575, 'completion_length': 791.3125, 'kl': 0.0136260986328125, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 591/800 [1:29:14<1:31:06, 26.15s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 592/800 [1:29:45<1:36:16, 27.77s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7753711690922688, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.26726123690605164, 'completion_length': 470.625, 'kl': 0.015350341796875, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 592/800 [1:29:45<1:36:16, 27.77s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 593/800 [1:29:59<1:21:17, 23.56s/it]                                                     {'loss': 0.0, 'grad_norm': 0.004873132048623367, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 370.375, 'kl': 0.018646240234375, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 593/800 [1:29:59<1:21:17, 23.56s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 594/800 [1:30:13<1:11:22, 20.79s/it]                                                     {'loss': 0.0, 'grad_norm': 0.726458215745643, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1767766922712326, 'completion_length': 428.4375, 'kl': 0.0203704833984375, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 594/800 [1:30:13<1:11:22, 20.79s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 595/800 [1:30:33<1:10:25, 20.61s/it]                                                     {'loss': 0.0, 'grad_norm': 0.46566651897150624, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 598.9375, 'kl': 0.012939453125, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 595/800 [1:30:33<1:10:25, 20.61s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 596/800 [1:30:53<1:09:37, 20.48s/it]                                                     {'loss': 0.0, 'grad_norm': 1.1579498031406186, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.494472935795784, 'completion_length': 522.09375, 'kl': 0.0487060546875, 'epoch': 0.32}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 596/800 [1:30:53<1:09:37, 20.48s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 597/800 [1:31:07<1:02:04, 18.35s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5601893314017505, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.9375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.9375, 'reward_std': 0.1767766922712326, 'completion_length': 364.25, 'kl': 0.01666259765625, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 597/800 [1:31:07<1:02:04, 18.35s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 598/800 [1:31:35<1:11:15, 21.17s/it]                                                     {'loss': 0.0, 'grad_norm': 0.569969124042132, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2630179077386856, 'completion_length': 768.84375, 'kl': 0.0157318115234375, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 598/800 [1:31:35<1:11:15, 21.17s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 599/800 [1:32:01<1:16:29, 22.83s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4421564841272404, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.1293872892856598, 'completion_length': 714.03125, 'kl': 0.01265716552734375, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 599/800 [1:32:01<1:16:29, 22.83s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [1:32:13<1:05:12, 19.56s/it]                                                     {'loss': 0.0, 'grad_norm': 0.005476887662549728, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0, 'rewards/reward_correct_and_format': 0.0, 'reward': 1.0, 'reward_std': 0.0, 'completion_length': 340.6875, 'kl': 0.019012451171875, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 600/800 [1:32:13<1:05:12, 19.56s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 601/800 [1:33:53<2:24:59, 43.72s/it]                                                     {'loss': 0.0, 'grad_norm': 1.2106866186897915, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.4355512708425522, 'completion_length': 536.15625, 'kl': 0.0137481689453125, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 601/800 [1:33:53<2:24:59, 43.72s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 602/800 [1:34:22<2:09:18, 39.18s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7531301995637103, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2314550280570984, 'completion_length': 649.09375, 'kl': 0.0146942138671875, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 602/800 [1:34:22<2:09:18, 39.18s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 603/800 [1:34:38<1:45:40, 32.18s/it]                                                     {'loss': 0.0, 'grad_norm': 0.9905955993961462, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.3335031494498253, 'completion_length': 442.875, 'kl': 0.0129852294921875, 'epoch': 0.32}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 603/800 [1:34:38<1:45:40, 32.18s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 604/800 [1:34:54<1:29:54, 27.52s/it]                                                     {'loss': 0.0, 'grad_norm': 0.24223167649602895, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 430.5625, 'kl': 0.0184173583984375, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 604/800 [1:34:54<1:29:54, 27.52s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 605/800 [1:35:22<1:29:08, 27.43s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6925868268416292, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.22201896458864212, 'completion_length': 673.3125, 'kl': 0.0206451416015625, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 605/800 [1:35:22<1:29:08, 27.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 606/800 [1:35:37<1:16:56, 23.79s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6374611604509428, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.1293872892856598, 'completion_length': 444.875, 'kl': 0.01146697998046875, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 606/800 [1:35:37<1:16:56, 23.79s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 607/800 [1:35:48<1:04:39, 20.10s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4925754282926178, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 273.53125, 'kl': 0.013519287109375, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 607/800 [1:35:48<1:04:39, 20.10s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 608/800 [1:36:04<1:00:13, 18.82s/it]                                                     {'loss': 0.0, 'grad_norm': 1.3755580017231182, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.2651650384068489, 'completion_length': 428.84375, 'kl': 0.01534271240234375, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 608/800 [1:36:04<1:00:13, 18.82s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 609/800 [1:36:20<56:51, 17.86s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8699263271717305, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2177756354212761, 'completion_length': 426.5625, 'kl': 0.01352691650390625, 'epoch': 0.32}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 609/800 [1:36:20<56:51, 17.86s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 610/800 [1:36:38<56:56, 17.98s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5697161209093128, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.26726123690605164, 'completion_length': 491.34375, 'kl': 0.0165252685546875, 'epoch': 0.33}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 610/800 [1:36:38<56:56, 17.98s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 611/800 [1:37:00<1:00:15, 19.13s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5667358522387713, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.26726123690605164, 'completion_length': 579.09375, 'kl': 0.014129638671875, 'epoch': 0.33}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 611/800 [1:37:00<1:00:15, 19.13s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 612/800 [1:37:22<1:02:41, 20.01s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4757197143245176, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.2630179077386856, 'completion_length': 635.21875, 'kl': 0.01104736328125, 'epoch': 0.33}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 612/800 [1:37:22<1:02:41, 20.01s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 613/800 [1:37:46<1:05:40, 21.07s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5311618024763498, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 683.5, 'kl': 0.009552001953125, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 613/800 [1:37:46<1:05:40, 21.07s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 614/800 [1:38:07<1:05:41, 21.19s/it]                                                     {'loss': 0.0, 'grad_norm': 0.8630607408182285, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3608423173427582, 'completion_length': 542.125, 'kl': 0.0201568603515625, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 614/800 [1:38:07<1:05:41, 21.19s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 615/800 [1:38:38<1:14:48, 24.26s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7993091383202534, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.3104073107242584, 'completion_length': 805.90625, 'kl': 0.0135650634765625, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 615/800 [1:38:39<1:14:48, 24.26s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 616/800 [1:39:09<1:20:19, 26.19s/it]                                                     {'loss': 0.0, 'grad_norm': 1.0486008240622668, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.4807935431599617, 'completion_length': 639.75, 'kl': 0.020416259765625, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 616/800 [1:39:09<1:20:19, 26.19s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 617/800 [1:39:27<1:12:27, 23.76s/it]                                                     {'loss': 0.0, 'grad_norm': 0.32847566930208505, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 449.0, 'kl': 0.014617919921875, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 617/800 [1:39:27<1:12:27, 23.76s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 618/800 [1:39:46<1:07:29, 22.25s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4474508715565537, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.0883883461356163, 'completion_length': 479.3125, 'kl': 0.016357421875, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 618/800 [1:39:46<1:07:29, 22.25s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 619/800 [1:40:03<1:02:01, 20.56s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7341106958796872, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.24511480331420898, 'completion_length': 464.625, 'kl': 0.020294189453125, 'epoch': 0.33}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 619/800 [1:40:03<1:02:01, 20.56s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [1:40:17<56:02, 18.68s/it]                                                     {'loss': 0.0, 'grad_norm': 0.004038055789804464, 'learning_rate': 1e-06, 'rewards/reward_correct': 1.0, 'rewards/reward_correct_and_format': 0.0, 'reward': 1.0, 'reward_std': 0.0, 'completion_length': 358.4375, 'kl': 0.016326904296875, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 620/800 [1:40:17<56:02, 18.68s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 621/800 [1:40:53<1:11:08, 23.85s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7898710237274823, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.3471629247069359, 'completion_length': 637.6875, 'kl': 0.010986328125, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 621/800 [1:40:53<1:11:08, 23.85s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 622/800 [1:41:11<1:05:47, 22.18s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7723051536309896, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.2041158601641655, 'completion_length': 504.34375, 'kl': 0.0168609619140625, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 622/800 [1:41:11<1:05:47, 22.18s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 623/800 [1:41:34<1:06:26, 22.52s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6688420556183184, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.24511480331420898, 'completion_length': 550.40625, 'kl': 0.00930023193359375, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 623/800 [1:41:34<1:06:26, 22.52s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 624/800 [1:42:07<1:15:00, 25.57s/it]                                                     {'loss': 0.0, 'grad_norm': 0.4721129504054995, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.13363061845302582, 'completion_length': 640.71875, 'kl': 0.0189208984375, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 624/800 [1:42:07<1:15:00, 25.57s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 625/800 [1:42:23<1:06:07, 22.67s/it]                                                     {'loss': 0.0, 'grad_norm': 0.48480404064964766, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.96875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.96875, 'reward_std': 0.0883883461356163, 'completion_length': 394.96875, 'kl': 0.01751708984375, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 625/800 [1:42:23<1:06:07, 22.67s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 626/800 [1:42:37<58:13, 20.08s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5953067781630011, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.1293872892856598, 'completion_length': 338.46875, 'kl': 0.015655517578125, 'epoch': 0.33}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 626/800 [1:42:37<58:13, 20.08s/it]