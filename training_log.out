[2025-03-12 09:48:17,986] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
W0312 09:48:53.374000 5810 site-packages/torch/distributed/run.py:793] 
W0312 09:48:53.374000 5810 site-packages/torch/distributed/run.py:793] *****************************************
W0312 09:48:53.374000 5810 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0312 09:48:53.374000 5810 site-packages/torch/distributed/run.py:793] *****************************************
[2025-03-12 09:50:37,860] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-12 09:50:39,326] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 03-12 09:51:36 __init__.py:190] Automatically detected platform cuda.
INFO 03-12 09:51:36 __init__.py:190] Automatically detected platform cuda.
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-full', run_name='qwen3b-full', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=4, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=200, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False)
MyArguments(model_name='Qwen/Qwen2.5-3B', output_dir='outputs/qwen2.5-3b-grpo-full', run_name='qwen3b-full', learning_rate=1e-06, beta=0.001, adam_beta1=0.9, adam_beta2=0.99, weight_decay=0.1, warmup_steps=25, lr_scheduler_type='constant_with_warmup', logging_steps=1, bf16=True, bf16_full_eval=True, per_device_train_batch_size=4, gradient_accumulation_steps=4, gradient_checkpointing=True, num_generations=8, max_prompt_length=256, max_completion_length=4096, num_train_epochs=1, save_steps=50, max_grad_norm=0.1, report_to='wandb', use_vllm=True, vllm_max_model_len=5000, max_steps=200, log_completions=True, evaluation_strategy='steps', eval_steps=50, eval_on_start=False)
[2025-03-12 09:51:44,718] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-12 09:51:44,753] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-03-12 09:51:44,754] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-12 09:51:47,273] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-12 09:51:47,390] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
[2025-03-12 09:51:49,380] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:16<00:16, 16.66s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:17<00:17, 17.05s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:25<00:00, 12.17s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:25<00:00, 12.85s/it]
[2025-03-12 09:52:15,339] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 12.38s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:26<00:00, 13.08s/it]
[2025-03-12 09:52:15,873] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-12 09:52:16,075] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 870, num_elems = 6.79B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.54s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.05s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.09it/s]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.20s/it]
INFO 03-12 09:54:24 config.py:542] This model supports multiple tasks: {'generate', 'embed', 'classify', 'score', 'reward'}. Defaulting to 'generate'.
INFO 03-12 09:54:25 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='Qwen/Qwen2.5-3B', speculative_config=None, tokenizer='Qwen/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:2, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-3B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 03-12 09:54:32 cuda.py:230] Using Flash Attention backend.
INFO 03-12 09:54:32 model_runner.py:1110] Starting to load model Qwen/Qwen2.5-3B...
INFO 03-12 09:54:33 weight_utils.py:252] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.59it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.81it/s]

INFO 03-12 09:54:35 model_runner.py:1115] Loading model weights took 0.0000 GB
INFO 03-12 09:54:36 worker.py:267] Memory profiling takes 1.64 seconds
INFO 03-12 09:54:36 worker.py:267] the current vLLM instance can use total_gpu_memory (79.21GiB) x gpu_memory_utilization (0.90) = 71.29GiB
INFO 03-12 09:54:36 worker.py:267] model weights take 0.00GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 0.00GiB; the rest of the memory reserved for KV Cache is 71.29GiB.
INFO 03-12 09:54:36 executor_base.py:110] # CUDA blocks: 129775, # CPU blocks: 7281
INFO 03-12 09:54:36 executor_base.py:115] Maximum concurrency for 5000 tokens per request: 415.28x
INFO 03-12 09:54:39 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|‚ñé         | 1/35 [00:00<00:18,  1.82it/s]Capturing CUDA graph shapes:   6%|‚ñå         | 2/35 [00:00<00:13,  2.42it/s]Capturing CUDA graph shapes:   9%|‚ñä         | 3/35 [00:01<00:11,  2.71it/s]Capturing CUDA graph shapes:  11%|‚ñà‚ñè        | 4/35 [00:01<00:10,  2.87it/s]Capturing CUDA graph shapes:  14%|‚ñà‚ñç        | 5/35 [00:01<00:10,  2.91it/s]Capturing CUDA graph shapes:  17%|‚ñà‚ñã        | 6/35 [00:02<00:09,  3.00it/s]Capturing CUDA graph shapes:  20%|‚ñà‚ñà        | 7/35 [00:02<00:09,  3.05it/s]Capturing CUDA graph shapes:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:02<00:08,  3.08it/s]Capturing CUDA graph shapes:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:03<00:08,  3.09it/s]Capturing CUDA graph shapes:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:03<00:08,  3.11it/s]Capturing CUDA graph shapes:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:03<00:07,  3.13it/s]Capturing CUDA graph shapes:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:04<00:07,  3.14it/s]Capturing CUDA graph shapes:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:04<00:07,  3.14it/s]Capturing CUDA graph shapes:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:04<00:06,  3.14it/s]Capturing CUDA graph shapes:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:05<00:06,  3.15it/s]Capturing CUDA graph shapes:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:05<00:06,  3.15it/s]Capturing CUDA graph shapes:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:05<00:05,  3.03it/s]Capturing CUDA graph shapes:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:06<00:05,  3.05it/s]Capturing CUDA graph shapes:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:06<00:05,  3.08it/s]Capturing CUDA graph shapes:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:06<00:04,  3.10it/s]Capturing CUDA graph shapes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:06<00:04,  3.12it/s]Capturing CUDA graph shapes:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:07<00:04,  3.03it/s]Capturing CUDA graph shapes:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:07<00:04,  2.80it/s]Capturing CUDA graph shapes:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:08<00:04,  2.67it/s]Capturing CUDA graph shapes:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:08<00:03,  2.67it/s]Capturing CUDA graph shapes:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:08<00:03,  2.78it/s]Capturing CUDA graph shapes:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:09<00:02,  2.84it/s]Capturing CUDA graph shapes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:09<00:02,  2.88it/s]Capturing CUDA graph shapes:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:09<00:02,  2.90it/s]Capturing CUDA graph shapes:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:10<00:01,  2.92it/s]Capturing CUDA graph shapes:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:10<00:01,  2.92it/s]Capturing CUDA graph shapes:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:10<00:01,  2.94it/s]Capturing CUDA graph shapes:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:11<00:00,  2.61it/s]Capturing CUDA graph shapes:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:11<00:00,  2.73it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:12<00:00,  2.70it/s]Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:12<00:00,  2.90it/s]
INFO 03-12 09:54:51 model_runner.py:1562] Graph capturing finished in 12 secs, took 0.00 GiB
INFO 03-12 09:54:51 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 16.52 seconds
[2025-03-12 09:54:55,433] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed info: version=0.15.3, git-hash=unknown, git-branch=unknown
[2025-03-12 09:54:55,433] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-12 09:54:55,435] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 2
[2025-03-12 09:54:55,464] [INFO] [logging.py:129:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-03-12 09:54:55,466] [INFO] [logging.py:129:log_dist] [Rank 0] Creating ZeRO Offload
[2025-03-12 09:54:56,165] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-03-12 09:54:56,169] [INFO] [utils.py:782:see_memory_usage] MA 5.75 GB         Max_MA 5.75 GB         CA 5.91 GB         Max_CA 6 GB 
[2025-03-12 09:54:56,170] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 75.99 GB, percent = 3.8%
Parameter Offload: Total persistent parameters: 241664 in 181 params
[2025-03-12 09:54:56,902] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-03-12 09:54:56,904] [INFO] [utils.py:782:see_memory_usage] MA 5.75 GB         Max_MA 5.75 GB         CA 5.91 GB         Max_CA 6 GB 
[2025-03-12 09:54:56,908] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 75.98 GB, percent = 3.8%
[2025-03-12 09:54:56,910] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-03-12 09:54:56,911] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-12 09:54:56,912] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-12 09:54:56,913] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-03-12 09:54:56,914] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-03-12 09:54:56,915] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-12 09:54:56,915] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-03-12 09:54:56,916] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-03-12 09:54:56,917] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-03-12 09:54:56,918] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-03-12 09:54:56,918] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-03-12 09:54:56,919] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7c894efbc880>
[2025-03-12 09:54:56,920] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-03-12 09:54:56,921] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-12 09:54:56,922] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-03-12 09:54:56,922] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-03-12 09:54:56,923] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-12 09:54:56,924] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-03-12 09:54:56,925] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-03-12 09:54:56,925] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-03-12 09:54:56,925] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-03-12 09:54:56,926] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-03-12 09:54:56,927] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-03-12 09:54:56,928] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-12 09:54:56,929] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-12 09:54:56,929] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-03-12 09:54:56,930] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-03-12 09:54:56,931] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-03-12 09:54:56,932] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-03-12 09:54:56,932] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-03-12 09:54:56,933] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-03-12 09:54:56,934] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-12 09:54:56,935] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-03-12 09:54:56,935] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-03-12 09:54:56,936] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-03-12 09:54:56,937] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-03-12 09:54:56,938] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-03-12 09:54:56,938] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 4
[2025-03-12 09:54:56,939] [INFO] [config.py:1003:print]   gradient_clipping ............ 0.1
[2025-03-12 09:54:56,940] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-03-12 09:54:56,941] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-03-12 09:54:56,942] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-12 09:54:56,942] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-03-12 09:54:56,943] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-03-12 09:54:56,944] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-03-12 09:54:56,945] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-03-12 09:54:56,945] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-03-12 09:54:56,946] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-03-12 09:54:56,947] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-12 09:54:56,948] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-12 09:54:56,948] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-03-12 09:54:56,949] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2025-03-12 09:54:56,949] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2025-03-12 09:54:56,950] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-12 09:54:56,951] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-03-12 09:54:56,951] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-03-12 09:54:56,952] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-03-12 09:54:56,953] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2025-03-12 09:54:56,954] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2025-03-12 09:54:56,954] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-12 09:54:56,955] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-03-12 09:54:56,956] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-03-12 09:54:56,956] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-03-12 09:54:56,957] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-03-12 09:54:56,958] [INFO] [config.py:1003:print]   train_batch_size ............. 32
[2025-03-12 09:54:56,959] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  4
[2025-03-12 09:54:56,959] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-03-12 09:54:56,960] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-03-12 09:54:56,961] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-03-12 09:54:56,961] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-03-12 09:54:56,962] [INFO] [config.py:1003:print]   world_size ................... 2
[2025-03-12 09:54:56,963] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-03-12 09:54:56,964] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-03-12 09:54:56,965] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-03-12 09:54:56,966] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-12 09:54:56,967] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[2025-03-12 09:54:56,967] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 4, 
    "gradient_accumulation_steps": 4, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 0.1, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_optimization.reduce_bucket_size": 4.194304e+06, 
    "zero_optimization.stage3_param_persistence_threshold": 2.048000e+04, 
    "zero_optimization.stage3_prefetch_bucket_size": 3.774874e+06
}
Parameter Offload: Total persistent parameters: 241664 in 181 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: ss13750 (ss13750-new-york-university-abu-dhabi) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/VRL/wandb/run-20250312_095509-ckwa047b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run qwen3b-full
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface
wandb: üöÄ View run at https://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface/runs/ckwa047b
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [00:25<1:26:07, 25.97s/it]                                                 {'loss': 0.0, 'grad_norm': 0.947680726180562, 'learning_rate': 4e-08, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.13363061845302582, 'completion_length': 328.75, 'kl': 0.0, 'epoch': 0.0}
  0%|          | 1/200 [00:25<1:26:07, 25.97s/it]  1%|          | 2/200 [00:43<1:09:12, 20.97s/it]                                                 {'loss': -0.0, 'grad_norm': 2.0250795629515967, 'learning_rate': 8e-08, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.408231720328331, 'completion_length': 274.90625, 'kl': 0.0, 'epoch': 0.0}
  1%|          | 2/200 [00:43<1:09:12, 20.97s/it]  2%|‚ñè         | 3/200 [01:26<1:42:14, 31.14s/it]                                                 {'loss': 0.0, 'grad_norm': 1.6892237387776363, 'learning_rate': 1.2e-07, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.3335031494498253, 'completion_length': 537.59375, 'kl': 0.00017070770263671875, 'epoch': 0.0}
  2%|‚ñè         | 3/200 [01:26<1:42:14, 31.14s/it]  2%|‚ñè         | 4/200 [01:45<1:25:32, 26.18s/it]                                                 {'loss': 0.0, 'grad_norm': 1.5459356749733006, 'learning_rate': 1.6e-07, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.35564958304166794, 'completion_length': 284.71875, 'kl': 0.0001074075698852539, 'epoch': 0.0}
  2%|‚ñè         | 4/200 [01:45<1:25:32, 26.18s/it]  2%|‚ñé         | 5/200 [02:09<1:23:03, 25.56s/it]                                                 {'loss': 0.0, 'grad_norm': 0.5121829472917847, 'learning_rate': 2e-07, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.1157275140285492, 'completion_length': 351.46875, 'kl': 0.00010228157043457031, 'epoch': 0.0}
  2%|‚ñé         | 5/200 [02:09<1:23:03, 25.56s/it]  3%|‚ñé         | 6/200 [02:46<1:34:54, 29.35s/it]                                                 {'loss': 0.0, 'grad_norm': 2.054639775384679, 'learning_rate': 2.4e-07, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3608423173427582, 'completion_length': 361.96875, 'kl': 0.00011116266250610352, 'epoch': 0.0}
  3%|‚ñé         | 6/200 [02:46<1:34:54, 29.35s/it]  4%|‚ñé         | 7/200 [03:21<1:40:44, 31.32s/it]                                                 {'loss': 0.0, 'grad_norm': 1.0551649479462684, 'learning_rate': 2.8e-07, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.3924051970243454, 'completion_length': 608.84375, 'kl': 4.151463508605957e-05, 'epoch': 0.0}
  4%|‚ñé         | 7/200 [03:21<1:40:44, 31.32s/it]  4%|‚ñç         | 8/200 [03:57<1:44:43, 32.73s/it]                                                 {'loss': 0.0, 'grad_norm': 1.3385695817981016, 'learning_rate': 3.2e-07, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.2925042062997818, 'completion_length': 566.625, 'kl': 0.00013172626495361328, 'epoch': 0.0}
  4%|‚ñç         | 8/200 [03:57<1:44:43, 32.73s/it]Timeout during comparison
Timeout during comparison
  4%|‚ñç         | 9/200 [04:27<1:41:21, 31.84s/it]                                                 {'loss': 0.0, 'grad_norm': 1.0930880112340404, 'learning_rate': 3.6e-07, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.2587745785713196, 'completion_length': 329.6875, 'kl': 0.0001252889633178711, 'epoch': 0.0}
  4%|‚ñç         | 9/200 [04:27<1:41:21, 31.84s/it]  5%|‚ñå         | 10/200 [04:51<1:33:25, 29.50s/it]                                                  {'loss': 0.0, 'grad_norm': 1.407599397128983, 'learning_rate': 4e-07, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.2314550280570984, 'completion_length': 323.46875, 'kl': 0.00011819601058959961, 'epoch': 0.01}
  5%|‚ñå         | 10/200 [04:51<1:33:25, 29.50s/it]  6%|‚ñå         | 11/200 [05:12<1:24:33, 26.84s/it]                                                  {'loss': 0.0, 'grad_norm': 1.989604747202761, 'learning_rate': 4.3999999999999997e-07, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.4355512708425522, 'completion_length': 311.625, 'kl': 7.843971252441406e-05, 'epoch': 0.01}
  6%|‚ñå         | 11/200 [05:12<1:24:33, 26.84s/it]  6%|‚ñå         | 12/200 [05:52<1:36:29, 30.79s/it]                                                  {'loss': 0.0, 'grad_norm': 1.8953067319427044, 'learning_rate': 4.8e-07, 'rewards/reward_correct': 0.09375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.09375, 'reward_std': 0.2041158601641655, 'completion_length': 633.34375, 'kl': 0.00017142295837402344, 'epoch': 0.01}
  6%|‚ñå         | 12/200 [05:52<1:36:29, 30.79s/it]  6%|‚ñã         | 13/200 [06:27<1:40:33, 32.27s/it]                                                  {'loss': 0.0, 'grad_norm': 1.4879612323425115, 'learning_rate': 5.2e-07, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.3335031494498253, 'completion_length': 485.09375, 'kl': 0.00012600421905517578, 'epoch': 0.01}
  6%|‚ñã         | 13/200 [06:28<1:40:33, 32.27s/it]  7%|‚ñã         | 14/200 [07:08<1:47:58, 34.83s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0346862838992854, 'learning_rate': 5.6e-07, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.13363061845302582, 'completion_length': 574.625, 'kl': 0.0001933574676513672, 'epoch': 0.01}
  7%|‚ñã         | 14/200 [07:08<1:47:58, 34.83s/it]  8%|‚ñä         | 15/200 [08:17<2:19:11, 45.14s/it]                                                  {'loss': 0.0, 'grad_norm': 1.058442114714969, 'learning_rate': 6e-07, 'rewards/reward_correct': 0.21875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.21875, 'reward_std': 0.4218914955854416, 'completion_length': 860.5625, 'kl': 0.0001347064971923828, 'epoch': 0.01}
  8%|‚ñä         | 15/200 [08:17<2:19:11, 45.14s/it]  8%|‚ñä         | 16/200 [08:53<2:10:06, 42.43s/it]                                                  {'loss': 0.0, 'grad_norm': 1.5382953023904529, 'learning_rate': 6.4e-07, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.3966485261917114, 'completion_length': 399.65625, 'kl': 0.00010198354721069336, 'epoch': 0.01}
  8%|‚ñä         | 16/200 [08:53<2:10:06, 42.43s/it]  8%|‚ñä         | 17/200 [09:46<2:18:26, 45.39s/it]                                                  {'loss': 0.0, 'grad_norm': 2.0262208456097057, 'learning_rate': 6.800000000000001e-07, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3608423173427582, 'completion_length': 478.03125, 'kl': 0.00019359588623046875, 'epoch': 0.01}
  8%|‚ñä         | 17/200 [09:46<2:18:26, 45.39s/it]  9%|‚ñâ         | 18/200 [10:10<1:58:50, 39.18s/it]                                                  {'loss': 0.0, 'grad_norm': 1.9367359381533888, 'learning_rate': 7.2e-07, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.249358132481575, 'completion_length': 349.125, 'kl': 0.0002970695495605469, 'epoch': 0.01}
  9%|‚ñâ         | 18/200 [10:10<1:58:50, 39.18s/it] 10%|‚ñâ         | 19/200 [10:30<1:40:41, 33.38s/it]                                                  {'loss': 0.0, 'grad_norm': 2.4446407666362604, 'learning_rate': 7.599999999999999e-07, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.494472935795784, 'completion_length': 254.875, 'kl': 0.00023627281188964844, 'epoch': 0.01}
 10%|‚ñâ         | 19/200 [10:30<1:40:41, 33.38s/it] 10%|‚ñà         | 20/200 [11:12<1:47:12, 35.74s/it]                                                  {'loss': 0.0, 'grad_norm': 0.2996136700882747, 'learning_rate': 8e-07, 'rewards/reward_correct': 0.03125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.03125, 'reward_std': 0.0883883461356163, 'completion_length': 497.34375, 'kl': 0.0002499818801879883, 'epoch': 0.01}
 10%|‚ñà         | 20/200 [11:12<1:47:12, 35.74s/it] 10%|‚ñà         | 21/200 [11:29<1:30:01, 30.18s/it]                                                  {'loss': 0.0, 'grad_norm': 2.093622226513295, 'learning_rate': 8.399999999999999e-07, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.4355512708425522, 'completion_length': 292.65625, 'kl': 0.0003571510314941406, 'epoch': 0.01}
 10%|‚ñà         | 21/200 [11:29<1:30:01, 30.18s/it] 11%|‚ñà         | 22/200 [12:09<1:38:12, 33.10s/it]                                                  {'loss': 0.0, 'grad_norm': 1.9990419520171472, 'learning_rate': 8.799999999999999e-07, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.3104073107242584, 'completion_length': 463.1875, 'kl': 0.0009579658508300781, 'epoch': 0.01}
 11%|‚ñà         | 22/200 [12:09<1:38:12, 33.10s/it] 12%|‚ñà‚ñè        | 23/200 [12:25<1:22:41, 28.03s/it]                                                  {'loss': 0.0, 'grad_norm': 1.4607653591417418, 'learning_rate': 9.2e-07, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3608423173427582, 'completion_length': 295.3125, 'kl': 0.0006999969482421875, 'epoch': 0.01}
 12%|‚ñà‚ñè        | 23/200 [12:25<1:22:41, 28.03s/it] 12%|‚ñà‚ñè        | 24/200 [12:54<1:23:35, 28.50s/it]                                                  {'loss': 0.0, 'grad_norm': 1.2262677801897335, 'learning_rate': 9.6e-07, 'rewards/reward_correct': 0.21875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.21875, 'reward_std': 0.24511480331420898, 'completion_length': 437.375, 'kl': 0.0007920265197753906, 'epoch': 0.01}
 12%|‚ñà‚ñè        | 24/200 [12:54<1:23:35, 28.50s/it] 12%|‚ñà‚ñé        | 25/200 [13:17<1:18:06, 26.78s/it]                                                  {'loss': 0.0, 'grad_norm': 1.5531099987602544, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.2925042062997818, 'completion_length': 329.3125, 'kl': 0.0008182525634765625, 'epoch': 0.01}
 12%|‚ñà‚ñé        | 25/200 [13:17<1:18:06, 26.78s/it] 13%|‚ñà‚ñé        | 26/200 [13:45<1:18:21, 27.02s/it]                                                  {'loss': 0.0, 'grad_norm': 1.836483609025522, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.2041158601641655, 'completion_length': 419.15625, 'kl': 0.001346588134765625, 'epoch': 0.01}
 13%|‚ñà‚ñé        | 26/200 [13:45<1:18:21, 27.02s/it] 14%|‚ñà‚ñé        | 27/200 [14:22<1:27:04, 30.20s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1677611025260417, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.3514062538743019, 'completion_length': 374.65625, 'kl': 0.00217437744140625, 'epoch': 0.01}
 14%|‚ñà‚ñé        | 27/200 [14:22<1:27:04, 30.20s/it] 14%|‚ñà‚ñç        | 28/200 [15:10<1:41:39, 35.46s/it]                                                  {'loss': 0.0, 'grad_norm': 1.3386627827751234, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.3650856465101242, 'completion_length': 593.71875, 'kl': 0.001796722412109375, 'epoch': 0.01}
 14%|‚ñà‚ñç        | 28/200 [15:10<1:41:39, 35.46s/it] 14%|‚ñà‚ñç        | 29/200 [15:52<1:46:38, 37.42s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7667209006495099, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.09375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.09375, 'reward_std': 0.2041158601641655, 'completion_length': 690.59375, 'kl': 0.0018863677978515625, 'epoch': 0.02}
 14%|‚ñà‚ñç        | 29/200 [15:52<1:46:38, 37.42s/it] 15%|‚ñà‚ñå        | 30/200 [16:12<1:31:26, 32.27s/it]                                                  {'loss': 0.0, 'grad_norm': 1.422776856036787, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3061639815568924, 'completion_length': 260.65625, 'kl': 0.00527191162109375, 'epoch': 0.02}
 15%|‚ñà‚ñå        | 30/200 [16:12<1:31:26, 32.27s/it] 16%|‚ñà‚ñå        | 31/200 [16:34<1:21:53, 29.07s/it]                                                  {'loss': 0.0, 'grad_norm': 1.7034349436695213, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3377464786171913, 'completion_length': 434.1875, 'kl': 0.004139900207519531, 'epoch': 0.02}
 16%|‚ñà‚ñå        | 31/200 [16:34<1:21:53, 29.07s/it] 16%|‚ñà‚ñå        | 32/200 [17:13<1:30:08, 32.19s/it]                                                  {'loss': 0.0, 'grad_norm': 1.5645039880680314, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.49022960662841797, 'completion_length': 516.25, 'kl': 0.0070037841796875, 'epoch': 0.02}
 16%|‚ñà‚ñå        | 32/200 [17:13<1:30:08, 32.19s/it] 16%|‚ñà‚ñã        | 33/200 [17:46<1:29:50, 32.28s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9331668226329155, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.21875, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.25, 'reward_std': 0.2314550280570984, 'completion_length': 647.1875, 'kl': 0.0028076171875, 'epoch': 0.02}
 16%|‚ñà‚ñã        | 33/200 [17:46<1:29:50, 32.28s/it] 17%|‚ñà‚ñã        | 34/200 [18:37<1:44:57, 37.93s/it]                                                  {'loss': 0.0, 'grad_norm': 1.2556610507811343, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.4765502139925957, 'completion_length': 655.84375, 'kl': 0.007781982421875, 'epoch': 0.02}
 17%|‚ñà‚ñã        | 34/200 [18:37<1:44:57, 37.93s/it] 18%|‚ñà‚ñä        | 35/200 [19:05<1:35:58, 34.90s/it]                                                  {'loss': 0.0, 'grad_norm': 2.3372867671694317, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.34375, 'reward_std': 0.2773705795407295, 'completion_length': 484.96875, 'kl': 0.013153076171875, 'epoch': 0.02}
 18%|‚ñà‚ñä        | 35/200 [19:05<1:35:58, 34.90s/it] 18%|‚ñà‚ñä        | 36/200 [19:59<1:51:12, 40.68s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1267731008302408, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.46875, 'reward_std': 0.4189920723438263, 'completion_length': 700.25, 'kl': 0.011490821838378906, 'epoch': 0.02}
 18%|‚ñà‚ñä        | 36/200 [19:59<1:51:12, 40.68s/it] 18%|‚ñà‚ñä        | 37/200 [20:30<1:42:30, 37.74s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1551390728310749, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.1157275140285492, 'completion_length': 504.625, 'kl': 0.008144378662109375, 'epoch': 0.02}
 18%|‚ñà‚ñä        | 37/200 [20:30<1:42:30, 37.74s/it] 19%|‚ñà‚ñâ        | 38/200 [20:49<1:26:27, 32.02s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6036819087421833, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.2041158601641655, 'completion_length': 381.625, 'kl': 0.0067291259765625, 'epoch': 0.02}
 19%|‚ñà‚ñâ        | 38/200 [20:49<1:26:27, 32.02s/it] 20%|‚ñà‚ñâ        | 39/200 [21:14<1:20:55, 30.16s/it]                                                  {'loss': 0.0, 'grad_norm': 1.2838821024515341, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0625, 'reward': 0.5, 'reward_std': 0.4798540621995926, 'completion_length': 367.5625, 'kl': 0.008785247802734375, 'epoch': 0.02}
 20%|‚ñà‚ñâ        | 39/200 [21:14<1:20:55, 30.16s/it] 20%|‚ñà‚ñà        | 40/200 [22:06<1:37:25, 36.53s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9579000042468582, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.15625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.15625, 'reward_std': 0.24511480331420898, 'completion_length': 627.4375, 'kl': 0.0072460174560546875, 'epoch': 0.02}
 20%|‚ñà‚ñà        | 40/200 [22:06<1:37:25, 36.53s/it] 20%|‚ñà‚ñà        | 41/200 [23:09<1:57:50, 44.47s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5738656625707327, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.15625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.15625, 'reward_std': 0.22201896458864212, 'completion_length': 1022.6875, 'kl': 0.003376007080078125, 'epoch': 0.02}
 20%|‚ñà‚ñà        | 41/200 [23:09<1:57:50, 44.47s/it] 21%|‚ñà‚ñà        | 42/200 [23:39<1:45:26, 40.04s/it]                                                  {'loss': 0.0, 'grad_norm': 1.4436383696910822, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.3125, 'reward_std': 0.39012181013822556, 'completion_length': 553.25, 'kl': 0.0073394775390625, 'epoch': 0.02}
 21%|‚ñà‚ñà        | 42/200 [23:39<1:45:26, 40.04s/it] 22%|‚ñà‚ñà‚ñè       | 43/200 [24:13<1:40:11, 38.29s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0113067784848306, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3061639815568924, 'completion_length': 474.25, 'kl': 0.00835418701171875, 'epoch': 0.02}
 22%|‚ñà‚ñà‚ñè       | 43/200 [24:13<1:40:11, 38.29s/it] 22%|‚ñà‚ñà‚ñè       | 44/200 [24:49<1:37:46, 37.61s/it]                                                  {'loss': 0.0, 'grad_norm': 1.3778229770062655, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.3335031494498253, 'completion_length': 430.90625, 'kl': 0.0226287841796875, 'epoch': 0.02}
 22%|‚ñà‚ñà‚ñè       | 44/200 [24:49<1:37:46, 37.61s/it] 22%|‚ñà‚ñà‚ñé       | 45/200 [25:49<1:54:38, 44.38s/it]                                                  {'loss': 0.0, 'grad_norm': 1.575913257145941, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.40625, 'reward_std': 0.3787454217672348, 'completion_length': 990.15625, 'kl': 0.014596939086914062, 'epoch': 0.02}
 22%|‚ñà‚ñà‚ñé       | 45/200 [25:49<1:54:38, 44.38s/it] 23%|‚ñà‚ñà‚ñé       | 46/200 [26:31<1:52:19, 43.76s/it]                                                  {'loss': 0.0, 'grad_norm': 1.094594064808797, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.625, 'reward_std': 0.4671337679028511, 'completion_length': 553.625, 'kl': 0.0120697021484375, 'epoch': 0.02}
 23%|‚ñà‚ñà‚ñé       | 46/200 [26:31<1:52:19, 43.76s/it] 24%|‚ñà‚ñà‚ñé       | 47/200 [26:50<1:32:33, 36.30s/it]                                                  {'loss': 0.0, 'grad_norm': 1.744781614778907, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.4534739926457405, 'completion_length': 331.15625, 'kl': 0.01300048828125, 'epoch': 0.03}
 24%|‚ñà‚ñà‚ñé       | 47/200 [26:50<1:32:33, 36.30s/it] 24%|‚ñà‚ñà‚ñç       | 48/200 [27:26<1:31:38, 36.17s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8291172104147944, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.2314550280570984, 'completion_length': 569.46875, 'kl': 0.01332855224609375, 'epoch': 0.03}
 24%|‚ñà‚ñà‚ñç       | 48/200 [27:26<1:31:38, 36.17s/it] 24%|‚ñà‚ñà‚ñç       | 49/200 [28:07<1:34:25, 37.52s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8721924242865241, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.24511480331420898, 'completion_length': 537.03125, 'kl': 0.00997161865234375, 'epoch': 0.03}
 24%|‚ñà‚ñà‚ñç       | 49/200 [28:07<1:34:25, 37.52s/it] 25%|‚ñà‚ñà‚ñå       | 50/200 [28:58<1:44:02, 41.61s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8600917374592546, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3471629247069359, 'completion_length': 591.5625, 'kl': 0.01371002197265625, 'epoch': 0.03}
 25%|‚ñà‚ñà‚ñå       | 50/200 [28:58<1:44:02, 41.61s/it] 26%|‚ñà‚ñà‚ñå       | 51/200 [30:41<2:29:14, 60.10s/it]                                                  {'loss': 0.0, 'grad_norm': 1.268818312569821, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3061639815568924, 'completion_length': 398.28125, 'kl': 0.02133941650390625, 'epoch': 0.03}
 26%|‚ñà‚ñà‚ñå       | 51/200 [30:41<2:29:14, 60.10s/it] 26%|‚ñà‚ñà‚ñå       | 52/200 [31:19<2:12:01, 53.52s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6981968653021834, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2041158601641655, 'completion_length': 660.59375, 'kl': 0.00951385498046875, 'epoch': 0.03}
 26%|‚ñà‚ñà‚ñå       | 52/200 [31:19<2:12:01, 53.52s/it] 26%|‚ñà‚ñà‚ñã       | 53/200 [32:02<2:03:13, 50.30s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7571732085661225, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.4218914955854416, 'completion_length': 802.53125, 'kl': 0.00766754150390625, 'epoch': 0.03}
 26%|‚ñà‚ñà‚ñã       | 53/200 [32:02<2:03:13, 50.30s/it] 27%|‚ñà‚ñà‚ñã       | 54/200 [32:20<1:38:54, 40.65s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8989426648526644, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3061639815568924, 'completion_length': 406.09375, 'kl': 0.0160064697265625, 'epoch': 0.03}
 27%|‚ñà‚ñà‚ñã       | 54/200 [32:20<1:38:54, 40.65s/it] 28%|‚ñà‚ñà‚ñä       | 55/200 [33:07<1:43:00, 42.63s/it]                                                  {'loss': 0.0, 'grad_norm': 4.874430795516221, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.2587745785713196, 'completion_length': 815.1875, 'kl': 0.014530181884765625, 'epoch': 0.03}
 28%|‚ñà‚ñà‚ñä       | 55/200 [33:07<1:43:00, 42.63s/it] 28%|‚ñà‚ñà‚ñä       | 56/200 [33:55<1:46:03, 44.19s/it]                                                  {'loss': 0.0, 'grad_norm': 1.100545183049532, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.5175491571426392, 'completion_length': 627.0, 'kl': 0.01275634765625, 'epoch': 0.03}
 28%|‚ñà‚ñà‚ñä       | 56/200 [33:55<1:46:03, 44.19s/it] 28%|‚ñà‚ñà‚ñä       | 57/200 [34:27<1:36:18, 40.41s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9789117415295445, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.4355708882212639, 'completion_length': 609.40625, 'kl': 0.010195732116699219, 'epoch': 0.03}
 28%|‚ñà‚ñà‚ñä       | 57/200 [34:27<1:36:18, 40.41s/it] 29%|‚ñà‚ñà‚ñâ       | 58/200 [35:23<1:47:05, 45.25s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9784972921358082, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.28125, 'reward_std': 0.4218914955854416, 'completion_length': 859.1875, 'kl': 0.014046669006347656, 'epoch': 0.03}
 29%|‚ñà‚ñà‚ñâ       | 58/200 [35:23<1:47:05, 45.25s/it] 30%|‚ñà‚ñà‚ñâ       | 59/200 [35:46<1:30:02, 38.32s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9444863351060594, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.3608423173427582, 'completion_length': 529.375, 'kl': 0.0077362060546875, 'epoch': 0.03}
 30%|‚ñà‚ñà‚ñâ       | 59/200 [35:46<1:30:02, 38.32s/it] 30%|‚ñà‚ñà‚ñà       | 60/200 [36:22<1:28:22, 37.88s/it]                                                  {'loss': 0.0, 'grad_norm': 0.548786508364556, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.1293872892856598, 'completion_length': 623.625, 'kl': 0.0178985595703125, 'epoch': 0.03}
 30%|‚ñà‚ñà‚ñà       | 60/200 [36:22<1:28:22, 37.88s/it] 30%|‚ñà‚ñà‚ñà       | 61/200 [36:53<1:22:34, 35.65s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0791596973869042, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.4671337679028511, 'completion_length': 482.4375, 'kl': 0.0294952392578125, 'epoch': 0.03}
 30%|‚ñà‚ñà‚ñà       | 61/200 [36:53<1:22:34, 35.65s/it] 31%|‚ñà‚ñà‚ñà       | 62/200 [37:32<1:24:35, 36.78s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9997539368741925, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.35564958304166794, 'completion_length': 603.5, 'kl': 0.012054443359375, 'epoch': 0.03}
 31%|‚ñà‚ñà‚ñà       | 62/200 [37:32<1:24:35, 36.78s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [38:37<1:43:29, 45.32s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5498492515743879, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.3061639815568924, 'completion_length': 880.15625, 'kl': 0.016510009765625, 'epoch': 0.03}
 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [38:37<1:43:29, 45.32s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [39:25<1:44:25, 46.07s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7160061159998679, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.0625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.0625, 'reward_std': 0.1157275140285492, 'completion_length': 826.375, 'kl': 0.010711669921875, 'epoch': 0.03}
 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [39:25<1:44:25, 46.07s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [40:07<1:40:39, 44.74s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0722178469165449, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.4671337679028511, 'completion_length': 588.15625, 'kl': 0.02486419677734375, 'epoch': 0.03}
 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [40:07<1:40:39, 44.74s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [40:44<1:35:04, 42.57s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7944421281429115, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.0883883461356163, 'completion_length': 715.0625, 'kl': 0.0191192626953125, 'epoch': 0.04}
 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [40:44<1:35:04, 42.57s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [41:26<1:33:23, 42.13s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8238941220157192, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3608423173427582, 'completion_length': 651.125, 'kl': 0.014404296875, 'epoch': 0.04}
 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [41:26<1:33:23, 42.13s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [42:03<1:29:42, 40.78s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5713571897732854, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.0883883461356163, 'completion_length': 557.625, 'kl': 0.027557373046875, 'epoch': 0.04}
 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [42:03<1:29:42, 40.78s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [42:23<1:15:08, 34.41s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1033332197146664, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.49022960662841797, 'completion_length': 462.96875, 'kl': 0.013153076171875, 'epoch': 0.04}
 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [42:23<1:15:08, 34.41s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [43:03<1:18:16, 36.13s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9753210334781636, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.59375, 'reward_std': 0.3808925524353981, 'completion_length': 657.59375, 'kl': 0.031097412109375, 'epoch': 0.04}
 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [43:03<1:18:16, 36.13s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [43:22<1:06:56, 31.13s/it]                                                  {'loss': 0.0001, 'grad_norm': 1.066115444855071, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3945523276925087, 'completion_length': 419.75, 'kl': 0.10251617431640625, 'epoch': 0.04}
 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [43:22<1:06:56, 31.13s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [44:03<1:12:36, 34.04s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0858342172571098, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.3966485261917114, 'completion_length': 669.40625, 'kl': 0.012699127197265625, 'epoch': 0.04}
 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [44:03<1:12:36, 34.04s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [45:19<1:38:32, 46.56s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6238432847038808, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.0625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.0625, 'reward_std': 0.1767766922712326, 'completion_length': 1255.15625, 'kl': 0.0030364990234375, 'epoch': 0.04}
 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [45:19<1:38:32, 46.56s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [46:10<1:40:34, 47.89s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5026391514073743, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2630179077386856, 'completion_length': 703.8125, 'kl': 0.01735687255859375, 'epoch': 0.04}
 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [46:10<1:40:34, 47.89s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [47:16<1:50:53, 53.22s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7394053870950826, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.4807935431599617, 'completion_length': 921.84375, 'kl': 0.020263671875, 'epoch': 0.04}
 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [47:16<1:50:53, 53.22s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [47:38<1:30:53, 43.98s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1273863622459555, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.4218914955854416, 'completion_length': 598.46875, 'kl': 0.01862335205078125, 'epoch': 0.04}
 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [47:38<1:30:53, 43.98s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [48:28<1:33:55, 45.82s/it]                                                  {'loss': 0.0, 'grad_norm': 0.695952577574452, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.4765502139925957, 'completion_length': 872.96875, 'kl': 0.0123443603515625, 'epoch': 0.04}
 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [48:28<1:33:55, 45.82s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [49:10<1:30:54, 44.71s/it]                                                  {'loss': 0.0, 'grad_norm': 1.0241609914553758, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.4628904387354851, 'completion_length': 739.4375, 'kl': 0.006420135498046875, 'epoch': 0.04}
 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [49:10<1:30:54, 44.71s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [49:40<1:21:08, 40.24s/it]                                                  {'loss': 0.0002, 'grad_norm': 0.6884144516716028, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.24511480331420898, 'completion_length': 412.5, 'kl': 0.1702880859375, 'epoch': 0.04}
 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [49:40<1:21:08, 40.24s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [50:07<1:12:42, 36.35s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8267421978821488, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2925042062997818, 'completion_length': 631.40625, 'kl': 0.022064208984375, 'epoch': 0.04}
 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [50:07<1:12:42, 36.35s/it]Timeout during comparison
 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [50:48<1:14:52, 37.75s/it]                                                  {'loss': 0.0, 'grad_norm': 1.1693914134744017, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.21875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.21875, 'reward_std': 0.3471629247069359, 'completion_length': 576.21875, 'kl': 0.024871826171875, 'epoch': 0.04}
 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [50:48<1:14:52, 37.75s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [51:33<1:18:32, 39.94s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5923562805857084, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.24511480331420898, 'completion_length': 866.28125, 'kl': 0.01401519775390625, 'epoch': 0.04}
 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [51:33<1:18:32, 39.94s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [51:57<1:08:13, 34.99s/it]                                                  {'loss': 0.0, 'grad_norm': 0.7340607698824481, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.38298875093460083, 'completion_length': 614.15625, 'kl': 0.024078369140625, 'epoch': 0.04}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [51:57<1:08:13, 34.99s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [52:15<58:04, 30.04s/it]                                                  {'loss': 0.0, 'grad_norm': 1.017816225359758, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.4492306634783745, 'completion_length': 430.28125, 'kl': 0.028717041015625, 'epoch': 0.04}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [52:15<58:04, 30.04s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [53:00<1:05:44, 34.30s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6287065868247752, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.3198433741927147, 'completion_length': 796.0, 'kl': 0.0252838134765625, 'epoch': 0.05}
 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [53:00<1:05:44, 34.30s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [53:36<1:06:25, 34.96s/it]                                                  {'loss': 0.0, 'grad_norm': 0.6558634327805106, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.22201896458864212, 'completion_length': 582.78125, 'kl': 0.0200042724609375, 'epoch': 0.05}
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [53:36<1:06:25, 34.96s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [54:07<1:03:44, 33.84s/it]                                                  {'loss': 0.0, 'grad_norm': 1.2047160917421418, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.3745020925998688, 'completion_length': 571.46875, 'kl': 0.0283203125, 'epoch': 0.05}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [54:07<1:03:44, 33.84s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [55:11<1:20:11, 42.96s/it]                                                  {'loss': 0.0, 'grad_norm': 0.3304476997815507, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.1767766922712326, 'completion_length': 1196.03125, 'kl': 0.0168914794921875, 'epoch': 0.05}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [55:12<1:20:11, 42.96s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [56:07<1:26:42, 46.87s/it]                                                  {'loss': 0.0, 'grad_norm': 0.9045689916634241, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.3335031494498253, 'completion_length': 810.90625, 'kl': 0.031890869140625, 'epoch': 0.05}
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [56:07<1:26:42, 46.87s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [56:54<1:25:46, 46.78s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5374420737314201, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.24511480331420898, 'completion_length': 790.84375, 'kl': 0.0174102783203125, 'epoch': 0.05}
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [56:54<1:25:46, 46.78s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [57:34<1:21:09, 44.67s/it]                                                  {'loss': 0.0, 'grad_norm': 0.8518319095040651, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.408231720328331, 'completion_length': 714.90625, 'kl': 0.0167999267578125, 'epoch': 0.05}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [57:34<1:21:09, 44.67s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [58:18<1:19:54, 44.39s/it]                                                  {'loss': 0.0, 'grad_norm': 0.5557638154011966, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.2925042062997818, 'completion_length': 924.75, 'kl': 0.0443572998046875, 'epoch': 0.05}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [58:18<1:19:54, 44.39s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [58:55<1:15:16, 42.21s/it]                                                  {'loss': 0.0007, 'grad_norm': 0.9115610249814775, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.22201896458864212, 'completion_length': 858.9375, 'kl': 0.7469482421875, 'epoch': 0.05}
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [58:55<1:15:16, 42.21s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [1:00:00<1:26:38, 49.04s/it]                                                    {'loss': 0.0, 'grad_norm': 0.4877131442594071, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.2314550280570984, 'completion_length': 1107.125, 'kl': 0.014739990234375, 'epoch': 0.05}
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [1:00:00<1:26:38, 49.04s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [1:00:50<1:26:39, 49.52s/it]                                                    {'loss': 0.0, 'grad_norm': 0.2181250822808175, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.13363061845302582, 'completion_length': 1269.03125, 'kl': 0.0139312744140625, 'epoch': 0.05}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [1:00:50<1:26:39, 49.52s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [1:01:33<1:22:22, 47.52s/it]                                                    {'loss': 0.0002, 'grad_norm': 0.9483745644126913, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.408231720328331, 'completion_length': 658.09375, 'kl': 0.159576416015625, 'epoch': 0.05}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [1:01:33<1:22:22, 47.52s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [1:02:10<1:16:07, 44.34s/it]                                                    {'loss': 0.0001, 'grad_norm': 1.082316160976102, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.1767766922712326, 'completion_length': 673.90625, 'kl': 0.100189208984375, 'epoch': 0.05}
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [1:02:10<1:16:07, 44.34s/it]Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
    for g, p in zip(sorted(solved_gold), sorted(solved_pred))
TypeError: '<' not supported between instances of 'dict' and 'dict'
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
    for g, p in zip(sorted(solved_gold), sorted(solved_pred))
TypeError: '<' not supported between instances of 'dict' and 'dict'
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
    for g, p in zip(sorted(solved_gold), sorted(solved_pred))
TypeError: '<' not supported between instances of 'dict' and 'dict'
Error during comparison
Traceback (most recent call last):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 809, in compare_single_extraction_wrapper
    return compare_single_extraction(g, t)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/utils.py", line 51, in wrapper
    return func(*args, **kwargs)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 789, in compare_single_extraction
    return sympy_expr_eq(
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 667, in sympy_expr_eq
    return sympy_compare_relational(gold, pred, float_rounding, numeric_precision)
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 344, in sympy_compare_relational
    if sympy_solve_and_compare(gold, pred, float_rounding, numeric_precision):
  File "/home/VRL/env/lib/python3.10/site-packages/math_verify/grader.py", line 284, in sympy_solve_and_compare
    for g, p in zip(sorted(solved_gold), sorted(solved_pred))
TypeError: '<' not supported between instances of 'dict' and 'dict'
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [1:03:26<1:31:17, 53.70s/it]                                                    {'loss': 0.0, 'grad_norm': 0.7598122974956995, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.3608423173427582, 'completion_length': 1187.0625, 'kl': 0.01861572265625, 'epoch': 0.05}
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [1:03:26<1:31:17, 53.70s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [1:03:47<1:14:13, 44.09s/it]                                                    {'loss': 0.0001, 'grad_norm': 0.5303314798193288, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.249358132481575, 'completion_length': 521.65625, 'kl': 0.0553741455078125, 'epoch': 0.05}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [1:03:47<1:14:13, 44.09s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [1:04:23<1:09:26, 41.67s/it]                                                     {'loss': 0.0, 'grad_norm': 0.41968592278358635, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.2630179077386856, 'completion_length': 819.09375, 'kl': 0.0221099853515625, 'epoch': 0.05}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [1:04:23<1:09:26, 41.67s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [1:06:12<1:41:58, 61.80s/it]                                                     {'loss': 0.0, 'grad_norm': 0.7860233335332707, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.3650856465101242, 'completion_length': 651.84375, 'kl': 0.01387786865234375, 'epoch': 0.05}
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [1:06:12<1:41:58, 61.80s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [1:07:12<1:39:56, 61.19s/it]                                                     {'loss': 0.0, 'grad_norm': 0.5117690123708547, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.24511480331420898, 'completion_length': 1098.21875, 'kl': 0.026458740234375, 'epoch': 0.05}
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [1:07:12<1:39:56, 61.19s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [1:08:04<1:34:22, 58.38s/it]                                                     {'loss': 0.0, 'grad_norm': 0.6995567395349305, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.03125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.03125, 'reward_std': 0.0883883461356163, 'completion_length': 1068.34375, 'kl': 0.02655029296875, 'epoch': 0.05}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [1:08:04<1:34:22, 58.38s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [1:08:35<1:20:14, 50.15s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.2880782378139373, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.59375, 'reward_std': 0.47137709707021713, 'completion_length': 755.71875, 'kl': 0.0512847900390625, 'epoch': 0.06}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [1:08:35<1:20:14, 50.15s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [1:09:02<1:08:25, 43.21s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.9197903555000416, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.24511480331420898, 'completion_length': 525.96875, 'kl': 0.0628662109375, 'epoch': 0.06}
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [1:09:02<1:08:25, 43.21s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [1:09:38<1:04:23, 41.10s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8615981020623379, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3198433741927147, 'completion_length': 608.6875, 'kl': 0.10467910766601562, 'epoch': 0.06}
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [1:09:38<1:04:23, 41.10s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [1:09:56<53:09, 34.30s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.5725323771574178, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3335031494498253, 'completion_length': 316.84375, 'kl': 0.12518310546875, 'epoch': 0.06}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [1:09:56<53:09, 34.30s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [1:10:32<53:11, 34.69s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.9958520751598892, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.494472935795784, 'completion_length': 592.40625, 'kl': 0.057708740234375, 'epoch': 0.06}
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [1:10:32<53:11, 34.69s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [1:11:34<1:04:58, 42.84s/it]                                                     {'loss': 0.0, 'grad_norm': 0.2931347101279495, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.15625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.15625, 'reward_std': 0.1293872892856598, 'completion_length': 1088.84375, 'kl': 0.016819000244140625, 'epoch': 0.06}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [1:11:34<1:04:58, 42.84s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [1:12:28<1:09:14, 46.16s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.6406862739090963, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.3745020925998688, 'completion_length': 880.21875, 'kl': 0.057373046875, 'epoch': 0.06}
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [1:12:28<1:09:14, 46.16s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [1:13:05<1:04:23, 43.41s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8193722443123839, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3514062538743019, 'completion_length': 631.40625, 'kl': 0.095428466796875, 'epoch': 0.06}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [1:13:05<1:04:23, 43.41s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [1:13:59<1:08:40, 46.83s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.8820037474096379, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.408231720328331, 'completion_length': 876.8125, 'kl': 0.107635498046875, 'epoch': 0.06}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [1:13:59<1:08:40, 46.83s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [1:14:20<56:32, 39.00s/it]                                                     {'loss': 0.0001, 'grad_norm': 1.1232257224638769, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2041158601641655, 'completion_length': 557.21875, 'kl': 0.06536865234375, 'epoch': 0.06}
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [1:14:20<56:32, 39.00s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [1:14:54<53:48, 37.54s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5170567466046635, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.3471825420856476, 'completion_length': 801.125, 'kl': 0.017675399780273438, 'epoch': 0.06}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [1:14:54<53:48, 37.54s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [1:15:28<51:29, 36.34s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5759330928819071, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1767766922712326, 'completion_length': 742.5625, 'kl': 0.0880279541015625, 'epoch': 0.06}
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [1:15:28<51:29, 36.34s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [1:16:16<56:03, 40.04s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6584711279156413, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2587745785713196, 'completion_length': 1059.5, 'kl': 0.04170989990234375, 'epoch': 0.06}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [1:16:16<56:03, 40.04s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [1:17:15<1:03:13, 45.70s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.5872823952230961, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.1157275140285492, 'completion_length': 946.59375, 'kl': 0.056118011474609375, 'epoch': 0.06}
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [1:17:15<1:03:13, 45.70s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [1:17:38<52:56, 38.74s/it]                                                     {'loss': 0.0001, 'grad_norm': 0.05133877582938133, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.0, 'completion_length': 589.90625, 'kl': 0.121978759765625, 'epoch': 0.06}
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [1:17:38<52:56, 38.74s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [1:18:16<52:01, 38.54s/it]                                                   {'loss': 0.0008, 'grad_norm': 0.924812747386556, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3377464786171913, 'completion_length': 659.5625, 'kl': 0.779449462890625, 'epoch': 0.06}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [1:18:16<52:01, 38.54s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [1:19:09<57:11, 42.90s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8236485729515942, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3650856465101242, 'completion_length': 669.78125, 'kl': 0.0535888671875, 'epoch': 0.06}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [1:19:09<57:11, 42.90s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [1:19:27<46:39, 35.44s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.9369174690490826, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 401.8125, 'kl': 0.4665374755859375, 'epoch': 0.06}
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [1:19:27<46:39, 35.44s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [1:19:51<41:42, 32.08s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.6427310576481498, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.2041158601641655, 'completion_length': 478.59375, 'kl': 0.082550048828125, 'epoch': 0.07}
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [1:19:51<41:42, 32.08s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [1:20:27<42:29, 33.11s/it]                                                   {'loss': 0.0, 'grad_norm': 1.2565778595198962, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.249358132481575, 'completion_length': 758.96875, 'kl': 0.04815673828125, 'epoch': 0.07}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [1:20:27<42:29, 33.11s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [1:21:07<44:31, 35.14s/it]                                                   {'loss': 0.0, 'grad_norm': 1.059993528742348, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.125, 'reward_std': 0.2925042062997818, 'completion_length': 581.78125, 'kl': 0.032012939453125, 'epoch': 0.07}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [1:21:07<44:31, 35.14s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [1:21:59<50:12, 40.17s/it]                                                   {'loss': 0.0, 'grad_norm': 0.9080177653929598, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.3471825420856476, 'completion_length': 985.09375, 'kl': 0.02617645263671875, 'epoch': 0.07}
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [1:21:59<50:12, 40.17s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [1:22:14<40:18, 32.68s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.2179072114229954, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3335031494498253, 'completion_length': 321.75, 'kl': 0.33489990234375, 'epoch': 0.07}
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [1:22:14<40:18, 32.68s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [1:22:54<42:26, 34.89s/it]                                                   {'loss': 0.0001, 'grad_norm': 1.2226250442689512, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3608423173427582, 'completion_length': 637.59375, 'kl': 0.0532684326171875, 'epoch': 0.07}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [1:22:54<42:26, 34.89s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [1:23:46<48:04, 40.07s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5416248468919708, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.2177756354212761, 'completion_length': 835.75, 'kl': 0.02161407470703125, 'epoch': 0.07}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [1:23:46<48:04, 40.07s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [1:24:13<42:46, 36.15s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5489900734757042, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.1157275140285492, 'completion_length': 476.0, 'kl': 0.0313873291015625, 'epoch': 0.07}
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [1:24:13<42:46, 36.15s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [1:24:41<39:22, 33.75s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4579238194820861, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2630179077386856, 'completion_length': 577.09375, 'kl': 0.0162200927734375, 'epoch': 0.07}
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [1:24:41<39:22, 33.75s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [1:25:05<35:26, 30.81s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7665342508533828, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.40625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.40625, 'reward_std': 0.3061639815568924, 'completion_length': 651.09375, 'kl': 0.040081024169921875, 'epoch': 0.07}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [1:25:05<35:26, 30.81s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [1:25:33<33:58, 29.98s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5981381797307279, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.22201896458864212, 'completion_length': 618.125, 'kl': 0.034847259521484375, 'epoch': 0.07}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [1:25:33<33:58, 29.98s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [1:25:55<30:51, 27.63s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1104147060126104, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3104073107242584, 'completion_length': 468.03125, 'kl': 0.394744873046875, 'epoch': 0.07}
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [1:25:55<30:51, 27.63s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [1:26:40<36:00, 32.73s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7169660412116869, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.25, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.25, 'reward_std': 0.3335031494498253, 'completion_length': 1038.8125, 'kl': 0.019561767578125, 'epoch': 0.07}
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [1:26:40<36:00, 32.73s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [1:27:32<41:41, 38.48s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8019811107642837, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.2925042062997818, 'completion_length': 944.03125, 'kl': 0.075897216796875, 'epoch': 0.07}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [1:27:32<41:41, 38.48s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [1:28:08<40:20, 37.83s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8413352841936299, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.24511480331420898, 'completion_length': 650.375, 'kl': 0.0715789794921875, 'epoch': 0.07}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [1:28:08<40:20, 37.83s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [1:28:41<38:01, 36.22s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7193067317846138, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.2651650384068489, 'completion_length': 533.21875, 'kl': 0.036041259765625, 'epoch': 0.07}
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [1:28:41<38:01, 36.22s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [1:29:27<40:29, 39.18s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.41320091799367503, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.21875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.21875, 'reward_std': 0.2041158601641655, 'completion_length': 1149.59375, 'kl': 0.1210784912109375, 'epoch': 0.07}
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [1:29:27<40:29, 39.18s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [1:29:59<37:47, 37.16s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.7749714951786459, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.249358132481575, 'completion_length': 915.75, 'kl': 0.474884033203125, 'epoch': 0.07}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [1:29:59<37:47, 37.16s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [1:30:27<34:19, 34.32s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8685033835917839, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.2177756354212761, 'completion_length': 708.1875, 'kl': 0.04595947265625, 'epoch': 0.07}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [1:30:27<34:19, 34.32s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [1:30:42<28:03, 28.53s/it]                                                   {'loss': 0.0002, 'grad_norm': 1.562616390106974, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3377464786171913, 'completion_length': 327.8125, 'kl': 0.232269287109375, 'epoch': 0.08}
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [1:30:42<28:03, 28.53s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [1:31:21<30:32, 31.60s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6776211270056186, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5625, 'reward_std': 0.3335031494498253, 'completion_length': 701.4375, 'kl': 0.0465850830078125, 'epoch': 0.08}
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [1:31:21<30:32, 31.60s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [1:31:43<27:27, 28.91s/it]                                                   {'loss': 0.0, 'grad_norm': 0.539379009443993, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.2651650384068489, 'completion_length': 555.375, 'kl': 0.03375244140625, 'epoch': 0.08}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [1:31:43<27:27, 28.91s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [1:32:01<23:48, 25.50s/it]                                                   {'loss': 0.0, 'grad_norm': 1.1242939096004432, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.3335031494498253, 'completion_length': 438.0, 'kl': 0.03792572021484375, 'epoch': 0.08}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [1:32:01<23:48, 25.50s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [1:32:37<26:26, 28.84s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.408338493681116, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.249358132481575, 'completion_length': 737.0, 'kl': 0.1534423828125, 'epoch': 0.08}
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [1:32:37<26:26, 28.84s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [1:33:22<30:12, 33.56s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6400826541541987, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.3787454217672348, 'completion_length': 844.5625, 'kl': 0.0155487060546875, 'epoch': 0.08}
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [1:33:22<30:12, 33.56s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [1:33:58<30:09, 34.14s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8373145356394615, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.3471629247069359, 'completion_length': 809.90625, 'kl': 0.10546875, 'epoch': 0.08}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [1:33:58<30:09, 34.14s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [1:35:01<37:15, 42.99s/it]                                                   {'loss': 0.0001, 'grad_norm': 1.0073857246840163, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.4492306634783745, 'completion_length': 826.65625, 'kl': 0.114776611328125, 'epoch': 0.08}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [1:35:01<37:15, 42.99s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [1:35:18<29:56, 35.22s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.6968710844667696, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.2177756354212761, 'completion_length': 437.6875, 'kl': 0.1265869140625, 'epoch': 0.08}
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [1:35:18<29:56, 35.22s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [1:36:13<34:18, 41.17s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5008323436585957, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.3471629247069359, 'completion_length': 1010.40625, 'kl': 0.09149169921875, 'epoch': 0.08}
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [1:36:13<34:18, 41.17s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [1:38:30<56:57, 69.74s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5524492747070159, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.1767766922712326, 'completion_length': 842.9375, 'kl': 0.057346343994140625, 'epoch': 0.08}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [1:38:30<56:57, 69.74s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [1:39:17<50:18, 62.88s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5365274990721924, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2925042062997818, 'completion_length': 902.03125, 'kl': 0.09539794921875, 'epoch': 0.08}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [1:39:17<50:18, 62.88s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [1:40:12<47:26, 60.56s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6302560428891227, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.1875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.1875, 'reward_std': 0.2177756354212761, 'completion_length': 1096.0, 'kl': 0.0175018310546875, 'epoch': 0.08}
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [1:40:12<47:26, 60.56s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [1:40:45<40:10, 52.39s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.22132172858630925, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1157275140285492, 'completion_length': 714.78125, 'kl': 0.053924560546875, 'epoch': 0.08}
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [1:40:45<40:10, 52.39s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [1:41:11<33:19, 44.43s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5453433617022286, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 509.59375, 'kl': 0.119537353515625, 'epoch': 0.08}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [1:41:11<33:19, 44.43s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [1:41:50<31:23, 42.81s/it]                                                   {'loss': 0.0, 'grad_norm': 0.505798228611487, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.78125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.78125, 'reward_std': 0.3061639815568924, 'completion_length': 665.78125, 'kl': 0.03314208984375, 'epoch': 0.08}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [1:41:50<31:23, 42.81s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [1:42:04<24:27, 34.12s/it]                                                   {'loss': 0.0003, 'grad_norm': 1.3241559217120538, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.3535533845424652, 'completion_length': 314.65625, 'kl': 0.303070068359375, 'epoch': 0.08}
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [1:42:04<24:27, 34.12s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [1:42:42<24:41, 35.27s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3964274307914988, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.1767766922712326, 'completion_length': 844.65625, 'kl': 0.038238525390625, 'epoch': 0.08}
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [1:42:42<24:41, 35.27s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [1:43:05<21:33, 31.55s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8211446738930855, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.4218914955854416, 'completion_length': 638.90625, 'kl': 0.0307159423828125, 'epoch': 0.08}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [1:43:05<21:33, 31.55s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [1:43:54<24:31, 36.80s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7456494056362519, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.53125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.53125, 'reward_std': 0.4628904387354851, 'completion_length': 1004.09375, 'kl': 0.028472900390625, 'epoch': 0.09}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [1:43:54<24:31, 36.80s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [1:44:33<24:20, 37.46s/it]                                                   {'loss': 0.0, 'grad_norm': 0.5326099571131647, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.2177756354212761, 'completion_length': 729.1875, 'kl': 0.014892578125, 'epoch': 0.09}
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [1:44:33<24:20, 37.46s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [1:45:45<30:17, 47.82s/it]                                                   {'loss': 0.0, 'grad_norm': 0.48957504560061993, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.2041158601641655, 'completion_length': 1050.5, 'kl': 0.0431671142578125, 'epoch': 0.09}
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [1:45:45<30:17, 47.82s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [1:46:10<25:21, 41.13s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.7442407225869118, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.03125, 'reward': 0.625, 'reward_std': 0.2177756354212761, 'completion_length': 590.5, 'kl': 0.0792388916015625, 'epoch': 0.09}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [1:46:10<25:21, 41.13s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [1:47:03<26:50, 44.74s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.9640475901349383, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.3125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.3125, 'reward_std': 0.3514062538743019, 'completion_length': 848.03125, 'kl': 0.08233642578125, 'epoch': 0.09}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [1:47:03<26:50, 44.74s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [1:47:41<24:47, 42.50s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8467532310506312, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.2651650384068489, 'completion_length': 896.625, 'kl': 0.086761474609375, 'epoch': 0.09}
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [1:47:41<24:47, 42.50s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [1:47:56<19:24, 34.26s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8005252593943238, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.3745020925998688, 'completion_length': 373.03125, 'kl': 0.1396484375, 'epoch': 0.09}
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [1:47:56<19:24, 34.26s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [1:48:12<15:55, 28.95s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.752523677802522, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.2041158601641655, 'completion_length': 353.15625, 'kl': 0.06573486328125, 'epoch': 0.09}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [1:48:12<15:55, 28.95s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [1:48:39<15:10, 28.44s/it]                                                   {'loss': 0.0002, 'grad_norm': 1.1915310926127223, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.2651650384068489, 'completion_length': 363.78125, 'kl': 0.16357421875, 'epoch': 0.09}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [1:48:39<15:10, 28.44s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [1:49:02<13:49, 26.74s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.6854325568911378, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.1767766922712326, 'completion_length': 638.15625, 'kl': 0.067962646484375, 'epoch': 0.09}
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [1:49:02<13:49, 26.74s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [1:49:40<14:59, 29.97s/it]                                                   {'loss': 0.0, 'grad_norm': 1.1145241074626617, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.75, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.75, 'reward_std': 0.2925042062997818, 'completion_length': 664.40625, 'kl': 0.0490570068359375, 'epoch': 0.09}
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [1:49:40<14:59, 29.97s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [1:50:08<14:13, 29.43s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6449830140058661, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.1157275140285492, 'completion_length': 702.28125, 'kl': 0.04522705078125, 'epoch': 0.09}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [1:50:08<14:13, 29.43s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [1:50:44<14:41, 31.47s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6826582971659036, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.22201896458864212, 'completion_length': 658.65625, 'kl': 0.02980804443359375, 'epoch': 0.09}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [1:50:44<14:41, 31.47s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [1:51:03<12:24, 27.57s/it]                                                   {'loss': 0.0, 'grad_norm': 0.2599919476218901, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.13363061845302582, 'completion_length': 475.3125, 'kl': 0.0375518798828125, 'epoch': 0.09}
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [1:51:03<12:24, 27.57s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [1:51:23<11:04, 25.56s/it]                                                   {'loss': 0.0001, 'grad_norm': 1.239248163268987, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.5081327110528946, 'completion_length': 466.21875, 'kl': 0.079315185546875, 'epoch': 0.09}
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [1:51:23<11:04, 25.56s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [1:52:01<12:12, 29.30s/it]                                                   {'loss': 0.0, 'grad_norm': 0.7220163952377067, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.24511480331420898, 'completion_length': 774.78125, 'kl': 0.03290557861328125, 'epoch': 0.09}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [1:52:01<12:12, 29.30s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [1:52:33<12:00, 30.00s/it]                                                   {'loss': 0.0002, 'grad_norm': 1.2088267160109882, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3608423173427582, 'completion_length': 479.15625, 'kl': 0.1544647216796875, 'epoch': 0.09}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [1:52:33<12:00, 30.00s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [1:53:06<11:50, 30.89s/it]                                                   {'loss': 0.0003, 'grad_norm': 0.6726706915595676, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.2177756354212761, 'completion_length': 739.75, 'kl': 0.2506256103515625, 'epoch': 0.09}
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [1:53:06<11:50, 30.89s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [1:53:38<11:24, 31.12s/it]                                                   {'loss': 0.0, 'grad_norm': 0.3542491421573987, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.15625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.15625, 'reward_std': 0.1293872892856598, 'completion_length': 740.46875, 'kl': 0.0181884765625, 'epoch': 0.09}
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [1:53:38<11:24, 31.12s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [1:54:02<10:10, 29.09s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.4123999893829007, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.249358132481575, 'completion_length': 656.21875, 'kl': 0.08465576171875, 'epoch': 0.1}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [1:54:02<10:10, 29.09s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [1:54:15<08:05, 24.27s/it]                                                   {'loss': 0.0002, 'grad_norm': 68.3588925904194, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.90625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.90625, 'reward_std': 0.2041158601641655, 'completion_length': 334.65625, 'kl': 0.1722412109375, 'epoch': 0.1}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [1:54:15<08:05, 24.27s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [1:54:37<07:27, 23.54s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1624122149678775, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3335031494498253, 'completion_length': 628.1875, 'kl': 0.4466400146484375, 'epoch': 0.1}
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [1:54:37<07:27, 23.54s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [1:55:09<07:51, 26.18s/it]                                                   {'loss': 0.0004, 'grad_norm': 1.1269116121048084, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.59375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.59375, 'reward_std': 0.3061639815568924, 'completion_length': 672.1875, 'kl': 0.4320068359375, 'epoch': 0.1}
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [1:55:09<07:51, 26.18s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [1:56:14<10:39, 37.60s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5951265525241053, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.4375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.4375, 'reward_std': 0.1157275140285492, 'completion_length': 1041.25, 'kl': 0.05112457275390625, 'epoch': 0.1}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [1:56:14<10:39, 37.60s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [1:56:49<09:50, 36.88s/it]                                                   {'loss': 0.0002, 'grad_norm': 0.6010548683375114, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.625, 'reward_std': 0.2177756354212761, 'completion_length': 758.875, 'kl': 0.2075958251953125, 'epoch': 0.1}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [1:56:49<09:50, 36.88s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [1:57:09<07:57, 31.81s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.2062429237376827, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.13363061845302582, 'completion_length': 581.5625, 'kl': 0.0529632568359375, 'epoch': 0.1}
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [1:57:09<07:57, 31.81s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [1:57:48<07:58, 34.15s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.6830017183620527, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.28125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.28125, 'reward_std': 0.2041158601641655, 'completion_length': 781.78125, 'kl': 0.07234954833984375, 'epoch': 0.1}
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [1:57:48<07:58, 34.15s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [1:58:06<06:20, 29.28s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.7066298295669466, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.2177756354212761, 'completion_length': 495.0, 'kl': 0.5437774658203125, 'epoch': 0.1}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [1:58:06<06:20, 29.28s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [1:58:47<06:33, 32.83s/it]                                                   {'loss': 0.0, 'grad_norm': 0.6797686808515774, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.34375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.34375, 'reward_std': 0.4807935431599617, 'completion_length': 1063.34375, 'kl': 0.01416015625, 'epoch': 0.1}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [1:58:47<06:33, 32.83s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [1:59:13<05:39, 30.82s/it]                                                   {'loss': 0.0, 'grad_norm': 0.604890005210093, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.3650856465101242, 'completion_length': 654.75, 'kl': 0.0491180419921875, 'epoch': 0.1}
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [1:59:13<05:39, 30.82s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [1:59:38<04:49, 28.93s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.6336580452973084, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3104073107242584, 'completion_length': 590.71875, 'kl': 0.095428466796875, 'epoch': 0.1}
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [1:59:38<04:49, 28.93s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [1:59:59<03:58, 26.53s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.3891037451432539, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.0883883461356163, 'completion_length': 546.71875, 'kl': 0.137664794921875, 'epoch': 0.1}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [1:59:59<03:58, 26.53s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [2:00:39<04:04, 30.60s/it]                                                   {'loss': 0.0, 'grad_norm': 0.42351526874246337, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.375, 'reward_std': 0.2177756354212761, 'completion_length': 954.59375, 'kl': 0.025686264038085938, 'epoch': 0.1}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [2:00:39<04:04, 30.60s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [2:01:25<04:06, 35.18s/it]                                                   {'loss': 0.0005, 'grad_norm': 0.9915026200632779, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.6875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.6875, 'reward_std': 0.3535533845424652, 'completion_length': 719.8125, 'kl': 0.471923828125, 'epoch': 0.1}
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [2:01:25<04:06, 35.18s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [2:01:51<03:14, 32.35s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.5648685402444185, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.84375, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.84375, 'reward_std': 0.22201896458864212, 'completion_length': 567.5625, 'kl': 0.07989501953125, 'epoch': 0.1}
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [2:01:51<03:14, 32.35s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [2:02:30<02:52, 34.58s/it]                                                   {'loss': 0.0, 'grad_norm': 0.4002768663141139, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.65625, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.65625, 'reward_std': 0.1293872892856598, 'completion_length': 766.09375, 'kl': 0.033966064453125, 'epoch': 0.1}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [2:02:30<02:52, 34.58s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [2:03:08<02:21, 35.39s/it]                                                   {'loss': 0.0, 'grad_norm': 0.28172935202737487, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.46875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.46875, 'reward_std': 0.0883883461356163, 'completion_length': 647.9375, 'kl': 0.048431396484375, 'epoch': 0.1}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [2:03:08<02:21, 35.39s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [2:03:59<02:00, 40.27s/it]                                                   {'loss': 0.0, 'grad_norm': 0.8222443185396723, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.71875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.71875, 'reward_std': 0.3198433741927147, 'completion_length': 726.875, 'kl': 0.031097412109375, 'epoch': 0.11}
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [2:03:59<02:00, 40.27s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [2:04:35<01:17, 38.77s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.8410402302807645, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.875, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.875, 'reward_std': 0.2925042062997818, 'completion_length': 644.84375, 'kl': 0.05322265625, 'epoch': 0.11}
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [2:04:35<01:17, 38.77s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [2:04:49<00:31, 31.45s/it]                                                   {'loss': 0.0001, 'grad_norm': 1.335808183260256, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.8125, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.8125, 'reward_std': 0.3335031494498253, 'completion_length': 319.15625, 'kl': 0.07733154296875, 'epoch': 0.11}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [2:04:49<00:31, 31.45s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:05:26<00:00, 33.25s/it]                                                   {'loss': 0.0001, 'grad_norm': 0.40906047131739387, 'learning_rate': 1e-06, 'rewards/reward_correct': 0.5, 'rewards/reward_correct_and_format': 0.0, 'reward': 0.5, 'reward_std': 0.2587745785713196, 'completion_length': 762.9375, 'kl': 0.05999755859375, 'epoch': 0.11}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:05:26<00:00, 33.25s/it]                                                   {'train_runtime': 7612.4124, 'train_samples_per_second': 0.841, 'train_steps_per_second': 0.026, 'train_loss': 6.587113978319792e-05, 'epoch': 0.11}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:06:46<00:00, 33.25s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:06:46<00:00, 38.03s/it]
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mqwen3b-full[0m at: [34mhttps://wandb.ai/ss13750-new-york-university-abu-dhabi/huggingface/runs/ckwa047b[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250312_095509-ckwa047b/logs[0m
